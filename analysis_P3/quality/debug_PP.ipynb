{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from hydra import initialize, compose\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from openelm.quality_metrics import utils\n",
    "from openelm.mutation_model import PromptModel\n",
    "from openelm.environments.p3.p3 import P3ProbSol_Chat_PP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_high = '/home/laetitia/work/code-eval/data/puzzles_high_fitness_archivetrain.json'\n",
    "path_low = '/home/laetitia/work/code-eval/data/puzzles_low_fitness_archivetrain.json'\n",
    "p_high = json.load(open(path_high, 'r'))\n",
    "p_low = json.load(open(path_low, 'r'))\n",
    "all_puzzles = p_high + p_low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def f(n: int):\n",
      "    \"\"\"Find n  such that 2^n mod n = 3\"\"\"\n",
      "    return pow(2, n, n) == 3\n",
      "def g():\n",
      "    return 4700063497\n",
      "assert f(g()) == True\n"
     ]
    }
   ],
   "source": [
    "lehmer = [pz for pz in all_puzzles if 'name' in pz and 'Lehmer' in pz['name']][0]\n",
    "print(lehmer['program_str'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-3.5-turbo-0125\n"
     ]
    }
   ],
   "source": [
    "with initialize(version_base=\"1.2\"):\n",
    "    cfg = compose(\n",
    "        config_name=\"elmconfig\",\n",
    "        overrides=[\"env=P3ProbSolChatEnv_PP_ELM_NLP\"]\n",
    "    )\n",
    "    # print(cfg)\n",
    "config = OmegaConf.to_object(cfg)\n",
    "\n",
    "cfg_generation: dict = {\n",
    "            \"temperature\": 0.,\n",
    "            \"model\": config.model.model_path,\n",
    "        }\n",
    "print(config.model.model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\n",
      " ======================\n",
      "\n",
      " ======================\n",
      "\n",
      "none \n",
      "\n",
      " ======================\n",
      "\n",
      "\n",
      " ======================\n",
      "\n",
      "\n",
      "load embedding model:\n",
      "ChatGPT\n",
      "loading preprocessed trainset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133/133 [00:00<00:00, 682793.67it/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bsize 2\n",
      "LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(32256, 2048)\n",
      "    (layers): ModuleList(\n",
      "      (0-23): 24 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "          (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "          (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "          (rotary_emb): LlamaLinearScalingRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)\n",
      "          (up_proj): Linear(in_features=2048, out_features=5504, bias=False)\n",
      "          (down_proj): Linear(in_features=5504, out_features=2048, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=2048, out_features=32256, bias=False)\n",
      ")\n",
      "16384\n",
      "BWAAA\n",
      "Filtering long puzzles in the archive\n",
      "end filtering\n",
      "original losses tensor([0.0470, 0.3531, 0.0937, 2.6778, 1.0918, 0.3747, 0.8110, 1.7684, 1.3947,\n",
      "        0.6910, 0.0907, 0.8916, 0.4864, 1.1402, 0.8258, 1.1303, 1.9917, 0.4647,\n",
      "        0.3152, 0.4948, 0.6501, 0.6652, 0.4439, 1.4664, 0.9101, 0.0557, 1.6362,\n",
      "        1.0722, 0.8770, 0.8454, 0.0604, 0.8019, 0.3886, 1.5758, 0.1477, 0.3180,\n",
      "        0.0207, 0.0543, 0.0501, 1.0049, 0.7224, 0.0613, 0.6964, 0.7293, 0.5147,\n",
      "        0.7094, 1.2746, 0.5727, 0.4475, 0.4660, 0.6268, 0.9978, 1.5290, 0.5044,\n",
      "        1.4547, 1.0285, 0.2499, 0.9563, 1.9872, 1.5329, 0.5491, 0.2155, 0.2945,\n",
      "        0.4194, 0.1161, 0.1931, 0.7958, 0.9460, 0.6300, 0.7980, 0.6945, 0.8194,\n",
      "        0.1205, 0.7748, 0.0786, 0.2845, 0.6838, 1.0645, 0.6969, 0.2739, 0.1844,\n",
      "        0.1645, 0.6528, 0.6939, 0.5862, 0.2432, 0.4127, 0.9993, 0.6321, 1.3618,\n",
      "        0.7611, 0.7285, 0.4128, 0.6560, 0.1184, 0.1787, 1.3452, 0.4317, 1.0881,\n",
      "        1.0075, 0.6219, 0.9360, 0.6331, 0.6724, 0.2807, 0.6674, 0.3444, 0.3083,\n",
      "        0.8338, 1.3937, 0.4108, 0.4515, 1.3968, 0.4878, 0.8253, 0.8283, 0.5420,\n",
      "        0.5864, 0.4921, 0.7912, 0.6067, 0.6502, 0.8688, 1.3796, 0.7973, 1.3301,\n",
      "        0.8313, 0.4973, 1.0561, 0.4681, 0.5479, 0.9303, 0.8705, 0.7975, 0.4413,\n",
      "        1.1512, 0.9250, 0.8358])\n"
     ]
    }
   ],
   "source": [
    "mutation_model = PromptModel(config.model)\n",
    "env = P3ProbSol_Chat_PP(config=config.env,\n",
    "        mutation_model=mutation_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "puzzle, solution = utils.get_puzzle_sol(lehmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_losses = env._get_losses(puzzle, solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_losses.tolist().index(min(final_losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def f(s: str, target=\"foobarbazwow\", length=6):\\n    \"\"\"Find a substring of the given length centered within the target string.\"\"\"\\n    return target[(len(target) - length) // 2:(len(target) + length) // 2] == s'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.archive_puzzle_strs[36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [(i, p) for i, p in enumerate(env.archive_puzzle_strs) if 'pow(2, n, n)' in p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3,\n",
       "  'def f(n: int):\\n    \"\"\"Find n  such that 2^n mod n = 3\"\"\"\\n    return pow(2, n, n) == 3')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.7380)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_losses[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.0754)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(final_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0 = all_puzzles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_losses = env._get_losses(*utils.get_puzzle_sol(p0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PenultimateRevString:2'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p0['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aces",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
