{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocess dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# path_codex=\"/media/data/flowers/OpenELM/Codex_PAPER_1M_iter_0.txt\"\n",
    "# # with open(path_codex, 'r') as f:\n",
    "# #     codex = f.read()\n",
    "#     # codex = [x.strip() for x in codex]\n",
    "# f = open(path_codex, 'r')\n",
    "# out=f.read()\n",
    "# f.close()\n",
    "\n",
    "# path_save=\"/media/data/flowers/OpenELM/codex_dataset.json\"\n",
    "# def format_dataset(puzzles):\n",
    "#     puzzles_prompt=\"\"\n",
    "#     for i in range(len(puzzles)):\n",
    "#         puzzles_prompt += f\"Puzzle {i}:\\n\"+puzzles[i]+\"\\n\"\n",
    "\n",
    "#     return puzzles_prompt\n",
    "# n_fewshot=4\n",
    "# dataset =[]\n",
    "# split_out=out.split(\"\\nassert f(g())\\n\\n\")\n",
    "# split_out = [x+\"\\nassert f(g())\\n\" for x in split_out if x]\n",
    "# split_out = split_out[:-1]\n",
    "# for idx in range(0,len(split_out),n_fewshot):\n",
    "#     split_out_n_fs = split_out[idx:idx+n_fewshot]\n",
    "#     if len(split_out_n_fs)==n_fewshot:\n",
    "#         dataset.append(format_dataset(split_out_n_fs))\n",
    "# dataset_json= [{'text': puzz} for puzz in dataset]\n",
    "# with open(path_save, 'w') as outfile:\n",
    "#     json.dump(dataset_json, outfile,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test model\n",
    "import os\n",
    "os.environ['HF_DATASETS_CACHE'] = \"/media/data/flowers/OpenELM/hf/datasets\"\n",
    "os.environ['TRANSFORMERS_CACHE'] = \"/media/data/flowers/OpenELM/models\"\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig,TrainingArguments\n",
    "\n",
    "from peft import prepare_model_for_kbit_training\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from trl import SFTTrainer\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# base training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /media/data/flowers/conda/envs/codegpt/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda118.so\n",
      "CUDA SETUP: CUDA runtime path found: /media/data/flowers/conda/envs/codegpt/lib/libcudart.so.11.0\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
      "CUDA SETUP: Detected CUDA version 118\n",
      "CUDA SETUP: Loading binary /media/data/flowers/conda/envs/codegpt/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda118.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/flowers/conda/envs/codegpt/lib/python3.10/site-packages/peft/utils/other.py:122: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
      "  warnings.warn(\n",
      "Using pad_token, but it is not set yet.\n",
      "/media/data/flowers/conda/envs/codegpt/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:166: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11666d9f31d04ce1beae28174b91b5e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/249749 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "675e3d18c4074ba99ecdca0526596fc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/flowers/conda/envs/codegpt/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjulien_p\u001b[0m (\u001b[33mflowers-team\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.8 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/media/data/flowers/OpenELM/wandb/run-20230824_124539-8vzkx8p0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/flowers-team/huggingface/runs/8vzkx8p0' target=\"_blank\">youthful-frost-42</a></strong> to <a href='https://wandb.ai/flowers-team/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/flowers-team/huggingface' target=\"_blank\">https://wandb.ai/flowers-team/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/flowers-team/huggingface/runs/8vzkx8p0' target=\"_blank\">https://wandb.ai/flowers-team/huggingface/runs/8vzkx8p0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a8b2a832f5042e6a48987d3e173c4bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a CodeGenTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9308, 'learning_rate': 1e-05, 'epoch': 0.0}\n",
      "{'loss': 0.9504, 'learning_rate': 2e-05, 'epoch': 0.0}\n",
      "{'loss': 1.1145, 'learning_rate': 3e-05, 'epoch': 0.0}\n",
      "{'loss': 1.1092, 'learning_rate': 4e-05, 'epoch': 0.0}\n",
      "{'loss': 1.0962, 'learning_rate': 5e-05, 'epoch': 0.0}\n",
      "{'loss': 1.1342, 'learning_rate': 6e-05, 'epoch': 0.0}\n",
      "{'loss': 1.0289, 'learning_rate': 7e-05, 'epoch': 0.0}\n",
      "{'loss': 1.0816, 'learning_rate': 8e-05, 'epoch': 0.0}\n",
      "{'loss': 1.08, 'learning_rate': 9e-05, 'epoch': 0.0}\n",
      "{'loss': 1.1016, 'learning_rate': 0.0001, 'epoch': 0.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8595dd5c99844ab4b3d3946bcbb4300f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0945059061050415, 'eval_runtime': 13.8121, 'eval_samples_per_second': 18.1, 'eval_steps_per_second': 3.041, 'epoch': 0.0}\n",
      "{'loss': 1.1252, 'learning_rate': 0.00011000000000000002, 'epoch': 0.0}\n",
      "{'loss': 1.1025, 'learning_rate': 0.00012, 'epoch': 0.0}\n",
      "{'loss': 1.088, 'learning_rate': 0.00013000000000000002, 'epoch': 0.0}\n",
      "{'loss': 1.0314, 'learning_rate': 0.00014, 'epoch': 0.0}\n",
      "{'loss': 1.087, 'learning_rate': 0.00015000000000000001, 'epoch': 0.0}\n",
      "{'loss': 1.0334, 'learning_rate': 0.00016, 'epoch': 0.0}\n",
      "{'loss': 1.0218, 'learning_rate': 0.00017, 'epoch': 0.0}\n",
      "{'loss': 1.0035, 'learning_rate': 0.00018, 'epoch': 0.0}\n",
      "{'loss': 0.9649, 'learning_rate': 0.00019, 'epoch': 0.0}\n",
      "{'loss': 0.9353, 'learning_rate': 0.0002, 'epoch': 0.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "538b5e35a591496796953daf20e159f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9285508990287781, 'eval_runtime': 13.9123, 'eval_samples_per_second': 17.97, 'eval_steps_per_second': 3.019, 'epoch': 0.0}\n",
      "{'loss': 0.9288, 'learning_rate': 0.00019989898989898993, 'epoch': 0.0}\n",
      "{'loss': 0.9023, 'learning_rate': 0.0001997979797979798, 'epoch': 0.0}\n",
      "{'loss': 0.9544, 'learning_rate': 0.00019969696969696971, 'epoch': 0.0}\n",
      "{'loss': 0.98, 'learning_rate': 0.0001995959595959596, 'epoch': 0.0}\n",
      "{'loss': 0.8538, 'learning_rate': 0.0001994949494949495, 'epoch': 0.0}\n",
      "{'loss': 0.8298, 'learning_rate': 0.0001993939393939394, 'epoch': 0.0}\n",
      "{'loss': 0.8625, 'learning_rate': 0.0001992929292929293, 'epoch': 0.0}\n",
      "{'loss': 0.7372, 'learning_rate': 0.0001991919191919192, 'epoch': 0.0}\n",
      "{'loss': 0.8164, 'learning_rate': 0.0001990909090909091, 'epoch': 0.0}\n",
      "{'loss': 0.8697, 'learning_rate': 0.000198989898989899, 'epoch': 0.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8c1c633a24742b99be319815a30fe4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7928044199943542, 'eval_runtime': 13.9605, 'eval_samples_per_second': 17.908, 'eval_steps_per_second': 3.008, 'epoch': 0.0}\n",
      "{'loss': 0.8195, 'learning_rate': 0.0001988888888888889, 'epoch': 0.0}\n",
      "{'loss': 0.7949, 'learning_rate': 0.00019878787878787878, 'epoch': 0.0}\n",
      "{'loss': 0.844, 'learning_rate': 0.0001986868686868687, 'epoch': 0.0}\n",
      "{'loss': 0.7797, 'learning_rate': 0.0001985858585858586, 'epoch': 0.0}\n",
      "{'loss': 0.7537, 'learning_rate': 0.0001984848484848485, 'epoch': 0.0}\n",
      "{'loss': 0.8498, 'learning_rate': 0.00019838383838383837, 'epoch': 0.0}\n",
      "{'loss': 0.757, 'learning_rate': 0.0001982828282828283, 'epoch': 0.0}\n",
      "{'loss': 0.787, 'learning_rate': 0.00019818181818181821, 'epoch': 0.0}\n",
      "{'loss': 0.7134, 'learning_rate': 0.00019808080808080808, 'epoch': 0.0}\n",
      "{'loss': 0.8168, 'learning_rate': 0.000197979797979798, 'epoch': 0.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f240d89e4d14df09524fdbd94968d5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7541994452476501, 'eval_runtime': 13.9849, 'eval_samples_per_second': 17.876, 'eval_steps_per_second': 3.003, 'epoch': 0.0}\n",
      "{'loss': 0.7851, 'learning_rate': 0.0001978787878787879, 'epoch': 0.0}\n",
      "{'loss': 0.731, 'learning_rate': 0.00019777777777777778, 'epoch': 0.0}\n",
      "{'loss': 0.7672, 'learning_rate': 0.00019767676767676768, 'epoch': 0.0}\n",
      "{'loss': 0.7606, 'learning_rate': 0.0001975757575757576, 'epoch': 0.0}\n",
      "{'loss': 0.7373, 'learning_rate': 0.0001974747474747475, 'epoch': 0.0}\n",
      "{'loss': 0.7242, 'learning_rate': 0.00019737373737373738, 'epoch': 0.0}\n",
      "{'loss': 0.6992, 'learning_rate': 0.00019727272727272728, 'epoch': 0.0}\n",
      "{'loss': 0.7408, 'learning_rate': 0.0001971717171717172, 'epoch': 0.0}\n",
      "{'loss': 0.7322, 'learning_rate': 0.00019707070707070706, 'epoch': 0.0}\n",
      "{'loss': 0.6865, 'learning_rate': 0.00019696969696969698, 'epoch': 0.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3d2683858244182ada2c296445ecd50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7421572208404541, 'eval_runtime': 13.9689, 'eval_samples_per_second': 17.897, 'eval_steps_per_second': 3.007, 'epoch': 0.0}\n",
      "{'loss': 0.7754, 'learning_rate': 0.00019686868686868687, 'epoch': 0.0}\n",
      "{'loss': 0.7334, 'learning_rate': 0.00019676767676767677, 'epoch': 0.0}\n",
      "{'loss': 0.7995, 'learning_rate': 0.00019666666666666666, 'epoch': 0.0}\n",
      "{'loss': 0.761, 'learning_rate': 0.00019656565656565658, 'epoch': 0.0}\n",
      "{'loss': 0.7324, 'learning_rate': 0.0001964646464646465, 'epoch': 0.0}\n",
      "{'loss': 0.7245, 'learning_rate': 0.00019636363636363636, 'epoch': 0.0}\n",
      "{'loss': 0.6995, 'learning_rate': 0.00019626262626262628, 'epoch': 0.0}\n",
      "{'loss': 0.7986, 'learning_rate': 0.00019616161616161618, 'epoch': 0.0}\n",
      "{'loss': 0.7783, 'learning_rate': 0.00019606060606060607, 'epoch': 0.0}\n",
      "{'loss': 0.745, 'learning_rate': 0.00019595959595959596, 'epoch': 0.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57722aaad1aa4234bf145fe5c7a97933",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.732877790927887, 'eval_runtime': 13.9913, 'eval_samples_per_second': 17.868, 'eval_steps_per_second': 3.002, 'epoch': 0.0}\n",
      "{'loss': 0.7948, 'learning_rate': 0.00019585858585858588, 'epoch': 0.0}\n",
      "{'loss': 0.7689, 'learning_rate': 0.00019575757575757577, 'epoch': 0.0}\n",
      "{'loss': 0.6961, 'learning_rate': 0.00019565656565656567, 'epoch': 0.0}\n",
      "{'loss': 0.7207, 'learning_rate': 0.00019555555555555556, 'epoch': 0.0}\n",
      "{'loss': 0.7386, 'learning_rate': 0.00019545454545454548, 'epoch': 0.0}\n",
      "{'loss': 0.8009, 'learning_rate': 0.00019535353535353534, 'epoch': 0.0}\n",
      "{'loss': 0.7341, 'learning_rate': 0.00019525252525252526, 'epoch': 0.0}\n",
      "{'loss': 0.7711, 'learning_rate': 0.00019515151515151516, 'epoch': 0.0}\n",
      "{'loss': 0.7283, 'learning_rate': 0.00019505050505050505, 'epoch': 0.0}\n",
      "{'loss': 0.7322, 'learning_rate': 0.00019494949494949494, 'epoch': 0.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccdbbac934334019866ba16c5b742fcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7189012169837952, 'eval_runtime': 13.9902, 'eval_samples_per_second': 17.87, 'eval_steps_per_second': 3.002, 'epoch': 0.0}\n",
      "{'loss': 0.7113, 'learning_rate': 0.00019484848484848486, 'epoch': 0.0}\n",
      "{'loss': 0.7248, 'learning_rate': 0.00019474747474747476, 'epoch': 0.0}\n",
      "{'loss': 0.8043, 'learning_rate': 0.00019464646464646465, 'epoch': 0.0}\n",
      "{'loss': 0.7405, 'learning_rate': 0.00019454545454545457, 'epoch': 0.0}\n",
      "{'loss': 0.7548, 'learning_rate': 0.00019444444444444446, 'epoch': 0.0}\n",
      "{'loss': 0.7031, 'learning_rate': 0.00019434343434343435, 'epoch': 0.0}\n",
      "{'loss': 0.7423, 'learning_rate': 0.00019424242424242425, 'epoch': 0.0}\n",
      "{'loss': 0.7663, 'learning_rate': 0.00019414141414141417, 'epoch': 0.0}\n",
      "{'loss': 0.7253, 'learning_rate': 0.00019404040404040403, 'epoch': 0.0}\n",
      "{'loss': 0.7529, 'learning_rate': 0.00019393939393939395, 'epoch': 0.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35e63b3186cd49268e99240d6a88673b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7119365334510803, 'eval_runtime': 14.0548, 'eval_samples_per_second': 17.787, 'eval_steps_per_second': 2.988, 'epoch': 0.0}\n",
      "{'loss': 0.666, 'learning_rate': 0.00019383838383838384, 'epoch': 0.0}\n",
      "{'loss': 0.7348, 'learning_rate': 0.00019373737373737376, 'epoch': 0.0}\n",
      "{'loss': 0.6953, 'learning_rate': 0.00019363636363636363, 'epoch': 0.0}\n",
      "{'loss': 0.7749, 'learning_rate': 0.00019353535353535355, 'epoch': 0.0}\n",
      "{'loss': 0.704, 'learning_rate': 0.00019343434343434344, 'epoch': 0.0}\n",
      "{'loss': 0.6808, 'learning_rate': 0.00019333333333333333, 'epoch': 0.0}\n",
      "{'loss': 0.7649, 'learning_rate': 0.00019323232323232323, 'epoch': 0.0}\n",
      "{'loss': 0.7554, 'learning_rate': 0.00019313131313131315, 'epoch': 0.0}\n",
      "{'loss': 0.6937, 'learning_rate': 0.00019303030303030304, 'epoch': 0.0}\n",
      "{'loss': 0.6878, 'learning_rate': 0.00019292929292929293, 'epoch': 0.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "745e84030cf6438fa65727b5147a5386",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7086156010627747, 'eval_runtime': 13.9967, 'eval_samples_per_second': 17.861, 'eval_steps_per_second': 3.001, 'epoch': 0.0}\n",
      "{'loss': 0.6809, 'learning_rate': 0.00019282828282828285, 'epoch': 0.0}\n",
      "{'loss': 0.7298, 'learning_rate': 0.00019272727272727274, 'epoch': 0.0}\n",
      "{'loss': 0.8007, 'learning_rate': 0.00019262626262626264, 'epoch': 0.0}\n",
      "{'loss': 0.6944, 'learning_rate': 0.00019252525252525253, 'epoch': 0.0}\n",
      "{'loss': 0.6711, 'learning_rate': 0.00019242424242424245, 'epoch': 0.0}\n",
      "{'loss': 0.7025, 'learning_rate': 0.00019232323232323232, 'epoch': 0.0}\n",
      "{'loss': 0.6897, 'learning_rate': 0.00019222222222222224, 'epoch': 0.0}\n",
      "{'loss': 0.641, 'learning_rate': 0.00019212121212121213, 'epoch': 0.0}\n",
      "{'loss': 0.7007, 'learning_rate': 0.00019202020202020202, 'epoch': 0.0}\n",
      "{'loss': 0.6682, 'learning_rate': 0.00019191919191919191, 'epoch': 0.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14e63e97b5b54b76804598b201bc17e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7109216451644897, 'eval_runtime': 13.9616, 'eval_samples_per_second': 17.906, 'eval_steps_per_second': 3.008, 'epoch': 0.0}\n",
      "{'loss': 0.6808, 'learning_rate': 0.00019181818181818183, 'epoch': 0.0}\n",
      "{'loss': 0.7277, 'learning_rate': 0.00019171717171717173, 'epoch': 0.0}\n",
      "{'loss': 0.7459, 'learning_rate': 0.00019161616161616162, 'epoch': 0.0}\n",
      "{'loss': 0.6732, 'learning_rate': 0.0001915151515151515, 'epoch': 0.0}\n",
      "{'loss': 0.6885, 'learning_rate': 0.00019141414141414143, 'epoch': 0.01}\n",
      "{'loss': 0.7218, 'learning_rate': 0.00019131313131313132, 'epoch': 0.01}\n",
      "{'loss': 0.6366, 'learning_rate': 0.00019121212121212122, 'epoch': 0.01}\n",
      "{'loss': 0.6959, 'learning_rate': 0.00019111111111111114, 'epoch': 0.01}\n",
      "{'loss': 0.736, 'learning_rate': 0.00019101010101010103, 'epoch': 0.01}\n",
      "{'loss': 0.6621, 'learning_rate': 0.00019090909090909092, 'epoch': 0.01}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49e5fcce1e9e412ab0800196675302f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7115762829780579, 'eval_runtime': 13.9674, 'eval_samples_per_second': 17.899, 'eval_steps_per_second': 3.007, 'epoch': 0.01}\n",
      "{'loss': 0.7494, 'learning_rate': 0.00019080808080808081, 'epoch': 0.01}\n",
      "{'loss': 0.6837, 'learning_rate': 0.00019070707070707073, 'epoch': 0.01}\n",
      "{'loss': 0.7493, 'learning_rate': 0.0001906060606060606, 'epoch': 0.01}\n",
      "{'loss': 0.7198, 'learning_rate': 0.00019050505050505052, 'epoch': 0.01}\n",
      "{'loss': 0.7146, 'learning_rate': 0.0001904040404040404, 'epoch': 0.01}\n",
      "{'loss': 0.6755, 'learning_rate': 0.0001903030303030303, 'epoch': 0.01}\n",
      "{'loss': 0.6731, 'learning_rate': 0.0001902020202020202, 'epoch': 0.01}\n",
      "{'loss': 0.771, 'learning_rate': 0.00019010101010101012, 'epoch': 0.01}\n",
      "{'loss': 0.7357, 'learning_rate': 0.00019, 'epoch': 0.01}\n",
      "{'loss': 0.6797, 'learning_rate': 0.0001898989898989899, 'epoch': 0.01}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b2bbdd07e4b468fb11d83e42896cf7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7007269263267517, 'eval_runtime': 13.9703, 'eval_samples_per_second': 17.895, 'eval_steps_per_second': 3.006, 'epoch': 0.01}\n",
      "{'loss': 0.7033, 'learning_rate': 0.0001897979797979798, 'epoch': 0.01}\n",
      "{'loss': 0.7078, 'learning_rate': 0.00018969696969696972, 'epoch': 0.01}\n",
      "{'loss': 0.6911, 'learning_rate': 0.0001895959595959596, 'epoch': 0.01}\n",
      "{'loss': 0.706, 'learning_rate': 0.0001894949494949495, 'epoch': 0.01}\n",
      "{'loss': 0.6973, 'learning_rate': 0.00018939393939393942, 'epoch': 0.01}\n",
      "{'loss': 0.7117, 'learning_rate': 0.0001892929292929293, 'epoch': 0.01}\n",
      "{'loss': 0.7899, 'learning_rate': 0.0001891919191919192, 'epoch': 0.01}\n",
      "{'loss': 0.761, 'learning_rate': 0.0001890909090909091, 'epoch': 0.01}\n",
      "{'loss': 0.7139, 'learning_rate': 0.00018898989898989902, 'epoch': 0.01}\n",
      "{'loss': 0.6619, 'learning_rate': 0.00018888888888888888, 'epoch': 0.01}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f307c5982fe948b0baeeba49c986cb7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6985626816749573, 'eval_runtime': 13.9991, 'eval_samples_per_second': 17.858, 'eval_steps_per_second': 3.0, 'epoch': 0.01}\n",
      "{'loss': 0.7217, 'learning_rate': 0.0001887878787878788, 'epoch': 0.01}\n",
      "{'loss': 0.6802, 'learning_rate': 0.0001886868686868687, 'epoch': 0.01}\n",
      "{'loss': 0.6962, 'learning_rate': 0.0001885858585858586, 'epoch': 0.01}\n",
      "{'loss': 0.6229, 'learning_rate': 0.00018848484848484848, 'epoch': 0.01}\n",
      "{'loss': 0.7428, 'learning_rate': 0.0001883838383838384, 'epoch': 0.01}\n",
      "{'loss': 0.663, 'learning_rate': 0.0001882828282828283, 'epoch': 0.01}\n",
      "{'loss': 0.6784, 'learning_rate': 0.0001881818181818182, 'epoch': 0.01}\n",
      "{'loss': 0.6955, 'learning_rate': 0.00018808080808080808, 'epoch': 0.01}\n",
      "{'loss': 0.6425, 'learning_rate': 0.000187979797979798, 'epoch': 0.01}\n",
      "{'loss': 0.6784, 'learning_rate': 0.0001878787878787879, 'epoch': 0.01}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c59b0c52fc84b188f5eae769f31e879",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6975731253623962, 'eval_runtime': 14.0687, 'eval_samples_per_second': 17.77, 'eval_steps_per_second': 2.985, 'epoch': 0.01}\n",
      "{'loss': 0.6766, 'learning_rate': 0.00018777777777777779, 'epoch': 0.01}\n",
      "{'loss': 0.7146, 'learning_rate': 0.0001876767676767677, 'epoch': 0.01}\n",
      "{'loss': 0.7329, 'learning_rate': 0.00018757575757575757, 'epoch': 0.01}\n",
      "{'loss': 0.7655, 'learning_rate': 0.0001874747474747475, 'epoch': 0.01}\n",
      "{'loss': 0.6471, 'learning_rate': 0.00018737373737373738, 'epoch': 0.01}\n",
      "{'loss': 0.585, 'learning_rate': 0.00018727272727272728, 'epoch': 0.01}\n",
      "{'loss': 0.7227, 'learning_rate': 0.00018717171717171717, 'epoch': 0.01}\n",
      "{'loss': 0.6523, 'learning_rate': 0.0001870707070707071, 'epoch': 0.01}\n",
      "{'loss': 0.6992, 'learning_rate': 0.00018696969696969698, 'epoch': 0.01}\n",
      "{'loss': 0.6425, 'learning_rate': 0.00018686868686868687, 'epoch': 0.01}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d88b5dbae00049a380f7fc507110fdb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7000332474708557, 'eval_runtime': 14.0852, 'eval_samples_per_second': 17.749, 'eval_steps_per_second': 2.982, 'epoch': 0.01}\n",
      "{'loss': 0.6732, 'learning_rate': 0.00018676767676767677, 'epoch': 0.01}\n",
      "{'loss': 0.7241, 'learning_rate': 0.0001866666666666667, 'epoch': 0.01}\n",
      "{'loss': 0.6846, 'learning_rate': 0.00018656565656565658, 'epoch': 0.01}\n",
      "{'loss': 0.7345, 'learning_rate': 0.00018646464646464647, 'epoch': 0.01}\n",
      "{'loss': 0.7516, 'learning_rate': 0.00018636363636363636, 'epoch': 0.01}\n",
      "{'loss': 0.6885, 'learning_rate': 0.00018626262626262628, 'epoch': 0.01}\n",
      "{'loss': 0.7156, 'learning_rate': 0.00018616161616161618, 'epoch': 0.01}\n",
      "{'loss': 0.8088, 'learning_rate': 0.00018606060606060607, 'epoch': 0.01}\n",
      "{'loss': 0.7716, 'learning_rate': 0.000185959595959596, 'epoch': 0.01}\n",
      "{'loss': 0.6939, 'learning_rate': 0.00018585858585858586, 'epoch': 0.01}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2780cd20bf045aab8e5f8f3aade6001",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7020204663276672, 'eval_runtime': 13.9961, 'eval_samples_per_second': 17.862, 'eval_steps_per_second': 3.001, 'epoch': 0.01}\n",
      "{'loss': 0.6723, 'learning_rate': 0.00018575757575757577, 'epoch': 0.01}\n",
      "{'loss': 0.7598, 'learning_rate': 0.00018565656565656567, 'epoch': 0.01}\n",
      "{'loss': 0.7889, 'learning_rate': 0.00018555555555555556, 'epoch': 0.01}\n",
      "{'loss': 0.7125, 'learning_rate': 0.00018545454545454545, 'epoch': 0.01}\n",
      "{'loss': 0.6909, 'learning_rate': 0.00018535353535353537, 'epoch': 0.01}\n",
      "{'loss': 0.6975, 'learning_rate': 0.00018525252525252527, 'epoch': 0.01}\n",
      "{'loss': 0.7107, 'learning_rate': 0.00018515151515151516, 'epoch': 0.01}\n",
      "{'loss': 0.7232, 'learning_rate': 0.00018505050505050505, 'epoch': 0.01}\n",
      "{'loss': 0.7674, 'learning_rate': 0.00018494949494949497, 'epoch': 0.01}\n",
      "{'loss': 0.7092, 'learning_rate': 0.00018484848484848484, 'epoch': 0.01}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5c4fbead81c4d62a47b6e16d52684f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6934818625450134, 'eval_runtime': 13.9724, 'eval_samples_per_second': 17.892, 'eval_steps_per_second': 3.006, 'epoch': 0.01}\n",
      "{'loss': 0.7541, 'learning_rate': 0.00018474747474747476, 'epoch': 0.01}\n",
      "{'loss': 0.6838, 'learning_rate': 0.00018464646464646465, 'epoch': 0.01}\n",
      "{'loss': 0.7435, 'learning_rate': 0.00018454545454545454, 'epoch': 0.01}\n",
      "{'loss': 0.7071, 'learning_rate': 0.00018444444444444446, 'epoch': 0.01}\n",
      "{'loss': 0.7345, 'learning_rate': 0.00018434343434343435, 'epoch': 0.01}\n",
      "{'loss': 0.6708, 'learning_rate': 0.00018424242424242427, 'epoch': 0.01}\n",
      "{'loss': 0.6775, 'learning_rate': 0.00018414141414141414, 'epoch': 0.01}\n",
      "{'loss': 0.7054, 'learning_rate': 0.00018404040404040406, 'epoch': 0.01}\n",
      "{'loss': 0.6981, 'learning_rate': 0.00018393939393939395, 'epoch': 0.01}\n",
      "{'loss': 0.7275, 'learning_rate': 0.00018383838383838384, 'epoch': 0.01}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02ed83b0b50a4e64affd70cdea51cdfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6920152902603149, 'eval_runtime': 12.724, 'eval_samples_per_second': 19.648, 'eval_steps_per_second': 3.301, 'epoch': 0.01}\n",
      "{'loss': 0.7084, 'learning_rate': 0.00018373737373737374, 'epoch': 0.01}\n",
      "{'loss': 0.6664, 'learning_rate': 0.00018363636363636366, 'epoch': 0.01}\n",
      "{'loss': 0.6827, 'learning_rate': 0.00018353535353535355, 'epoch': 0.01}\n",
      "{'loss': 0.741, 'learning_rate': 0.00018343434343434344, 'epoch': 0.01}\n",
      "{'loss': 0.6622, 'learning_rate': 0.00018333333333333334, 'epoch': 0.01}\n",
      "{'loss': 0.6974, 'learning_rate': 0.00018323232323232326, 'epoch': 0.01}\n",
      "{'loss': 0.6056, 'learning_rate': 0.00018313131313131312, 'epoch': 0.01}\n",
      "{'loss': 0.6863, 'learning_rate': 0.00018303030303030304, 'epoch': 0.01}\n",
      "{'loss': 0.7217, 'learning_rate': 0.00018292929292929293, 'epoch': 0.01}\n",
      "{'loss': 0.6903, 'learning_rate': 0.00018282828282828283, 'epoch': 0.01}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0811c2ecff0c41478917e9f65f544107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6920090317726135, 'eval_runtime': 11.9888, 'eval_samples_per_second': 20.853, 'eval_steps_per_second': 3.503, 'epoch': 0.01}\n",
      "{'loss': 0.678, 'learning_rate': 0.00018272727272727275, 'epoch': 0.01}\n",
      "{'loss': 0.694, 'learning_rate': 0.00018262626262626264, 'epoch': 0.01}\n",
      "{'loss': 0.6923, 'learning_rate': 0.00018252525252525253, 'epoch': 0.01}\n",
      "{'loss': 0.7238, 'learning_rate': 0.00018242424242424242, 'epoch': 0.01}\n",
      "{'loss': 0.6375, 'learning_rate': 0.00018232323232323234, 'epoch': 0.01}\n",
      "{'loss': 0.7252, 'learning_rate': 0.00018222222222222224, 'epoch': 0.01}\n",
      "{'loss': 0.675, 'learning_rate': 0.00018212121212121213, 'epoch': 0.01}\n",
      "{'loss': 0.7134, 'learning_rate': 0.00018202020202020202, 'epoch': 0.01}\n",
      "{'loss': 0.6626, 'learning_rate': 0.00018191919191919194, 'epoch': 0.01}\n",
      "{'loss': 0.6604, 'learning_rate': 0.00018181818181818183, 'epoch': 0.01}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69f6afb4523f4646b3a52d0a11723421",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6938185691833496, 'eval_runtime': 11.9716, 'eval_samples_per_second': 20.883, 'eval_steps_per_second': 3.508, 'epoch': 0.01}\n",
      "{'loss': 0.7177, 'learning_rate': 0.00018171717171717173, 'epoch': 0.01}\n",
      "{'loss': 0.7101, 'learning_rate': 0.00018161616161616162, 'epoch': 0.01}\n",
      "{'loss': 0.6826, 'learning_rate': 0.00018151515151515154, 'epoch': 0.01}\n",
      "{'loss': 0.7571, 'learning_rate': 0.0001814141414141414, 'epoch': 0.01}\n",
      "{'loss': 0.6999, 'learning_rate': 0.00018131313131313132, 'epoch': 0.01}\n",
      "{'loss': 0.7349, 'learning_rate': 0.00018121212121212122, 'epoch': 0.01}\n",
      "{'loss': 0.7806, 'learning_rate': 0.0001811111111111111, 'epoch': 0.01}\n",
      "{'loss': 0.698, 'learning_rate': 0.00018101010101010103, 'epoch': 0.01}\n",
      "{'loss': 0.7348, 'learning_rate': 0.00018090909090909092, 'epoch': 0.01}\n",
      "{'loss': 0.6983, 'learning_rate': 0.00018080808080808082, 'epoch': 0.01}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34821fd2222448dc94220b43a2a913ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6951889395713806, 'eval_runtime': 11.988, 'eval_samples_per_second': 20.854, 'eval_steps_per_second': 3.504, 'epoch': 0.01}\n",
      "{'loss': 0.7397, 'learning_rate': 0.0001807070707070707, 'epoch': 0.01}\n",
      "{'loss': 0.7379, 'learning_rate': 0.00018060606060606063, 'epoch': 0.01}\n",
      "{'loss': 0.6985, 'learning_rate': 0.00018050505050505052, 'epoch': 0.01}\n",
      "{'loss': 0.7728, 'learning_rate': 0.0001804040404040404, 'epoch': 0.01}\n",
      "{'loss': 0.7057, 'learning_rate': 0.0001803030303030303, 'epoch': 0.01}\n",
      "{'loss': 0.6734, 'learning_rate': 0.00018020202020202023, 'epoch': 0.01}\n",
      "{'loss': 0.7164, 'learning_rate': 0.0001801010101010101, 'epoch': 0.01}\n",
      "{'loss': 0.758, 'learning_rate': 0.00018, 'epoch': 0.01}\n",
      "{'loss': 0.6916, 'learning_rate': 0.0001798989898989899, 'epoch': 0.01}\n",
      "{'loss': 0.6832, 'learning_rate': 0.0001797979797979798, 'epoch': 0.01}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8601b83ef9a04f8dbf6e515d7a5f3ae7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6891635656356812, 'eval_runtime': 12.0015, 'eval_samples_per_second': 20.831, 'eval_steps_per_second': 3.5, 'epoch': 0.01}\n",
      "{'loss': 0.7518, 'learning_rate': 0.0001796969696969697, 'epoch': 0.01}\n",
      "{'loss': 0.657, 'learning_rate': 0.0001795959595959596, 'epoch': 0.01}\n",
      "{'loss': 0.7004, 'learning_rate': 0.0001794949494949495, 'epoch': 0.01}\n",
      "{'loss': 0.7212, 'learning_rate': 0.0001793939393939394, 'epoch': 0.01}\n",
      "{'loss': 0.7314, 'learning_rate': 0.00017929292929292931, 'epoch': 0.01}\n",
      "{'loss': 0.705, 'learning_rate': 0.0001791919191919192, 'epoch': 0.01}\n",
      "{'loss': 0.6675, 'learning_rate': 0.0001790909090909091, 'epoch': 0.01}\n",
      "{'loss': 0.7589, 'learning_rate': 0.000178989898989899, 'epoch': 0.01}\n",
      "{'loss': 0.678, 'learning_rate': 0.0001788888888888889, 'epoch': 0.01}\n",
      "{'loss': 0.7668, 'learning_rate': 0.0001787878787878788, 'epoch': 0.01}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6911e382ac044bd09665455ce706da9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6868668794631958, 'eval_runtime': 12.0018, 'eval_samples_per_second': 20.83, 'eval_steps_per_second': 3.499, 'epoch': 0.01}\n",
      "{'loss': 0.6599, 'learning_rate': 0.0001786868686868687, 'epoch': 0.01}\n",
      "{'loss': 0.685, 'learning_rate': 0.0001785858585858586, 'epoch': 0.01}\n",
      "{'loss': 0.6832, 'learning_rate': 0.0001784848484848485, 'epoch': 0.01}\n",
      "{'loss': 0.7019, 'learning_rate': 0.00017838383838383838, 'epoch': 0.01}\n",
      "{'loss': 0.7554, 'learning_rate': 0.0001782828282828283, 'epoch': 0.01}\n",
      "{'loss': 0.727, 'learning_rate': 0.0001781818181818182, 'epoch': 0.01}\n",
      "{'loss': 0.7001, 'learning_rate': 0.00017808080808080808, 'epoch': 0.01}\n",
      "{'loss': 0.6981, 'learning_rate': 0.00017797979797979797, 'epoch': 0.01}\n",
      "{'loss': 0.6476, 'learning_rate': 0.0001778787878787879, 'epoch': 0.01}\n",
      "{'loss': 0.6897, 'learning_rate': 0.00017777777777777779, 'epoch': 0.01}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "395231f5081e4545bbbeae333aa6b95e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6865503191947937, 'eval_runtime': 11.9932, 'eval_samples_per_second': 20.845, 'eval_steps_per_second': 3.502, 'epoch': 0.01}\n",
      "{'loss': 0.6108, 'learning_rate': 0.00017767676767676768, 'epoch': 0.01}\n",
      "{'loss': 0.6594, 'learning_rate': 0.0001775757575757576, 'epoch': 0.01}\n",
      "{'loss': 0.7044, 'learning_rate': 0.0001774747474747475, 'epoch': 0.01}\n",
      "{'loss': 0.6804, 'learning_rate': 0.00017737373737373738, 'epoch': 0.01}\n",
      "{'loss': 0.7121, 'learning_rate': 0.00017727272727272728, 'epoch': 0.01}\n",
      "{'loss': 0.6013, 'learning_rate': 0.0001771717171717172, 'epoch': 0.01}\n",
      "{'loss': 0.6679, 'learning_rate': 0.0001770707070707071, 'epoch': 0.01}\n",
      "{'loss': 0.6566, 'learning_rate': 0.00017696969696969698, 'epoch': 0.01}\n",
      "{'loss': 0.6921, 'learning_rate': 0.00017686868686868687, 'epoch': 0.01}\n",
      "{'loss': 0.6626, 'learning_rate': 0.0001767676767676768, 'epoch': 0.01}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83ae9b4fdde840ceb940d662a4547a60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6912760734558105, 'eval_runtime': 11.9996, 'eval_samples_per_second': 20.834, 'eval_steps_per_second': 3.5, 'epoch': 0.01}\n",
      "{'loss': 0.8326, 'learning_rate': 0.00017666666666666666, 'epoch': 0.01}\n",
      "{'loss': 0.6683, 'learning_rate': 0.00017656565656565658, 'epoch': 0.01}\n",
      "{'loss': 0.6906, 'learning_rate': 0.00017646464646464647, 'epoch': 0.01}\n",
      "{'loss': 0.7949, 'learning_rate': 0.00017636363636363637, 'epoch': 0.01}\n",
      "{'loss': 0.7532, 'learning_rate': 0.00017626262626262626, 'epoch': 0.01}\n",
      "{'loss': 0.6653, 'learning_rate': 0.00017616161616161618, 'epoch': 0.01}\n",
      "{'loss': 0.6678, 'learning_rate': 0.00017606060606060607, 'epoch': 0.01}\n",
      "{'loss': 0.7058, 'learning_rate': 0.00017595959595959596, 'epoch': 0.01}\n",
      "{'loss': 0.6757, 'learning_rate': 0.00017585858585858588, 'epoch': 0.01}\n",
      "{'loss': 0.6854, 'learning_rate': 0.00017575757575757578, 'epoch': 0.01}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aaba6c69e394b4da2086b82d1b5912d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.689868152141571, 'eval_runtime': 12.0108, 'eval_samples_per_second': 20.815, 'eval_steps_per_second': 3.497, 'epoch': 0.01}\n",
      "{'loss': 0.7788, 'learning_rate': 0.00017565656565656567, 'epoch': 0.01}\n",
      "{'loss': 0.7038, 'learning_rate': 0.00017555555555555556, 'epoch': 0.01}\n",
      "{'loss': 0.6588, 'learning_rate': 0.00017545454545454548, 'epoch': 0.01}\n",
      "{'loss': 0.7465, 'learning_rate': 0.00017535353535353535, 'epoch': 0.01}\n",
      "{'loss': 0.6888, 'learning_rate': 0.00017525252525252527, 'epoch': 0.01}\n",
      "{'loss': 0.7112, 'learning_rate': 0.00017515151515151516, 'epoch': 0.01}\n",
      "{'loss': 0.7148, 'learning_rate': 0.00017505050505050505, 'epoch': 0.01}\n",
      "{'loss': 0.7362, 'learning_rate': 0.00017494949494949494, 'epoch': 0.01}\n",
      "{'loss': 0.7081, 'learning_rate': 0.00017484848484848486, 'epoch': 0.01}\n",
      "{'loss': 0.6801, 'learning_rate': 0.00017474747474747476, 'epoch': 0.01}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a5e96b959b9473282d5b2e6bbbee33f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.684431254863739, 'eval_runtime': 12.011, 'eval_samples_per_second': 20.814, 'eval_steps_per_second': 3.497, 'epoch': 0.01}\n",
      "{'loss': 0.7074, 'learning_rate': 0.00017464646464646465, 'epoch': 0.01}\n",
      "{'loss': 0.6826, 'learning_rate': 0.00017454545454545454, 'epoch': 0.01}\n",
      "{'loss': 0.7652, 'learning_rate': 0.00017444444444444446, 'epoch': 0.01}\n",
      "{'loss': 0.7068, 'learning_rate': 0.00017434343434343435, 'epoch': 0.01}\n",
      "{'loss': 0.6452, 'learning_rate': 0.00017424242424242425, 'epoch': 0.01}\n",
      "{'loss': 0.7238, 'learning_rate': 0.00017414141414141414, 'epoch': 0.01}\n",
      "{'loss': 0.6843, 'learning_rate': 0.00017404040404040406, 'epoch': 0.01}\n",
      "{'loss': 0.6638, 'learning_rate': 0.00017393939393939395, 'epoch': 0.01}\n",
      "{'loss': 0.6929, 'learning_rate': 0.00017383838383838385, 'epoch': 0.01}\n",
      "{'loss': 0.6751, 'learning_rate': 0.00017373737373737377, 'epoch': 0.01}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4de7fd7ae58b4195b097750fec77a554",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6840265393257141, 'eval_runtime': 12.0101, 'eval_samples_per_second': 20.816, 'eval_steps_per_second': 3.497, 'epoch': 0.01}\n",
      "{'loss': 0.6987, 'learning_rate': 0.00017363636363636363, 'epoch': 0.01}\n",
      "{'loss': 0.7013, 'learning_rate': 0.00017353535353535355, 'epoch': 0.01}\n",
      "{'loss': 0.7357, 'learning_rate': 0.00017343434343434344, 'epoch': 0.01}\n",
      "{'loss': 0.7195, 'learning_rate': 0.00017333333333333334, 'epoch': 0.01}\n",
      "{'loss': 0.6796, 'learning_rate': 0.00017323232323232323, 'epoch': 0.01}\n",
      "{'loss': 0.7154, 'learning_rate': 0.00017313131313131315, 'epoch': 0.01}\n",
      "{'loss': 0.645, 'learning_rate': 0.00017303030303030304, 'epoch': 0.01}\n",
      "{'loss': 0.694, 'learning_rate': 0.00017292929292929293, 'epoch': 0.01}\n",
      "{'loss': 0.6918, 'learning_rate': 0.00017282828282828283, 'epoch': 0.01}\n",
      "{'loss': 0.6655, 'learning_rate': 0.00017272727272727275, 'epoch': 0.01}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c79c568e29a7488f8d6b195d7c86edba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6851793527603149, 'eval_runtime': 12.0138, 'eval_samples_per_second': 20.809, 'eval_steps_per_second': 3.496, 'epoch': 0.01}\n",
      "{'loss': 0.7094, 'learning_rate': 0.0001726262626262626, 'epoch': 0.01}\n",
      "{'loss': 0.6565, 'learning_rate': 0.00017252525252525253, 'epoch': 0.01}\n",
      "{'loss': 0.7497, 'learning_rate': 0.00017242424242424242, 'epoch': 0.01}\n",
      "{'loss': 0.7017, 'learning_rate': 0.00017232323232323232, 'epoch': 0.01}\n",
      "{'loss': 0.6768, 'learning_rate': 0.00017222222222222224, 'epoch': 0.01}\n",
      "{'loss': 0.6558, 'learning_rate': 0.00017212121212121213, 'epoch': 0.01}\n",
      "{'loss': 0.6697, 'learning_rate': 0.00017202020202020205, 'epoch': 0.01}\n",
      "{'loss': 0.6237, 'learning_rate': 0.00017191919191919192, 'epoch': 0.01}\n",
      "{'loss': 0.678, 'learning_rate': 0.00017181818181818184, 'epoch': 0.01}\n",
      "{'loss': 0.6243, 'learning_rate': 0.00017171717171717173, 'epoch': 0.01}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c531f6937b4140d99122247b4f8b3566",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6889166235923767, 'eval_runtime': 12.0033, 'eval_samples_per_second': 20.828, 'eval_steps_per_second': 3.499, 'epoch': 0.01}\n",
      "{'loss': 0.7274, 'learning_rate': 0.00017161616161616162, 'epoch': 0.01}\n",
      "{'loss': 0.7691, 'learning_rate': 0.0001715151515151515, 'epoch': 0.01}\n",
      "{'loss': 0.7915, 'learning_rate': 0.00017141414141414143, 'epoch': 0.01}\n",
      "{'loss': 0.6689, 'learning_rate': 0.00017131313131313133, 'epoch': 0.01}\n",
      "{'loss': 0.723, 'learning_rate': 0.00017121212121212122, 'epoch': 0.01}\n",
      "{'loss': 0.6936, 'learning_rate': 0.0001711111111111111, 'epoch': 0.01}\n",
      "{'loss': 0.7991, 'learning_rate': 0.00017101010101010103, 'epoch': 0.01}\n",
      "{'loss': 0.7206, 'learning_rate': 0.0001709090909090909, 'epoch': 0.01}\n",
      "{'loss': 0.7077, 'learning_rate': 0.00017080808080808082, 'epoch': 0.01}\n",
      "{'loss': 0.706, 'learning_rate': 0.0001707070707070707, 'epoch': 0.01}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eb68600470748a6a39453b0f4f136c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6864758133888245, 'eval_runtime': 12.0174, 'eval_samples_per_second': 20.803, 'eval_steps_per_second': 3.495, 'epoch': 0.01}\n",
      "{'loss': 0.7346, 'learning_rate': 0.0001706060606060606, 'epoch': 0.01}\n",
      "{'loss': 0.72, 'learning_rate': 0.00017050505050505052, 'epoch': 0.01}\n",
      "{'loss': 0.6973, 'learning_rate': 0.00017040404040404041, 'epoch': 0.02}\n",
      "{'loss': 0.7834, 'learning_rate': 0.0001703030303030303, 'epoch': 0.02}\n",
      "{'loss': 0.6781, 'learning_rate': 0.0001702020202020202, 'epoch': 0.02}\n",
      "{'loss': 0.7401, 'learning_rate': 0.00017010101010101012, 'epoch': 0.02}\n",
      "{'loss': 0.7101, 'learning_rate': 0.00017, 'epoch': 0.02}\n",
      "{'loss': 0.7107, 'learning_rate': 0.0001698989898989899, 'epoch': 0.02}\n",
      "{'loss': 0.6299, 'learning_rate': 0.0001697979797979798, 'epoch': 0.02}\n",
      "{'loss': 0.7602, 'learning_rate': 0.00016969696969696972, 'epoch': 0.02}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55a68dba0afa4fffa07052cca1d27aa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6830678582191467, 'eval_runtime': 12.0091, 'eval_samples_per_second': 20.818, 'eval_steps_per_second': 3.497, 'epoch': 0.02}\n",
      "{'loss': 0.7227, 'learning_rate': 0.0001695959595959596, 'epoch': 0.02}\n",
      "{'loss': 0.7021, 'learning_rate': 0.0001694949494949495, 'epoch': 0.02}\n",
      "{'loss': 0.6414, 'learning_rate': 0.0001693939393939394, 'epoch': 0.02}\n",
      "{'loss': 0.6766, 'learning_rate': 0.00016929292929292932, 'epoch': 0.02}\n",
      "{'loss': 0.7154, 'learning_rate': 0.00016919191919191918, 'epoch': 0.02}\n",
      "{'loss': 0.6642, 'learning_rate': 0.0001690909090909091, 'epoch': 0.02}\n",
      "{'loss': 0.7099, 'learning_rate': 0.000168989898989899, 'epoch': 0.02}\n",
      "{'loss': 0.7221, 'learning_rate': 0.00016888888888888889, 'epoch': 0.02}\n",
      "{'loss': 0.6718, 'learning_rate': 0.0001687878787878788, 'epoch': 0.02}\n",
      "{'loss': 0.7197, 'learning_rate': 0.0001686868686868687, 'epoch': 0.02}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f93616517fc4d8b8bd43cd60c611a4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6808726787567139, 'eval_runtime': 12.0053, 'eval_samples_per_second': 20.824, 'eval_steps_per_second': 3.498, 'epoch': 0.02}\n",
      "{'loss': 0.695, 'learning_rate': 0.0001685858585858586, 'epoch': 0.02}\n",
      "{'loss': 0.7073, 'learning_rate': 0.00016848484848484848, 'epoch': 0.02}\n",
      "{'loss': 0.7045, 'learning_rate': 0.0001683838383838384, 'epoch': 0.02}\n",
      "{'loss': 0.6604, 'learning_rate': 0.0001682828282828283, 'epoch': 0.02}\n",
      "{'loss': 0.6671, 'learning_rate': 0.0001681818181818182, 'epoch': 0.02}\n",
      "{'loss': 0.7193, 'learning_rate': 0.00016808080808080808, 'epoch': 0.02}\n",
      "{'loss': 0.7165, 'learning_rate': 0.000167979797979798, 'epoch': 0.02}\n",
      "{'loss': 0.6623, 'learning_rate': 0.00016787878787878787, 'epoch': 0.02}\n",
      "{'loss': 0.6379, 'learning_rate': 0.0001677777777777778, 'epoch': 0.02}\n",
      "{'loss': 0.6874, 'learning_rate': 0.00016767676767676768, 'epoch': 0.02}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "526c87d590a14e6ab4e53912ebad7404",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6817160844802856, 'eval_runtime': 12.0153, 'eval_samples_per_second': 20.807, 'eval_steps_per_second': 3.496, 'epoch': 0.02}\n",
      "{'loss': 0.6891, 'learning_rate': 0.00016757575757575757, 'epoch': 0.02}\n",
      "{'loss': 0.711, 'learning_rate': 0.00016747474747474747, 'epoch': 0.02}\n",
      "{'loss': 0.6883, 'learning_rate': 0.00016737373737373739, 'epoch': 0.02}\n",
      "{'loss': 0.6378, 'learning_rate': 0.00016727272727272728, 'epoch': 0.02}\n",
      "{'loss': 0.6993, 'learning_rate': 0.00016717171717171717, 'epoch': 0.02}\n",
      "{'loss': 0.6692, 'learning_rate': 0.0001670707070707071, 'epoch': 0.02}\n",
      "{'loss': 0.6256, 'learning_rate': 0.00016696969696969698, 'epoch': 0.02}\n",
      "{'loss': 0.672, 'learning_rate': 0.00016686868686868688, 'epoch': 0.02}\n",
      "{'loss': 0.6436, 'learning_rate': 0.00016676767676767677, 'epoch': 0.02}\n",
      "{'loss': 0.62, 'learning_rate': 0.0001666666666666667, 'epoch': 0.02}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43ae2084707349659da7f57392243b8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.683788001537323, 'eval_runtime': 12.0058, 'eval_samples_per_second': 20.823, 'eval_steps_per_second': 3.498, 'epoch': 0.02}\n",
      "{'loss': 0.6627, 'learning_rate': 0.00016656565656565658, 'epoch': 0.02}\n",
      "{'loss': 0.6698, 'learning_rate': 0.00016646464646464647, 'epoch': 0.02}\n",
      "{'loss': 0.7664, 'learning_rate': 0.00016636363636363637, 'epoch': 0.02}\n",
      "{'loss': 0.7731, 'learning_rate': 0.00016626262626262629, 'epoch': 0.02}\n",
      "{'loss': 0.7252, 'learning_rate': 0.00016616161616161615, 'epoch': 0.02}\n",
      "{'loss': 0.7621, 'learning_rate': 0.00016606060606060607, 'epoch': 0.02}\n",
      "{'loss': 0.6998, 'learning_rate': 0.00016595959595959596, 'epoch': 0.02}\n",
      "{'loss': 0.7141, 'learning_rate': 0.00016585858585858586, 'epoch': 0.02}\n",
      "{'loss': 0.7103, 'learning_rate': 0.00016575757575757575, 'epoch': 0.02}\n",
      "{'loss': 0.784, 'learning_rate': 0.00016565656565656567, 'epoch': 0.02}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f6e231392b846c8af8b8e351045e1a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6832106709480286, 'eval_runtime': 11.9731, 'eval_samples_per_second': 20.88, 'eval_steps_per_second': 3.508, 'epoch': 0.02}\n",
      "{'loss': 0.7129, 'learning_rate': 0.00016555555555555556, 'epoch': 0.02}\n",
      "{'loss': 0.7213, 'learning_rate': 0.00016545454545454545, 'epoch': 0.02}\n",
      "{'loss': 0.7102, 'learning_rate': 0.00016535353535353537, 'epoch': 0.02}\n",
      "{'loss': 0.6657, 'learning_rate': 0.00016525252525252527, 'epoch': 0.02}\n",
      "{'loss': 0.6918, 'learning_rate': 0.00016515151515151516, 'epoch': 0.02}\n",
      "{'loss': 0.7149, 'learning_rate': 0.00016505050505050505, 'epoch': 0.02}\n",
      "{'loss': 0.7177, 'learning_rate': 0.00016494949494949497, 'epoch': 0.02}\n",
      "{'loss': 0.6782, 'learning_rate': 0.00016484848484848487, 'epoch': 0.02}\n",
      "{'loss': 0.6481, 'learning_rate': 0.00016474747474747476, 'epoch': 0.02}\n",
      "{'loss': 0.6935, 'learning_rate': 0.00016464646464646465, 'epoch': 0.02}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f72222af3ef04420829b2d76eb59cafd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6794133186340332, 'eval_runtime': 11.9901, 'eval_samples_per_second': 20.851, 'eval_steps_per_second': 3.503, 'epoch': 0.02}\n",
      "{'loss': 0.6624, 'learning_rate': 0.00016454545454545457, 'epoch': 0.02}\n",
      "{'loss': 0.7579, 'learning_rate': 0.00016444444444444444, 'epoch': 0.02}\n",
      "{'loss': 0.6599, 'learning_rate': 0.00016434343434343436, 'epoch': 0.02}\n",
      "{'loss': 0.6939, 'learning_rate': 0.00016424242424242425, 'epoch': 0.02}\n",
      "{'loss': 0.6743, 'learning_rate': 0.00016414141414141414, 'epoch': 0.02}\n",
      "{'loss': 0.7428, 'learning_rate': 0.00016404040404040403, 'epoch': 0.02}\n",
      "{'loss': 0.6998, 'learning_rate': 0.00016393939393939395, 'epoch': 0.02}\n",
      "{'loss': 0.6598, 'learning_rate': 0.00016383838383838385, 'epoch': 0.02}\n",
      "{'loss': 0.7221, 'learning_rate': 0.00016373737373737374, 'epoch': 0.02}\n",
      "{'loss': 0.719, 'learning_rate': 0.00016363636363636366, 'epoch': 0.02}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a897e04604f742839b092ed8bdab98b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6785213351249695, 'eval_runtime': 11.9943, 'eval_samples_per_second': 20.843, 'eval_steps_per_second': 3.502, 'epoch': 0.02}\n",
      "{'loss': 0.6572, 'learning_rate': 0.00016353535353535355, 'epoch': 0.02}\n",
      "{'loss': 0.6719, 'learning_rate': 0.00016343434343434344, 'epoch': 0.02}\n",
      "{'loss': 0.7004, 'learning_rate': 0.00016333333333333334, 'epoch': 0.02}\n",
      "{'loss': 0.6737, 'learning_rate': 0.00016323232323232326, 'epoch': 0.02}\n",
      "{'loss': 0.6586, 'learning_rate': 0.00016313131313131312, 'epoch': 0.02}\n",
      "{'loss': 0.7247, 'learning_rate': 0.00016303030303030304, 'epoch': 0.02}\n",
      "{'loss': 0.6708, 'learning_rate': 0.00016292929292929294, 'epoch': 0.02}\n",
      "{'loss': 0.6803, 'learning_rate': 0.00016282828282828283, 'epoch': 0.02}\n",
      "{'loss': 0.6421, 'learning_rate': 0.00016272727272727272, 'epoch': 0.02}\n",
      "{'loss': 0.6697, 'learning_rate': 0.00016262626262626264, 'epoch': 0.02}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0bcd445766c423883b2a92a46cb6054",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6785171031951904, 'eval_runtime': 11.9941, 'eval_samples_per_second': 20.844, 'eval_steps_per_second': 3.502, 'epoch': 0.02}\n",
      "{'loss': 0.6812, 'learning_rate': 0.00016252525252525253, 'epoch': 0.02}\n",
      "{'loss': 0.6198, 'learning_rate': 0.00016242424242424243, 'epoch': 0.02}\n",
      "{'loss': 0.6325, 'learning_rate': 0.00016232323232323232, 'epoch': 0.02}\n",
      "{'loss': 0.6347, 'learning_rate': 0.00016222222222222224, 'epoch': 0.02}\n",
      "{'loss': 0.6611, 'learning_rate': 0.00016212121212121213, 'epoch': 0.02}\n",
      "{'loss': 0.6732, 'learning_rate': 0.00016202020202020202, 'epoch': 0.02}\n",
      "{'loss': 0.6787, 'learning_rate': 0.00016191919191919194, 'epoch': 0.02}\n",
      "{'loss': 0.6247, 'learning_rate': 0.00016181818181818184, 'epoch': 0.02}\n",
      "{'loss': 0.6902, 'learning_rate': 0.00016171717171717173, 'epoch': 0.02}\n",
      "{'loss': 0.5996, 'learning_rate': 0.00016161616161616162, 'epoch': 0.02}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "474deb617c534c238787f2366a2f88e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6841033697128296, 'eval_runtime': 11.9964, 'eval_samples_per_second': 20.84, 'eval_steps_per_second': 3.501, 'epoch': 0.02}\n",
      "{'loss': 0.7067, 'learning_rate': 0.00016151515151515154, 'epoch': 0.02}\n",
      "{'loss': 0.6718, 'learning_rate': 0.0001614141414141414, 'epoch': 0.02}\n",
      "{'loss': 0.7306, 'learning_rate': 0.00016131313131313133, 'epoch': 0.02}\n",
      "{'loss': 0.7351, 'learning_rate': 0.00016121212121212122, 'epoch': 0.02}\n",
      "{'loss': 0.6542, 'learning_rate': 0.0001611111111111111, 'epoch': 0.02}\n",
      "{'loss': 0.7405, 'learning_rate': 0.000161010101010101, 'epoch': 0.02}\n",
      "{'loss': 0.7357, 'learning_rate': 0.00016090909090909092, 'epoch': 0.02}\n",
      "{'loss': 0.7347, 'learning_rate': 0.00016080808080808082, 'epoch': 0.02}\n",
      "{'loss': 0.7029, 'learning_rate': 0.0001607070707070707, 'epoch': 0.02}\n",
      "{'loss': 0.6415, 'learning_rate': 0.0001606060606060606, 'epoch': 0.02}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1775895cb26b4482908d8c659860fe44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6807562112808228, 'eval_runtime': 11.998, 'eval_samples_per_second': 20.837, 'eval_steps_per_second': 3.501, 'epoch': 0.02}\n",
      "{'loss': 0.6744, 'learning_rate': 0.00016050505050505052, 'epoch': 0.02}\n",
      "{'loss': 0.6796, 'learning_rate': 0.0001604040404040404, 'epoch': 0.02}\n",
      "{'loss': 0.7039, 'learning_rate': 0.0001603030303030303, 'epoch': 0.02}\n",
      "{'loss': 0.7183, 'learning_rate': 0.00016020202020202023, 'epoch': 0.02}\n",
      "{'loss': 0.6661, 'learning_rate': 0.00016010101010101012, 'epoch': 0.02}\n",
      "{'loss': 0.7023, 'learning_rate': 0.00016, 'epoch': 0.02}\n",
      "{'loss': 0.6815, 'learning_rate': 0.0001598989898989899, 'epoch': 0.02}\n",
      "{'loss': 0.6622, 'learning_rate': 0.00015979797979797983, 'epoch': 0.02}\n",
      "{'loss': 0.7244, 'learning_rate': 0.0001596969696969697, 'epoch': 0.02}\n",
      "{'loss': 0.7783, 'learning_rate': 0.0001595959595959596, 'epoch': 0.02}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51b5eee9e1524dcca899dea97da48cf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6775051355361938, 'eval_runtime': 12.01, 'eval_samples_per_second': 20.816, 'eval_steps_per_second': 3.497, 'epoch': 0.02}\n",
      "{'loss': 0.7302, 'learning_rate': 0.0001594949494949495, 'epoch': 0.02}\n",
      "{'loss': 0.6498, 'learning_rate': 0.0001593939393939394, 'epoch': 0.02}\n",
      "{'loss': 0.6671, 'learning_rate': 0.0001592929292929293, 'epoch': 0.02}\n",
      "{'loss': 0.7075, 'learning_rate': 0.0001591919191919192, 'epoch': 0.02}\n",
      "{'loss': 0.6473, 'learning_rate': 0.0001590909090909091, 'epoch': 0.02}\n",
      "{'loss': 0.6982, 'learning_rate': 0.000158989898989899, 'epoch': 0.02}\n",
      "{'loss': 0.7369, 'learning_rate': 0.0001588888888888889, 'epoch': 0.02}\n",
      "{'loss': 0.7099, 'learning_rate': 0.0001587878787878788, 'epoch': 0.02}\n",
      "{'loss': 0.6364, 'learning_rate': 0.00015868686868686867, 'epoch': 0.02}\n",
      "{'loss': 0.6875, 'learning_rate': 0.0001585858585858586, 'epoch': 0.02}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ea842096f814152bb838dcdc3957f42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6762484312057495, 'eval_runtime': 12.0073, 'eval_samples_per_second': 20.821, 'eval_steps_per_second': 3.498, 'epoch': 0.02}\n",
      "{'loss': 0.688, 'learning_rate': 0.0001584848484848485, 'epoch': 0.02}\n",
      "{'loss': 0.767, 'learning_rate': 0.00015838383838383838, 'epoch': 0.02}\n",
      "{'loss': 0.6632, 'learning_rate': 0.0001582828282828283, 'epoch': 0.02}\n",
      "{'loss': 0.6742, 'learning_rate': 0.0001581818181818182, 'epoch': 0.02}\n",
      "{'loss': 0.6592, 'learning_rate': 0.00015808080808080808, 'epoch': 0.02}\n",
      "{'loss': 0.6468, 'learning_rate': 0.00015797979797979798, 'epoch': 0.02}\n",
      "{'loss': 0.707, 'learning_rate': 0.0001578787878787879, 'epoch': 0.02}\n",
      "{'loss': 0.6087, 'learning_rate': 0.0001577777777777778, 'epoch': 0.02}\n",
      "{'loss': 0.5985, 'learning_rate': 0.00015767676767676768, 'epoch': 0.02}\n",
      "{'loss': 0.6839, 'learning_rate': 0.00015757575757575757, 'epoch': 0.02}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91dd30f01e304462b94f7a851516adfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6757301688194275, 'eval_runtime': 12.0032, 'eval_samples_per_second': 20.828, 'eval_steps_per_second': 3.499, 'epoch': 0.02}\n",
      "{'loss': 0.6669, 'learning_rate': 0.0001574747474747475, 'epoch': 0.02}\n",
      "{'loss': 0.6452, 'learning_rate': 0.00015737373737373739, 'epoch': 0.02}\n",
      "{'loss': 0.6662, 'learning_rate': 0.00015727272727272728, 'epoch': 0.02}\n",
      "{'loss': 0.6851, 'learning_rate': 0.00015717171717171717, 'epoch': 0.02}\n",
      "{'loss': 0.6821, 'learning_rate': 0.0001570707070707071, 'epoch': 0.02}\n",
      "{'loss': 0.7077, 'learning_rate': 0.00015696969696969696, 'epoch': 0.02}\n",
      "{'loss': 0.6866, 'learning_rate': 0.00015686868686868688, 'epoch': 0.02}\n",
      "{'loss': 0.6385, 'learning_rate': 0.0001567676767676768, 'epoch': 0.02}\n",
      "{'loss': 0.6895, 'learning_rate': 0.00015666666666666666, 'epoch': 0.02}\n",
      "{'loss': 0.6539, 'learning_rate': 0.00015656565656565658, 'epoch': 0.02}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8560ce98decb4687985766cd80d8dbdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6803193688392639, 'eval_runtime': 12.0187, 'eval_samples_per_second': 20.801, 'eval_steps_per_second': 3.495, 'epoch': 0.02}\n",
      "{'loss': 0.7164, 'learning_rate': 0.00015646464646464647, 'epoch': 0.02}\n",
      "{'loss': 0.7038, 'learning_rate': 0.00015636363636363637, 'epoch': 0.02}\n",
      "{'loss': 0.7059, 'learning_rate': 0.00015626262626262626, 'epoch': 0.02}\n",
      "{'loss': 0.6984, 'learning_rate': 0.00015616161616161618, 'epoch': 0.02}\n",
      "{'loss': 0.8129, 'learning_rate': 0.00015606060606060607, 'epoch': 0.02}\n",
      "{'loss': 0.6979, 'learning_rate': 0.00015595959595959597, 'epoch': 0.02}\n",
      "{'loss': 0.697, 'learning_rate': 0.00015585858585858586, 'epoch': 0.02}\n",
      "{'loss': 0.6638, 'learning_rate': 0.00015575757575757578, 'epoch': 0.02}\n",
      "{'loss': 0.717, 'learning_rate': 0.00015565656565656564, 'epoch': 0.02}\n",
      "{'loss': 0.6573, 'learning_rate': 0.00015555555555555556, 'epoch': 0.02}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8950978ad27540ee8df90bfa23df8874",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6774927377700806, 'eval_runtime': 12.0105, 'eval_samples_per_second': 20.815, 'eval_steps_per_second': 3.497, 'epoch': 0.02}\n",
      "{'loss': 0.7298, 'learning_rate': 0.00015545454545454546, 'epoch': 0.02}\n",
      "{'loss': 0.6494, 'learning_rate': 0.00015535353535353538, 'epoch': 0.02}\n",
      "{'loss': 0.6379, 'learning_rate': 0.00015525252525252524, 'epoch': 0.02}\n",
      "{'loss': 0.7057, 'learning_rate': 0.00015515151515151516, 'epoch': 0.02}\n",
      "{'loss': 0.6696, 'learning_rate': 0.00015505050505050508, 'epoch': 0.02}\n",
      "{'loss': 0.6689, 'learning_rate': 0.00015494949494949495, 'epoch': 0.02}\n",
      "{'loss': 0.709, 'learning_rate': 0.00015484848484848487, 'epoch': 0.02}\n",
      "{'loss': 0.6574, 'learning_rate': 0.00015474747474747476, 'epoch': 0.02}\n",
      "{'loss': 0.6919, 'learning_rate': 0.00015464646464646465, 'epoch': 0.02}\n",
      "{'loss': 0.6952, 'learning_rate': 0.00015454545454545454, 'epoch': 0.02}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5faf004512a1415190447046ad94bdc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6759976148605347, 'eval_runtime': 12.0164, 'eval_samples_per_second': 20.805, 'eval_steps_per_second': 3.495, 'epoch': 0.02}\n",
      "{'loss': 0.6444, 'learning_rate': 0.00015444444444444446, 'epoch': 0.02}\n",
      "{'loss': 0.7782, 'learning_rate': 0.00015434343434343436, 'epoch': 0.02}\n",
      "{'loss': 0.6903, 'learning_rate': 0.00015424242424242425, 'epoch': 0.02}\n",
      "{'loss': 0.7149, 'learning_rate': 0.00015414141414141414, 'epoch': 0.02}\n",
      "{'loss': 0.7201, 'learning_rate': 0.00015404040404040406, 'epoch': 0.02}\n",
      "{'loss': 0.6903, 'learning_rate': 0.00015393939393939393, 'epoch': 0.02}\n",
      "{'loss': 0.6644, 'learning_rate': 0.00015383838383838385, 'epoch': 0.02}\n",
      "{'loss': 0.6028, 'learning_rate': 0.00015373737373737374, 'epoch': 0.02}\n",
      "{'loss': 0.6657, 'learning_rate': 0.00015363636363636363, 'epoch': 0.02}\n",
      "{'loss': 0.6398, 'learning_rate': 0.00015353535353535353, 'epoch': 0.02}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "949eda2df73044d7ba5995d6632d6003",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6739307641983032, 'eval_runtime': 12.0117, 'eval_samples_per_second': 20.813, 'eval_steps_per_second': 3.497, 'epoch': 0.02}\n",
      "{'loss': 0.696, 'learning_rate': 0.00015343434343434345, 'epoch': 0.02}\n",
      "{'loss': 0.6731, 'learning_rate': 0.00015333333333333334, 'epoch': 0.02}\n",
      "{'loss': 0.6472, 'learning_rate': 0.00015323232323232323, 'epoch': 0.02}\n",
      "{'loss': 0.692, 'learning_rate': 0.00015313131313131315, 'epoch': 0.02}\n",
      "{'loss': 0.715, 'learning_rate': 0.00015303030303030304, 'epoch': 0.02}\n",
      "{'loss': 0.7001, 'learning_rate': 0.00015292929292929294, 'epoch': 0.02}\n",
      "{'loss': 0.7071, 'learning_rate': 0.00015282828282828283, 'epoch': 0.02}\n",
      "{'loss': 0.7122, 'learning_rate': 0.00015272727272727275, 'epoch': 0.02}\n",
      "{'loss': 0.6859, 'learning_rate': 0.00015262626262626264, 'epoch': 0.02}\n",
      "{'loss': 0.7446, 'learning_rate': 0.00015252525252525253, 'epoch': 0.02}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32d48a79a50541feb88a6b2f78fbc2cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6742963790893555, 'eval_runtime': 12.0285, 'eval_samples_per_second': 20.784, 'eval_steps_per_second': 3.492, 'epoch': 0.02}\n",
      "{'loss': 0.6463, 'learning_rate': 0.00015242424242424243, 'epoch': 0.02}\n",
      "{'loss': 0.6611, 'learning_rate': 0.00015232323232323235, 'epoch': 0.02}\n",
      "{'loss': 0.6047, 'learning_rate': 0.0001522222222222222, 'epoch': 0.02}\n",
      "{'loss': 0.6681, 'learning_rate': 0.00015212121212121213, 'epoch': 0.02}\n",
      "{'loss': 0.6902, 'learning_rate': 0.00015202020202020202, 'epoch': 0.02}\n",
      "{'loss': 0.6568, 'learning_rate': 0.00015191919191919192, 'epoch': 0.02}\n",
      "{'loss': 0.6191, 'learning_rate': 0.0001518181818181818, 'epoch': 0.02}\n",
      "{'loss': 0.6515, 'learning_rate': 0.00015171717171717173, 'epoch': 0.02}\n",
      "{'loss': 0.7083, 'learning_rate': 0.00015161616161616162, 'epoch': 0.02}\n",
      "{'loss': 0.5876, 'learning_rate': 0.00015151515151515152, 'epoch': 0.02}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11d13bf1a50549eeaa71d84b5f2982a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6774261593818665, 'eval_runtime': 12.0099, 'eval_samples_per_second': 20.816, 'eval_steps_per_second': 3.497, 'epoch': 0.02}\n",
      "{'loss': 0.6451, 'learning_rate': 0.00015141414141414143, 'epoch': 0.02}\n",
      "{'loss': 0.6974, 'learning_rate': 0.00015131313131313133, 'epoch': 0.02}\n",
      "{'loss': 0.6931, 'learning_rate': 0.00015121212121212122, 'epoch': 0.02}\n",
      "{'loss': 0.694, 'learning_rate': 0.0001511111111111111, 'epoch': 0.02}\n",
      "{'loss': 0.7309, 'learning_rate': 0.00015101010101010103, 'epoch': 0.02}\n",
      "{'loss': 0.6582, 'learning_rate': 0.0001509090909090909, 'epoch': 0.02}\n",
      "{'loss': 0.7594, 'learning_rate': 0.00015080808080808082, 'epoch': 0.02}\n",
      "{'loss': 0.7073, 'learning_rate': 0.0001507070707070707, 'epoch': 0.02}\n",
      "{'loss': 0.7446, 'learning_rate': 0.00015060606060606063, 'epoch': 0.02}\n",
      "{'loss': 0.6245, 'learning_rate': 0.0001505050505050505, 'epoch': 0.02}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb00f04a9ba449d6a2684043432a5964",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6745975613594055, 'eval_runtime': 11.9941, 'eval_samples_per_second': 20.844, 'eval_steps_per_second': 3.502, 'epoch': 0.02}\n",
      "{'loss': 0.6703, 'learning_rate': 0.00015040404040404042, 'epoch': 0.02}\n",
      "{'loss': 0.689, 'learning_rate': 0.0001503030303030303, 'epoch': 0.02}\n",
      "{'loss': 0.685, 'learning_rate': 0.0001502020202020202, 'epoch': 0.02}\n",
      "{'loss': 0.7082, 'learning_rate': 0.0001501010101010101, 'epoch': 0.02}\n",
      "{'loss': 0.7201, 'learning_rate': 0.00015000000000000001, 'epoch': 0.02}\n",
      "{'loss': 0.6884, 'learning_rate': 0.0001498989898989899, 'epoch': 0.02}\n",
      "{'loss': 0.7119, 'learning_rate': 0.0001497979797979798, 'epoch': 0.02}\n",
      "{'loss': 0.6901, 'learning_rate': 0.00014969696969696972, 'epoch': 0.02}\n",
      "{'loss': 0.6834, 'learning_rate': 0.0001495959595959596, 'epoch': 0.02}\n",
      "{'loss': 0.6572, 'learning_rate': 0.0001494949494949495, 'epoch': 0.02}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5b7a391e12f4de289b94eec8e741f5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6746629476547241, 'eval_runtime': 11.9719, 'eval_samples_per_second': 20.882, 'eval_steps_per_second': 3.508, 'epoch': 0.02}\n",
      "{'loss': 0.6736, 'learning_rate': 0.0001493939393939394, 'epoch': 0.03}\n",
      "{'loss': 0.6953, 'learning_rate': 0.00014929292929292932, 'epoch': 0.03}\n",
      "{'loss': 0.7031, 'learning_rate': 0.00014919191919191918, 'epoch': 0.03}\n",
      "{'loss': 0.643, 'learning_rate': 0.0001490909090909091, 'epoch': 0.03}\n",
      "{'loss': 0.6523, 'learning_rate': 0.000148989898989899, 'epoch': 0.03}\n",
      "{'loss': 0.6974, 'learning_rate': 0.0001488888888888889, 'epoch': 0.03}\n",
      "{'loss': 0.7143, 'learning_rate': 0.00014878787878787878, 'epoch': 0.03}\n",
      "{'loss': 0.6635, 'learning_rate': 0.0001486868686868687, 'epoch': 0.03}\n",
      "{'loss': 0.7233, 'learning_rate': 0.0001485858585858586, 'epoch': 0.03}\n",
      "{'loss': 0.6488, 'learning_rate': 0.00014848484848484849, 'epoch': 0.03}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1552429ebd4049d5be54d2d4a11677e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6726515293121338, 'eval_runtime': 11.9905, 'eval_samples_per_second': 20.85, 'eval_steps_per_second': 3.503, 'epoch': 0.03}\n",
      "{'loss': 0.6463, 'learning_rate': 0.00014838383838383838, 'epoch': 0.03}\n",
      "{'loss': 0.7172, 'learning_rate': 0.0001482828282828283, 'epoch': 0.03}\n",
      "{'loss': 0.6863, 'learning_rate': 0.0001481818181818182, 'epoch': 0.03}\n",
      "{'loss': 0.6756, 'learning_rate': 0.00014808080808080808, 'epoch': 0.03}\n",
      "{'loss': 0.6558, 'learning_rate': 0.000147979797979798, 'epoch': 0.03}\n",
      "{'loss': 0.7206, 'learning_rate': 0.0001478787878787879, 'epoch': 0.03}\n",
      "{'loss': 0.6659, 'learning_rate': 0.0001477777777777778, 'epoch': 0.03}\n",
      "{'loss': 0.6701, 'learning_rate': 0.00014767676767676768, 'epoch': 0.03}\n",
      "{'loss': 0.6955, 'learning_rate': 0.0001475757575757576, 'epoch': 0.03}\n",
      "{'loss': 0.6479, 'learning_rate': 0.00014747474747474747, 'epoch': 0.03}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "296f3de268ad4f0787fc648d6aae63a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.672280490398407, 'eval_runtime': 12.0031, 'eval_samples_per_second': 20.828, 'eval_steps_per_second': 3.499, 'epoch': 0.03}\n",
      "{'loss': 0.6595, 'learning_rate': 0.0001473737373737374, 'epoch': 0.03}\n",
      "{'loss': 0.6946, 'learning_rate': 0.00014727272727272728, 'epoch': 0.03}\n",
      "{'loss': 0.6745, 'learning_rate': 0.00014717171717171717, 'epoch': 0.03}\n",
      "{'loss': 0.6916, 'learning_rate': 0.00014707070707070706, 'epoch': 0.03}\n",
      "{'loss': 0.7249, 'learning_rate': 0.00014696969696969698, 'epoch': 0.03}\n",
      "{'loss': 0.6129, 'learning_rate': 0.00014686868686868688, 'epoch': 0.03}\n",
      "{'loss': 0.6374, 'learning_rate': 0.00014676767676767677, 'epoch': 0.03}\n",
      "{'loss': 0.6863, 'learning_rate': 0.00014666666666666666, 'epoch': 0.03}\n",
      "{'loss': 0.681, 'learning_rate': 0.00014656565656565658, 'epoch': 0.03}\n",
      "{'loss': 0.6251, 'learning_rate': 0.00014646464646464648, 'epoch': 0.03}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63d399fdc262456a98a981ecdb8ab75d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6742619872093201, 'eval_runtime': 12.0035, 'eval_samples_per_second': 20.827, 'eval_steps_per_second': 3.499, 'epoch': 0.03}\n",
      "{'loss': 0.7435, 'learning_rate': 0.00014636363636363637, 'epoch': 0.03}\n",
      "{'loss': 0.6696, 'learning_rate': 0.0001462626262626263, 'epoch': 0.03}\n",
      "{'loss': 0.6436, 'learning_rate': 0.00014616161616161615, 'epoch': 0.03}\n",
      "{'loss': 0.6452, 'learning_rate': 0.00014606060606060607, 'epoch': 0.03}\n",
      "{'loss': 0.6753, 'learning_rate': 0.00014595959595959597, 'epoch': 0.03}\n",
      "{'loss': 0.7132, 'learning_rate': 0.00014585858585858586, 'epoch': 0.03}\n",
      "{'loss': 0.7021, 'learning_rate': 0.00014575757575757575, 'epoch': 0.03}\n",
      "{'loss': 0.7323, 'learning_rate': 0.00014565656565656567, 'epoch': 0.03}\n",
      "{'loss': 0.6794, 'learning_rate': 0.00014555555555555556, 'epoch': 0.03}\n",
      "{'loss': 0.6833, 'learning_rate': 0.00014545454545454546, 'epoch': 0.03}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe8260a4e91a46daa834daf035616f8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6713942289352417, 'eval_runtime': 12.0109, 'eval_samples_per_second': 20.814, 'eval_steps_per_second': 3.497, 'epoch': 0.03}\n",
      "{'loss': 0.7334, 'learning_rate': 0.00014535353535353535, 'epoch': 0.03}\n",
      "{'loss': 0.6994, 'learning_rate': 0.00014525252525252527, 'epoch': 0.03}\n",
      "{'loss': 0.7431, 'learning_rate': 0.00014515151515151516, 'epoch': 0.03}\n",
      "{'loss': 0.7323, 'learning_rate': 0.00014505050505050505, 'epoch': 0.03}\n",
      "{'loss': 0.5851, 'learning_rate': 0.00014494949494949495, 'epoch': 0.03}\n",
      "{'loss': 0.6935, 'learning_rate': 0.00014484848484848487, 'epoch': 0.03}\n",
      "{'loss': 0.7445, 'learning_rate': 0.00014474747474747476, 'epoch': 0.03}\n",
      "{'loss': 0.6876, 'learning_rate': 0.00014464646464646465, 'epoch': 0.03}\n",
      "{'loss': 0.6812, 'learning_rate': 0.00014454545454545457, 'epoch': 0.03}\n",
      "{'loss': 0.7422, 'learning_rate': 0.00014444444444444444, 'epoch': 0.03}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5ead9b16260466da511cfd7e1f92fc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6733337640762329, 'eval_runtime': 12.0067, 'eval_samples_per_second': 20.822, 'eval_steps_per_second': 3.498, 'epoch': 0.03}\n",
      "{'loss': 0.6766, 'learning_rate': 0.00014434343434343436, 'epoch': 0.03}\n",
      "{'loss': 0.6076, 'learning_rate': 0.00014424242424242425, 'epoch': 0.03}\n",
      "{'loss': 0.6268, 'learning_rate': 0.00014414141414141414, 'epoch': 0.03}\n",
      "{'loss': 0.6769, 'learning_rate': 0.00014404040404040404, 'epoch': 0.03}\n",
      "{'loss': 0.677, 'learning_rate': 0.00014393939393939396, 'epoch': 0.03}\n",
      "{'loss': 0.7233, 'learning_rate': 0.00014383838383838385, 'epoch': 0.03}\n",
      "{'loss': 0.6548, 'learning_rate': 0.00014373737373737374, 'epoch': 0.03}\n",
      "{'loss': 0.6805, 'learning_rate': 0.00014363636363636363, 'epoch': 0.03}\n",
      "{'loss': 0.7241, 'learning_rate': 0.00014353535353535355, 'epoch': 0.03}\n",
      "{'loss': 0.6461, 'learning_rate': 0.00014343434343434342, 'epoch': 0.03}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8229ff86ef1460fbb353390098810ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6707108020782471, 'eval_runtime': 12.0046, 'eval_samples_per_second': 20.825, 'eval_steps_per_second': 3.499, 'epoch': 0.03}\n",
      "{'loss': 0.6226, 'learning_rate': 0.00014333333333333334, 'epoch': 0.03}\n",
      "{'loss': 0.7085, 'learning_rate': 0.00014323232323232323, 'epoch': 0.03}\n",
      "{'loss': 0.7399, 'learning_rate': 0.00014313131313131315, 'epoch': 0.03}\n",
      "{'loss': 0.6816, 'learning_rate': 0.00014303030303030304, 'epoch': 0.03}\n",
      "{'loss': 0.6815, 'learning_rate': 0.00014292929292929294, 'epoch': 0.03}\n",
      "{'loss': 0.6907, 'learning_rate': 0.00014282828282828286, 'epoch': 0.03}\n",
      "{'loss': 0.6942, 'learning_rate': 0.00014272727272727272, 'epoch': 0.03}\n",
      "{'loss': 0.6728, 'learning_rate': 0.00014262626262626264, 'epoch': 0.03}\n",
      "{'loss': 0.6198, 'learning_rate': 0.00014252525252525253, 'epoch': 0.03}\n",
      "{'loss': 0.6665, 'learning_rate': 0.00014242424242424243, 'epoch': 0.03}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7ec1e9100164e4f91f63e4c30edfda4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6704276204109192, 'eval_runtime': 12.0095, 'eval_samples_per_second': 20.817, 'eval_steps_per_second': 3.497, 'epoch': 0.03}\n",
      "{'loss': 0.695, 'learning_rate': 0.00014232323232323232, 'epoch': 0.03}\n",
      "{'loss': 0.6341, 'learning_rate': 0.00014222222222222224, 'epoch': 0.03}\n",
      "{'loss': 0.7516, 'learning_rate': 0.00014212121212121213, 'epoch': 0.03}\n",
      "{'loss': 0.6064, 'learning_rate': 0.00014202020202020203, 'epoch': 0.03}\n",
      "{'loss': 0.647, 'learning_rate': 0.00014191919191919192, 'epoch': 0.03}\n",
      "{'loss': 0.6825, 'learning_rate': 0.00014181818181818184, 'epoch': 0.03}\n",
      "{'loss': 0.665, 'learning_rate': 0.0001417171717171717, 'epoch': 0.03}\n",
      "{'loss': 0.6421, 'learning_rate': 0.00014161616161616162, 'epoch': 0.03}\n",
      "{'loss': 0.6814, 'learning_rate': 0.00014151515151515152, 'epoch': 0.03}\n",
      "{'loss': 0.6304, 'learning_rate': 0.0001414141414141414, 'epoch': 0.03}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be4413eae8c249da9304c5bf9980e320",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6736153364181519, 'eval_runtime': 12.0115, 'eval_samples_per_second': 20.813, 'eval_steps_per_second': 3.497, 'epoch': 0.03}\n",
      "{'loss': 0.7867, 'learning_rate': 0.00014131313131313133, 'epoch': 0.03}\n",
      "{'loss': 0.6245, 'learning_rate': 0.00014121212121212122, 'epoch': 0.03}\n",
      "{'loss': 0.7, 'learning_rate': 0.00014111111111111111, 'epoch': 0.03}\n",
      "{'loss': 0.6842, 'learning_rate': 0.000141010101010101, 'epoch': 0.03}\n",
      "{'loss': 0.671, 'learning_rate': 0.00014090909090909093, 'epoch': 0.03}\n",
      "{'loss': 0.7103, 'learning_rate': 0.00014080808080808082, 'epoch': 0.03}\n",
      "{'loss': 0.6741, 'learning_rate': 0.0001407070707070707, 'epoch': 0.03}\n",
      "{'loss': 0.7725, 'learning_rate': 0.0001406060606060606, 'epoch': 0.03}\n",
      "{'loss': 0.7304, 'learning_rate': 0.00014050505050505052, 'epoch': 0.03}\n",
      "{'loss': 0.6823, 'learning_rate': 0.00014040404040404042, 'epoch': 0.03}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec6410c81bc340c19b244286552f39b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6702815294265747, 'eval_runtime': 12.0126, 'eval_samples_per_second': 20.811, 'eval_steps_per_second': 3.496, 'epoch': 0.03}\n",
      "{'loss': 0.6622, 'learning_rate': 0.0001403030303030303, 'epoch': 0.03}\n",
      "{'loss': 0.6985, 'learning_rate': 0.0001402020202020202, 'epoch': 0.03}\n",
      "{'loss': 0.6793, 'learning_rate': 0.00014010101010101012, 'epoch': 0.03}\n",
      "{'loss': 0.6543, 'learning_rate': 0.00014, 'epoch': 0.03}\n",
      "{'loss': 0.7037, 'learning_rate': 0.0001398989898989899, 'epoch': 0.03}\n",
      "{'loss': 0.7235, 'learning_rate': 0.0001397979797979798, 'epoch': 0.03}\n",
      "{'loss': 0.6933, 'learning_rate': 0.0001396969696969697, 'epoch': 0.03}\n",
      "{'loss': 0.6481, 'learning_rate': 0.0001395959595959596, 'epoch': 0.03}\n",
      "{'loss': 0.8145, 'learning_rate': 0.0001394949494949495, 'epoch': 0.03}\n",
      "{'loss': 0.7579, 'learning_rate': 0.0001393939393939394, 'epoch': 0.03}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c900392e40b4485da9249e0b75b5d34f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6719992160797119, 'eval_runtime': 12.0176, 'eval_samples_per_second': 20.803, 'eval_steps_per_second': 3.495, 'epoch': 0.03}\n",
      "{'loss': 0.7657, 'learning_rate': 0.0001392929292929293, 'epoch': 0.03}\n",
      "{'loss': 0.6942, 'learning_rate': 0.0001391919191919192, 'epoch': 0.03}\n",
      "{'loss': 0.692, 'learning_rate': 0.0001390909090909091, 'epoch': 0.03}\n",
      "{'loss': 0.6891, 'learning_rate': 0.000138989898989899, 'epoch': 0.03}\n",
      "{'loss': 0.7204, 'learning_rate': 0.0001388888888888889, 'epoch': 0.03}\n",
      "{'loss': 0.6643, 'learning_rate': 0.0001387878787878788, 'epoch': 0.03}\n",
      "{'loss': 0.7562, 'learning_rate': 0.00013868686868686867, 'epoch': 0.03}\n",
      "{'loss': 0.6854, 'learning_rate': 0.0001385858585858586, 'epoch': 0.03}\n",
      "{'loss': 0.6628, 'learning_rate': 0.0001384848484848485, 'epoch': 0.03}\n",
      "{'loss': 0.6838, 'learning_rate': 0.0001383838383838384, 'epoch': 0.03}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f9c12f0511d43299e188b66d5522b88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6692193746566772, 'eval_runtime': 12.0193, 'eval_samples_per_second': 20.8, 'eval_steps_per_second': 3.494, 'epoch': 0.03}\n",
      "{'loss': 0.6857, 'learning_rate': 0.00013828282828282827, 'epoch': 0.03}\n",
      "{'loss': 0.6526, 'learning_rate': 0.0001381818181818182, 'epoch': 0.03}\n",
      "{'loss': 0.6445, 'learning_rate': 0.00013808080808080808, 'epoch': 0.03}\n",
      "{'loss': 0.649, 'learning_rate': 0.00013797979797979798, 'epoch': 0.03}\n",
      "{'loss': 0.7325, 'learning_rate': 0.0001378787878787879, 'epoch': 0.03}\n",
      "{'loss': 0.6757, 'learning_rate': 0.0001377777777777778, 'epoch': 0.03}\n",
      "{'loss': 0.6423, 'learning_rate': 0.00013767676767676768, 'epoch': 0.03}\n",
      "{'loss': 0.6765, 'learning_rate': 0.00013757575757575758, 'epoch': 0.03}\n",
      "{'loss': 0.7231, 'learning_rate': 0.0001374747474747475, 'epoch': 0.03}\n",
      "{'loss': 0.6599, 'learning_rate': 0.0001373737373737374, 'epoch': 0.03}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dfa302369e941979e2a1bbd14fde6e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6695619821548462, 'eval_runtime': 12.0192, 'eval_samples_per_second': 20.8, 'eval_steps_per_second': 3.494, 'epoch': 0.03}\n",
      "{'loss': 0.6346, 'learning_rate': 0.00013727272727272728, 'epoch': 0.03}\n",
      "{'loss': 0.6389, 'learning_rate': 0.00013717171717171717, 'epoch': 0.03}\n",
      "{'loss': 0.5836, 'learning_rate': 0.0001370707070707071, 'epoch': 0.03}\n",
      "{'loss': 0.6297, 'learning_rate': 0.00013696969696969696, 'epoch': 0.03}\n",
      "{'loss': 0.6378, 'learning_rate': 0.00013686868686868688, 'epoch': 0.03}\n",
      "{'loss': 0.6911, 'learning_rate': 0.00013676767676767677, 'epoch': 0.03}\n",
      "{'loss': 0.6423, 'learning_rate': 0.00013666666666666666, 'epoch': 0.03}\n",
      "{'loss': 0.6553, 'learning_rate': 0.00013656565656565656, 'epoch': 0.03}\n",
      "{'loss': 0.6419, 'learning_rate': 0.00013646464646464648, 'epoch': 0.03}\n",
      "{'loss': 0.6182, 'learning_rate': 0.00013636363636363637, 'epoch': 0.03}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b874150e3bf2418280d873424393d507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6725505590438843, 'eval_runtime': 12.0285, 'eval_samples_per_second': 20.784, 'eval_steps_per_second': 3.492, 'epoch': 0.03}\n",
      "{'loss': 0.7137, 'learning_rate': 0.00013626262626262626, 'epoch': 0.03}\n",
      "{'loss': 0.7409, 'learning_rate': 0.00013616161616161618, 'epoch': 0.03}\n",
      "{'loss': 0.6932, 'learning_rate': 0.00013606060606060607, 'epoch': 0.03}\n",
      "{'loss': 0.6622, 'learning_rate': 0.00013595959595959597, 'epoch': 0.03}\n",
      "{'loss': 0.6667, 'learning_rate': 0.00013585858585858586, 'epoch': 0.03}\n",
      "{'loss': 0.6615, 'learning_rate': 0.00013575757575757578, 'epoch': 0.03}\n",
      "{'loss': 0.7058, 'learning_rate': 0.00013565656565656567, 'epoch': 0.03}\n",
      "{'loss': 0.7624, 'learning_rate': 0.00013555555555555556, 'epoch': 0.03}\n",
      "{'loss': 0.6851, 'learning_rate': 0.00013545454545454546, 'epoch': 0.03}\n",
      "{'loss': 0.7533, 'learning_rate': 0.00013535353535353538, 'epoch': 0.03}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdc0d049c42f48beb3735135436424dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6699584722518921, 'eval_runtime': 12.0234, 'eval_samples_per_second': 20.793, 'eval_steps_per_second': 3.493, 'epoch': 0.03}\n",
      "{'loss': 0.7663, 'learning_rate': 0.00013525252525252524, 'epoch': 0.03}\n",
      "{'loss': 0.6513, 'learning_rate': 0.00013515151515151516, 'epoch': 0.03}\n",
      "{'loss': 0.7359, 'learning_rate': 0.00013505050505050506, 'epoch': 0.03}\n",
      "{'loss': 0.6735, 'learning_rate': 0.00013494949494949495, 'epoch': 0.03}\n",
      "{'loss': 0.719, 'learning_rate': 0.00013484848484848484, 'epoch': 0.03}\n",
      "{'loss': 0.6877, 'learning_rate': 0.00013474747474747476, 'epoch': 0.03}\n",
      "{'loss': 0.7863, 'learning_rate': 0.00013464646464646465, 'epoch': 0.03}\n",
      "{'loss': 0.7568, 'learning_rate': 0.00013454545454545455, 'epoch': 0.03}\n",
      "{'loss': 0.6639, 'learning_rate': 0.00013444444444444447, 'epoch': 0.03}\n",
      "{'loss': 0.7087, 'learning_rate': 0.00013434343434343436, 'epoch': 0.03}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "245d521191fa4a71b36d09f551ad557c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6700965762138367, 'eval_runtime': 11.9941, 'eval_samples_per_second': 20.844, 'eval_steps_per_second': 3.502, 'epoch': 0.03}\n",
      "{'loss': 0.717, 'learning_rate': 0.00013424242424242425, 'epoch': 0.03}\n",
      "{'loss': 0.6901, 'learning_rate': 0.00013414141414141414, 'epoch': 0.03}\n",
      "{'loss': 0.687, 'learning_rate': 0.00013404040404040406, 'epoch': 0.03}\n",
      "{'loss': 0.7273, 'learning_rate': 0.00013393939393939393, 'epoch': 0.03}\n",
      "{'loss': 0.6669, 'learning_rate': 0.00013383838383838385, 'epoch': 0.03}\n",
      "{'loss': 0.6907, 'learning_rate': 0.00013373737373737374, 'epoch': 0.03}\n",
      "{'loss': 0.6952, 'learning_rate': 0.00013363636363636366, 'epoch': 0.03}\n",
      "{'loss': 0.7357, 'learning_rate': 0.00013353535353535353, 'epoch': 0.03}\n",
      "{'loss': 0.7073, 'learning_rate': 0.00013343434343434345, 'epoch': 0.03}\n",
      "{'loss': 0.699, 'learning_rate': 0.00013333333333333334, 'epoch': 0.03}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "532f67d7a00441b580c782d9462f38ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6681568026542664, 'eval_runtime': 11.9767, 'eval_samples_per_second': 20.874, 'eval_steps_per_second': 3.507, 'epoch': 0.03}\n",
      "{'loss': 0.6956, 'learning_rate': 0.00013323232323232323, 'epoch': 0.03}\n",
      "{'loss': 0.6142, 'learning_rate': 0.00013313131313131313, 'epoch': 0.03}\n",
      "{'loss': 0.6753, 'learning_rate': 0.00013303030303030304, 'epoch': 0.03}\n",
      "{'loss': 0.6964, 'learning_rate': 0.00013292929292929294, 'epoch': 0.03}\n",
      "{'loss': 0.6414, 'learning_rate': 0.00013282828282828283, 'epoch': 0.03}\n",
      "{'loss': 0.6707, 'learning_rate': 0.00013272727272727275, 'epoch': 0.03}\n",
      "{'loss': 0.6754, 'learning_rate': 0.00013262626262626264, 'epoch': 0.03}\n",
      "{'loss': 0.6543, 'learning_rate': 0.00013252525252525254, 'epoch': 0.03}\n",
      "{'loss': 0.6609, 'learning_rate': 0.00013242424242424243, 'epoch': 0.03}\n",
      "{'loss': 0.6961, 'learning_rate': 0.00013232323232323235, 'epoch': 0.03}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb30213d70c24b3f91f4d511554135d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6683374047279358, 'eval_runtime': 11.9995, 'eval_samples_per_second': 20.834, 'eval_steps_per_second': 3.5, 'epoch': 0.03}\n",
      "{'loss': 0.6379, 'learning_rate': 0.00013222222222222221, 'epoch': 0.03}\n",
      "{'loss': 0.6621, 'learning_rate': 0.00013212121212121213, 'epoch': 0.03}\n",
      "{'loss': 0.6727, 'learning_rate': 0.00013202020202020203, 'epoch': 0.03}\n",
      "{'loss': 0.635, 'learning_rate': 0.00013191919191919192, 'epoch': 0.03}\n",
      "{'loss': 0.6448, 'learning_rate': 0.0001318181818181818, 'epoch': 0.03}\n",
      "{'loss': 0.6561, 'learning_rate': 0.00013171717171717173, 'epoch': 0.03}\n",
      "{'loss': 0.613, 'learning_rate': 0.00013161616161616162, 'epoch': 0.03}\n",
      "{'loss': 0.634, 'learning_rate': 0.00013151515151515152, 'epoch': 0.03}\n",
      "{'loss': 0.5916, 'learning_rate': 0.0001314141414141414, 'epoch': 0.03}\n",
      "{'loss': 0.6177, 'learning_rate': 0.00013131313131313133, 'epoch': 0.03}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf9d6f58001d4068be72b1ca87ecdc4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6714962124824524, 'eval_runtime': 12.0015, 'eval_samples_per_second': 20.831, 'eval_steps_per_second': 3.5, 'epoch': 0.03}\n",
      "{'loss': 0.7143, 'learning_rate': 0.00013121212121212122, 'epoch': 0.03}\n",
      "{'loss': 0.6574, 'learning_rate': 0.00013111111111111111, 'epoch': 0.03}\n",
      "{'loss': 0.7399, 'learning_rate': 0.00013101010101010103, 'epoch': 0.03}\n",
      "{'loss': 0.7335, 'learning_rate': 0.00013090909090909093, 'epoch': 0.03}\n",
      "{'loss': 0.6543, 'learning_rate': 0.00013080808080808082, 'epoch': 0.03}\n",
      "{'loss': 0.6643, 'learning_rate': 0.0001307070707070707, 'epoch': 0.03}\n",
      "{'loss': 0.721, 'learning_rate': 0.00013060606060606063, 'epoch': 0.03}\n",
      "{'loss': 0.6584, 'learning_rate': 0.0001305050505050505, 'epoch': 0.03}\n",
      "{'loss': 0.7637, 'learning_rate': 0.00013040404040404042, 'epoch': 0.03}\n",
      "{'loss': 0.6845, 'learning_rate': 0.0001303030303030303, 'epoch': 0.03}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89760bcf828f4b7084b5be1bef0d530f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6685135364532471, 'eval_runtime': 12.0122, 'eval_samples_per_second': 20.812, 'eval_steps_per_second': 3.496, 'epoch': 0.03}\n",
      "{'loss': 0.6691, 'learning_rate': 0.0001302020202020202, 'epoch': 0.03}\n",
      "{'loss': 0.6456, 'learning_rate': 0.0001301010101010101, 'epoch': 0.03}\n",
      "{'loss': 0.6672, 'learning_rate': 0.00013000000000000002, 'epoch': 0.03}\n",
      "{'loss': 0.6407, 'learning_rate': 0.0001298989898989899, 'epoch': 0.03}\n",
      "{'loss': 0.7231, 'learning_rate': 0.0001297979797979798, 'epoch': 0.03}\n",
      "{'loss': 0.7484, 'learning_rate': 0.0001296969696969697, 'epoch': 0.03}\n",
      "{'loss': 0.6612, 'learning_rate': 0.00012959595959595961, 'epoch': 0.03}\n",
      "{'loss': 0.7416, 'learning_rate': 0.00012949494949494948, 'epoch': 0.03}\n",
      "{'loss': 0.7108, 'learning_rate': 0.0001293939393939394, 'epoch': 0.03}\n",
      "{'loss': 0.6269, 'learning_rate': 0.00012929292929292932, 'epoch': 0.03}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0655d0e66c2f45518785fa49ee09ba14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6701716780662537, 'eval_runtime': 12.0146, 'eval_samples_per_second': 20.808, 'eval_steps_per_second': 3.496, 'epoch': 0.03}\n",
      "{'loss': 0.7083, 'learning_rate': 0.00012919191919191918, 'epoch': 0.03}\n",
      "{'loss': 0.7027, 'learning_rate': 0.0001290909090909091, 'epoch': 0.03}\n",
      "{'loss': 0.724, 'learning_rate': 0.000128989898989899, 'epoch': 0.03}\n",
      "{'loss': 0.7183, 'learning_rate': 0.00012888888888888892, 'epoch': 0.03}\n",
      "{'loss': 0.7845, 'learning_rate': 0.00012878787878787878, 'epoch': 0.03}\n",
      "{'loss': 0.6218, 'learning_rate': 0.0001286868686868687, 'epoch': 0.03}\n",
      "{'loss': 0.6458, 'learning_rate': 0.0001285858585858586, 'epoch': 0.03}\n",
      "{'loss': 0.6816, 'learning_rate': 0.0001284848484848485, 'epoch': 0.03}\n",
      "{'loss': 0.6737, 'learning_rate': 0.00012838383838383838, 'epoch': 0.04}\n",
      "{'loss': 0.634, 'learning_rate': 0.0001282828282828283, 'epoch': 0.04}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffce0c2de87c4835bacf1ef25e3e55fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6665512919425964, 'eval_runtime': 12.0264, 'eval_samples_per_second': 20.788, 'eval_steps_per_second': 3.492, 'epoch': 0.04}\n",
      "{'loss': 0.6264, 'learning_rate': 0.0001281818181818182, 'epoch': 0.04}\n",
      "{'loss': 0.6775, 'learning_rate': 0.00012808080808080809, 'epoch': 0.04}\n",
      "{'loss': 0.6521, 'learning_rate': 0.00012797979797979798, 'epoch': 0.04}\n",
      "{'loss': 0.656, 'learning_rate': 0.0001278787878787879, 'epoch': 0.04}\n",
      "{'loss': 0.6582, 'learning_rate': 0.00012777777777777776, 'epoch': 0.04}\n",
      "{'loss': 0.6429, 'learning_rate': 0.00012767676767676768, 'epoch': 0.04}\n",
      "{'loss': 0.6884, 'learning_rate': 0.0001275757575757576, 'epoch': 0.04}\n",
      "{'loss': 0.6326, 'learning_rate': 0.00012747474747474747, 'epoch': 0.04}\n",
      "{'loss': 0.6458, 'learning_rate': 0.0001273737373737374, 'epoch': 0.04}\n",
      "{'loss': 0.6245, 'learning_rate': 0.00012727272727272728, 'epoch': 0.04}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d17fe78dd5e4610b6a661f47720cfca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6672379374504089, 'eval_runtime': 12.026, 'eval_samples_per_second': 20.788, 'eval_steps_per_second': 3.492, 'epoch': 0.04}\n",
      "{'loss': 0.661, 'learning_rate': 0.00012717171717171717, 'epoch': 0.04}\n",
      "{'loss': 0.6582, 'learning_rate': 0.00012707070707070707, 'epoch': 0.04}\n",
      "{'loss': 0.6519, 'learning_rate': 0.000126969696969697, 'epoch': 0.04}\n",
      "{'loss': 0.6171, 'learning_rate': 0.00012686868686868688, 'epoch': 0.04}\n",
      "{'loss': 0.6569, 'learning_rate': 0.00012676767676767677, 'epoch': 0.04}\n",
      "{'loss': 0.6682, 'learning_rate': 0.00012666666666666666, 'epoch': 0.04}\n",
      "{'loss': 0.698, 'learning_rate': 0.00012656565656565658, 'epoch': 0.04}\n",
      "{'loss': 0.6084, 'learning_rate': 0.00012646464646464645, 'epoch': 0.04}\n",
      "{'loss': 0.6482, 'learning_rate': 0.00012636363636363637, 'epoch': 0.04}\n",
      "{'loss': 0.652, 'learning_rate': 0.00012626262626262626, 'epoch': 0.04}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68e9cba8507b4a54a0181c6b7bf3f331",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.670666515827179, 'eval_runtime': 12.0129, 'eval_samples_per_second': 20.811, 'eval_steps_per_second': 3.496, 'epoch': 0.04}\n",
      "{'loss': 0.692, 'learning_rate': 0.00012616161616161618, 'epoch': 0.04}\n",
      "{'loss': 0.7032, 'learning_rate': 0.00012606060606060605, 'epoch': 0.04}\n",
      "{'loss': 0.716, 'learning_rate': 0.00012595959595959597, 'epoch': 0.04}\n",
      "{'loss': 0.8379, 'learning_rate': 0.0001258585858585859, 'epoch': 0.04}\n",
      "{'loss': 0.6646, 'learning_rate': 0.00012575757575757575, 'epoch': 0.04}\n",
      "{'loss': 0.7087, 'learning_rate': 0.00012565656565656567, 'epoch': 0.04}\n",
      "{'loss': 0.743, 'learning_rate': 0.00012555555555555557, 'epoch': 0.04}\n",
      "{'loss': 0.6783, 'learning_rate': 0.00012545454545454546, 'epoch': 0.04}\n",
      "{'loss': 0.6852, 'learning_rate': 0.00012535353535353535, 'epoch': 0.04}\n",
      "{'loss': 0.6005, 'learning_rate': 0.00012525252525252527, 'epoch': 0.04}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a91b3be408f745f09e634a661fcf4cd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6674066781997681, 'eval_runtime': 12.0186, 'eval_samples_per_second': 20.801, 'eval_steps_per_second': 3.495, 'epoch': 0.04}\n",
      "{'loss': 0.6921, 'learning_rate': 0.00012515151515151516, 'epoch': 0.04}\n",
      "{'loss': 0.7003, 'learning_rate': 0.00012505050505050506, 'epoch': 0.04}\n",
      "{'loss': 0.7094, 'learning_rate': 0.00012494949494949495, 'epoch': 0.04}\n",
      "{'loss': 0.6358, 'learning_rate': 0.00012484848484848487, 'epoch': 0.04}\n",
      "{'loss': 0.6869, 'learning_rate': 0.00012474747474747473, 'epoch': 0.04}\n",
      "{'loss': 0.6282, 'learning_rate': 0.00012464646464646465, 'epoch': 0.04}\n",
      "{'loss': 0.7235, 'learning_rate': 0.00012454545454545455, 'epoch': 0.04}\n",
      "{'loss': 0.7364, 'learning_rate': 0.00012444444444444444, 'epoch': 0.04}\n",
      "{'loss': 0.6609, 'learning_rate': 0.00012434343434343433, 'epoch': 0.04}\n",
      "{'loss': 0.6377, 'learning_rate': 0.00012424242424242425, 'epoch': 0.04}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdb6e4ef38f74cc281245984e626586c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6692755818367004, 'eval_runtime': 12.0197, 'eval_samples_per_second': 20.799, 'eval_steps_per_second': 3.494, 'epoch': 0.04}\n",
      "{'loss': 0.7002, 'learning_rate': 0.00012414141414141414, 'epoch': 0.04}\n",
      "{'loss': 0.6855, 'learning_rate': 0.00012404040404040404, 'epoch': 0.04}\n",
      "{'loss': 0.656, 'learning_rate': 0.00012393939393939396, 'epoch': 0.04}\n",
      "{'loss': 0.7067, 'learning_rate': 0.00012383838383838385, 'epoch': 0.04}\n",
      "{'loss': 0.7422, 'learning_rate': 0.00012373737373737374, 'epoch': 0.04}\n",
      "{'loss': 0.6747, 'learning_rate': 0.00012363636363636364, 'epoch': 0.04}\n",
      "{'loss': 0.6999, 'learning_rate': 0.00012353535353535356, 'epoch': 0.04}\n",
      "{'loss': 0.638, 'learning_rate': 0.00012343434343434345, 'epoch': 0.04}\n",
      "{'loss': 0.6427, 'learning_rate': 0.00012333333333333334, 'epoch': 0.04}\n",
      "{'loss': 0.6976, 'learning_rate': 0.00012323232323232323, 'epoch': 0.04}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87c1cc34a64743c48d98fa095456b9dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.666486382484436, 'eval_runtime': 12.0202, 'eval_samples_per_second': 20.798, 'eval_steps_per_second': 3.494, 'epoch': 0.04}\n",
      "{'loss': 0.6538, 'learning_rate': 0.00012313131313131315, 'epoch': 0.04}\n",
      "{'loss': 0.7192, 'learning_rate': 0.00012303030303030302, 'epoch': 0.04}\n",
      "{'loss': 0.7207, 'learning_rate': 0.00012292929292929294, 'epoch': 0.04}\n",
      "{'loss': 0.6633, 'learning_rate': 0.00012282828282828283, 'epoch': 0.04}\n",
      "{'loss': 0.6978, 'learning_rate': 0.00012272727272727272, 'epoch': 0.04}\n",
      "{'loss': 0.636, 'learning_rate': 0.00012262626262626262, 'epoch': 0.04}\n",
      "{'loss': 0.7061, 'learning_rate': 0.00012252525252525254, 'epoch': 0.04}\n",
      "{'loss': 0.703, 'learning_rate': 0.00012242424242424243, 'epoch': 0.04}\n",
      "{'loss': 0.6038, 'learning_rate': 0.00012232323232323232, 'epoch': 0.04}\n",
      "{'loss': 0.6341, 'learning_rate': 0.00012222222222222224, 'epoch': 0.04}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76fdcd842ca94e42b85eb71217a6e3c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6663810014724731, 'eval_runtime': 12.0224, 'eval_samples_per_second': 20.794, 'eval_steps_per_second': 3.493, 'epoch': 0.04}\n",
      "{'loss': 0.6302, 'learning_rate': 0.00012212121212121213, 'epoch': 0.04}\n",
      "{'loss': 0.6709, 'learning_rate': 0.00012202020202020204, 'epoch': 0.04}\n",
      "{'loss': 0.6406, 'learning_rate': 0.00012191919191919192, 'epoch': 0.04}\n",
      "{'loss': 0.6497, 'learning_rate': 0.00012181818181818183, 'epoch': 0.04}\n",
      "{'loss': 0.5952, 'learning_rate': 0.00012171717171717172, 'epoch': 0.04}\n",
      "{'loss': 0.6191, 'learning_rate': 0.00012161616161616162, 'epoch': 0.04}\n",
      "{'loss': 0.6503, 'learning_rate': 0.00012151515151515152, 'epoch': 0.04}\n",
      "{'loss': 0.6666, 'learning_rate': 0.00012141414141414142, 'epoch': 0.04}\n",
      "{'loss': 0.6474, 'learning_rate': 0.00012131313131313132, 'epoch': 0.04}\n",
      "{'loss': 0.5983, 'learning_rate': 0.00012121212121212122, 'epoch': 0.04}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7945a18ba6ac48f7bb003de2a8808405",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6693308353424072, 'eval_runtime': 12.0151, 'eval_samples_per_second': 20.807, 'eval_steps_per_second': 3.496, 'epoch': 0.04}\n",
      "{'loss': 0.7182, 'learning_rate': 0.0001211111111111111, 'epoch': 0.04}\n",
      "{'loss': 0.7101, 'learning_rate': 0.00012101010101010102, 'epoch': 0.04}\n",
      "{'loss': 0.7349, 'learning_rate': 0.0001209090909090909, 'epoch': 0.04}\n",
      "{'loss': 0.6953, 'learning_rate': 0.00012080808080808082, 'epoch': 0.04}\n",
      "{'loss': 0.7133, 'learning_rate': 0.0001207070707070707, 'epoch': 0.04}\n",
      "{'loss': 0.7182, 'learning_rate': 0.0001206060606060606, 'epoch': 0.04}\n",
      "{'loss': 0.6292, 'learning_rate': 0.00012050505050505053, 'epoch': 0.04}\n",
      "{'loss': 0.6765, 'learning_rate': 0.0001204040404040404, 'epoch': 0.04}\n",
      "{'loss': 0.6603, 'learning_rate': 0.00012030303030303031, 'epoch': 0.04}\n",
      "{'loss': 0.6777, 'learning_rate': 0.0001202020202020202, 'epoch': 0.04}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cc09285ea684511abeeead9bcf3cc80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.666340708732605, 'eval_runtime': 11.994, 'eval_samples_per_second': 20.844, 'eval_steps_per_second': 3.502, 'epoch': 0.04}\n",
      "{'loss': 0.7388, 'learning_rate': 0.00012010101010101011, 'epoch': 0.04}\n",
      "{'loss': 0.7193, 'learning_rate': 0.00012, 'epoch': 0.04}\n",
      "{'loss': 0.6318, 'learning_rate': 0.00011989898989898991, 'epoch': 0.04}\n",
      "{'loss': 0.6595, 'learning_rate': 0.0001197979797979798, 'epoch': 0.04}\n",
      "{'loss': 0.6865, 'learning_rate': 0.00011969696969696971, 'epoch': 0.04}\n",
      "{'loss': 0.7032, 'learning_rate': 0.0001195959595959596, 'epoch': 0.04}\n",
      "{'loss': 0.7174, 'learning_rate': 0.00011949494949494951, 'epoch': 0.04}\n",
      "{'loss': 0.6783, 'learning_rate': 0.00011939393939393939, 'epoch': 0.04}\n",
      "{'loss': 0.6422, 'learning_rate': 0.0001192929292929293, 'epoch': 0.04}\n",
      "{'loss': 0.6642, 'learning_rate': 0.00011919191919191919, 'epoch': 0.04}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f74ffe13916e4a8f8a71f7c4972e3f10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.668516993522644, 'eval_runtime': 12.0024, 'eval_samples_per_second': 20.829, 'eval_steps_per_second': 3.499, 'epoch': 0.04}\n",
      "{'loss': 0.6893, 'learning_rate': 0.00011909090909090909, 'epoch': 0.04}\n",
      "{'loss': 0.6978, 'learning_rate': 0.00011898989898989898, 'epoch': 0.04}\n",
      "{'loss': 0.7137, 'learning_rate': 0.00011888888888888889, 'epoch': 0.04}\n",
      "{'loss': 0.6825, 'learning_rate': 0.0001187878787878788, 'epoch': 0.04}\n",
      "{'loss': 0.7094, 'learning_rate': 0.00011868686868686869, 'epoch': 0.04}\n",
      "{'loss': 0.7, 'learning_rate': 0.0001185858585858586, 'epoch': 0.04}\n",
      "{'loss': 0.7091, 'learning_rate': 0.00011848484848484849, 'epoch': 0.04}\n",
      "{'loss': 0.6622, 'learning_rate': 0.0001183838383838384, 'epoch': 0.04}\n",
      "{'loss': 0.6789, 'learning_rate': 0.00011828282828282829, 'epoch': 0.04}\n",
      "{'loss': 0.6688, 'learning_rate': 0.0001181818181818182, 'epoch': 0.04}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "144e7463535a48928a66f79aaa9cc1f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6649839878082275, 'eval_runtime': 11.9994, 'eval_samples_per_second': 20.834, 'eval_steps_per_second': 3.5, 'epoch': 0.04}\n",
      "{'loss': 0.6876, 'learning_rate': 0.00011808080808080809, 'epoch': 0.04}\n",
      "{'loss': 0.6562, 'learning_rate': 0.00011797979797979799, 'epoch': 0.04}\n",
      "{'loss': 0.7173, 'learning_rate': 0.00011787878787878787, 'epoch': 0.04}\n",
      "{'loss': 0.6576, 'learning_rate': 0.00011777777777777779, 'epoch': 0.04}\n",
      "{'loss': 0.6616, 'learning_rate': 0.00011767676767676767, 'epoch': 0.04}\n",
      "{'loss': 0.6325, 'learning_rate': 0.00011757575757575758, 'epoch': 0.04}\n",
      "{'loss': 0.6519, 'learning_rate': 0.00011747474747474747, 'epoch': 0.04}\n",
      "{'loss': 0.6484, 'learning_rate': 0.00011737373737373738, 'epoch': 0.04}\n",
      "{'loss': 0.6591, 'learning_rate': 0.00011727272727272727, 'epoch': 0.04}\n",
      "{'loss': 0.6968, 'learning_rate': 0.00011717171717171717, 'epoch': 0.04}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d1beaeb3fc44cadac6b556bd258165b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.665192723274231, 'eval_runtime': 12.0101, 'eval_samples_per_second': 20.816, 'eval_steps_per_second': 3.497, 'epoch': 0.04}\n",
      "{'loss': 0.6823, 'learning_rate': 0.00011707070707070708, 'epoch': 0.04}\n",
      "{'loss': 0.6621, 'learning_rate': 0.00011696969696969697, 'epoch': 0.04}\n",
      "{'loss': 0.6237, 'learning_rate': 0.00011686868686868688, 'epoch': 0.04}\n",
      "{'loss': 0.5928, 'learning_rate': 0.00011676767676767677, 'epoch': 0.04}\n",
      "{'loss': 0.6644, 'learning_rate': 0.00011666666666666668, 'epoch': 0.04}\n",
      "{'loss': 0.6429, 'learning_rate': 0.00011656565656565657, 'epoch': 0.04}\n",
      "{'loss': 0.7047, 'learning_rate': 0.00011646464646464648, 'epoch': 0.04}\n",
      "{'loss': 0.6931, 'learning_rate': 0.00011636363636363636, 'epoch': 0.04}\n",
      "{'loss': 0.549, 'learning_rate': 0.00011626262626262628, 'epoch': 0.04}\n",
      "{'loss': 0.6255, 'learning_rate': 0.00011616161616161616, 'epoch': 0.04}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a6d9f2db53043159d2ad04a99f5b4a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6679951548576355, 'eval_runtime': 12.0122, 'eval_samples_per_second': 20.812, 'eval_steps_per_second': 3.496, 'epoch': 0.04}\n",
      "{'loss': 0.6851, 'learning_rate': 0.00011606060606060608, 'epoch': 0.04}\n",
      "{'loss': 0.6677, 'learning_rate': 0.00011595959595959596, 'epoch': 0.04}\n",
      "{'loss': 0.6666, 'learning_rate': 0.00011585858585858586, 'epoch': 0.04}\n",
      "{'loss': 0.6659, 'learning_rate': 0.00011575757575757575, 'epoch': 0.04}\n",
      "{'loss': 0.6992, 'learning_rate': 0.00011565656565656566, 'epoch': 0.04}\n",
      "{'loss': 0.6177, 'learning_rate': 0.00011555555555555555, 'epoch': 0.04}\n",
      "{'loss': 0.6445, 'learning_rate': 0.00011545454545454546, 'epoch': 0.04}\n",
      "{'loss': 0.7064, 'learning_rate': 0.00011535353535353537, 'epoch': 0.04}\n",
      "{'loss': 0.6823, 'learning_rate': 0.00011525252525252526, 'epoch': 0.04}\n",
      "{'loss': 0.6899, 'learning_rate': 0.00011515151515151516, 'epoch': 0.04}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1015288252ba443193ea2d0552871b98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6647009253501892, 'eval_runtime': 12.0117, 'eval_samples_per_second': 20.813, 'eval_steps_per_second': 3.497, 'epoch': 0.04}\n",
      "{'loss': 0.6467, 'learning_rate': 0.00011505050505050506, 'epoch': 0.04}\n",
      "{'loss': 0.7069, 'learning_rate': 0.00011494949494949496, 'epoch': 0.04}\n",
      "{'loss': 0.7088, 'learning_rate': 0.00011484848484848486, 'epoch': 0.04}\n",
      "{'loss': 0.6703, 'learning_rate': 0.00011474747474747476, 'epoch': 0.04}\n",
      "{'loss': 0.657, 'learning_rate': 0.00011464646464646464, 'epoch': 0.04}\n",
      "{'loss': 0.6584, 'learning_rate': 0.00011454545454545456, 'epoch': 0.04}\n",
      "{'loss': 0.6807, 'learning_rate': 0.00011444444444444444, 'epoch': 0.04}\n",
      "{'loss': 0.6696, 'learning_rate': 0.00011434343434343435, 'epoch': 0.04}\n",
      "{'loss': 0.733, 'learning_rate': 0.00011424242424242424, 'epoch': 0.04}\n",
      "{'loss': 0.6824, 'learning_rate': 0.00011414141414141415, 'epoch': 0.04}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4231d78d0a29444aa42f001469e55e3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6671565175056458, 'eval_runtime': 12.0145, 'eval_samples_per_second': 20.808, 'eval_steps_per_second': 3.496, 'epoch': 0.04}\n",
      "{'loss': 0.7138, 'learning_rate': 0.00011404040404040404, 'epoch': 0.04}\n",
      "{'loss': 0.6717, 'learning_rate': 0.00011393939393939394, 'epoch': 0.04}\n",
      "{'loss': 0.6569, 'learning_rate': 0.00011383838383838384, 'epoch': 0.04}\n",
      "{'loss': 0.6975, 'learning_rate': 0.00011373737373737374, 'epoch': 0.04}\n",
      "{'loss': 0.7135, 'learning_rate': 0.00011363636363636365, 'epoch': 0.04}\n",
      "{'loss': 0.7169, 'learning_rate': 0.00011353535353535354, 'epoch': 0.04}\n",
      "{'loss': 0.6966, 'learning_rate': 0.00011343434343434345, 'epoch': 0.04}\n",
      "{'loss': 0.6878, 'learning_rate': 0.00011333333333333334, 'epoch': 0.04}\n",
      "{'loss': 0.6824, 'learning_rate': 0.00011323232323232325, 'epoch': 0.04}\n",
      "{'loss': 0.6881, 'learning_rate': 0.00011313131313131313, 'epoch': 0.04}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edd6a0ad677440bcafb93bf6c24e9559",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6639475226402283, 'eval_runtime': 12.0144, 'eval_samples_per_second': 20.808, 'eval_steps_per_second': 3.496, 'epoch': 0.04}\n",
      "{'loss': 0.6991, 'learning_rate': 0.00011303030303030305, 'epoch': 0.04}\n",
      "{'loss': 0.6611, 'learning_rate': 0.00011292929292929293, 'epoch': 0.04}\n",
      "{'loss': 0.7508, 'learning_rate': 0.00011282828282828283, 'epoch': 0.04}\n",
      "{'loss': 0.6946, 'learning_rate': 0.00011272727272727272, 'epoch': 0.04}\n",
      "{'loss': 0.6939, 'learning_rate': 0.00011262626262626263, 'epoch': 0.04}\n",
      "{'loss': 0.6331, 'learning_rate': 0.00011252525252525252, 'epoch': 0.04}\n",
      "{'loss': 0.6718, 'learning_rate': 0.00011242424242424243, 'epoch': 0.04}\n",
      "{'loss': 0.6684, 'learning_rate': 0.00011232323232323232, 'epoch': 0.04}\n",
      "{'loss': 0.6606, 'learning_rate': 0.00011222222222222223, 'epoch': 0.04}\n",
      "{'loss': 0.6436, 'learning_rate': 0.00011212121212121212, 'epoch': 0.04}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ac3ee876ce446e3a5ac62501c6f5098",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6642538905143738, 'eval_runtime': 12.0209, 'eval_samples_per_second': 20.797, 'eval_steps_per_second': 3.494, 'epoch': 0.04}\n",
      "{'loss': 0.6903, 'learning_rate': 0.00011202020202020203, 'epoch': 0.04}\n",
      "{'loss': 0.6489, 'learning_rate': 0.00011191919191919193, 'epoch': 0.04}\n",
      "{'loss': 0.6053, 'learning_rate': 0.00011181818181818183, 'epoch': 0.04}\n",
      "{'loss': 0.6514, 'learning_rate': 0.00011171717171717173, 'epoch': 0.04}\n",
      "{'loss': 0.6616, 'learning_rate': 0.00011161616161616161, 'epoch': 0.04}\n",
      "{'loss': 0.653, 'learning_rate': 0.00011151515151515153, 'epoch': 0.04}\n",
      "{'loss': 0.6114, 'learning_rate': 0.00011141414141414141, 'epoch': 0.04}\n",
      "{'loss': 0.6454, 'learning_rate': 0.00011131313131313133, 'epoch': 0.04}\n",
      "{'loss': 0.6323, 'learning_rate': 0.00011121212121212121, 'epoch': 0.04}\n",
      "{'loss': 0.6407, 'learning_rate': 0.00011111111111111112, 'epoch': 0.04}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a41ff9c9f9b94e19bc7eb35c59b156e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6666629910469055, 'eval_runtime': 12.0142, 'eval_samples_per_second': 20.809, 'eval_steps_per_second': 3.496, 'epoch': 0.04}\n",
      "{'loss': 0.6565, 'learning_rate': 0.00011101010101010101, 'epoch': 0.04}\n",
      "{'loss': 0.622, 'learning_rate': 0.00011090909090909092, 'epoch': 0.04}\n",
      "{'loss': 0.7632, 'learning_rate': 0.00011080808080808081, 'epoch': 0.04}\n",
      "{'loss': 0.6844, 'learning_rate': 0.00011070707070707071, 'epoch': 0.04}\n",
      "{'loss': 0.6419, 'learning_rate': 0.00011060606060606061, 'epoch': 0.04}\n",
      "{'loss': 0.7084, 'learning_rate': 0.00011050505050505051, 'epoch': 0.04}\n",
      "{'loss': 0.6492, 'learning_rate': 0.00011040404040404039, 'epoch': 0.04}\n",
      "{'loss': 0.6635, 'learning_rate': 0.00011030303030303031, 'epoch': 0.04}\n",
      "{'loss': 0.6782, 'learning_rate': 0.00011020202020202022, 'epoch': 0.04}\n",
      "{'loss': 0.6231, 'learning_rate': 0.00011010101010101011, 'epoch': 0.04}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ab20a2c9d6a4cc38081271100c36aff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6643900275230408, 'eval_runtime': 12.0194, 'eval_samples_per_second': 20.8, 'eval_steps_per_second': 3.494, 'epoch': 0.04}\n",
      "{'loss': 0.6575, 'learning_rate': 0.00011000000000000002, 'epoch': 0.04}\n",
      "{'loss': 0.7781, 'learning_rate': 0.0001098989898989899, 'epoch': 0.04}\n",
      "{'loss': 0.6378, 'learning_rate': 0.00010979797979797982, 'epoch': 0.04}\n",
      "{'loss': 0.6976, 'learning_rate': 0.0001096969696969697, 'epoch': 0.04}\n",
      "{'loss': 0.6781, 'learning_rate': 0.0001095959595959596, 'epoch': 0.04}\n",
      "{'loss': 0.6353, 'learning_rate': 0.0001094949494949495, 'epoch': 0.04}\n",
      "{'loss': 0.7114, 'learning_rate': 0.0001093939393939394, 'epoch': 0.04}\n",
      "{'loss': 0.6952, 'learning_rate': 0.0001092929292929293, 'epoch': 0.04}\n",
      "{'loss': 0.6876, 'learning_rate': 0.0001091919191919192, 'epoch': 0.04}\n",
      "{'loss': 0.6543, 'learning_rate': 0.00010909090909090909, 'epoch': 0.04}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc4ad98354cd426ea795ce7f039fb905",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6657858490943909, 'eval_runtime': 12.0167, 'eval_samples_per_second': 20.804, 'eval_steps_per_second': 3.495, 'epoch': 0.04}\n",
      "{'loss': 0.6302, 'learning_rate': 0.000108989898989899, 'epoch': 0.04}\n",
      "{'loss': 0.7045, 'learning_rate': 0.00010888888888888889, 'epoch': 0.04}\n",
      "{'loss': 0.7226, 'learning_rate': 0.0001087878787878788, 'epoch': 0.04}\n",
      "{'loss': 0.7453, 'learning_rate': 0.00010868686868686868, 'epoch': 0.04}\n",
      "{'loss': 0.7244, 'learning_rate': 0.0001085858585858586, 'epoch': 0.04}\n",
      "{'loss': 0.7277, 'learning_rate': 0.0001084848484848485, 'epoch': 0.04}\n",
      "{'loss': 0.6696, 'learning_rate': 0.00010838383838383838, 'epoch': 0.04}\n",
      "{'loss': 0.6322, 'learning_rate': 0.0001082828282828283, 'epoch': 0.04}\n",
      "{'loss': 0.6687, 'learning_rate': 0.00010818181818181818, 'epoch': 0.04}\n",
      "{'loss': 0.6745, 'learning_rate': 0.00010808080808080809, 'epoch': 0.04}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c28a16308c79486a9c1e16e1802c1a77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6633577942848206, 'eval_runtime': 12.0099, 'eval_samples_per_second': 20.816, 'eval_steps_per_second': 3.497, 'epoch': 0.04}\n",
      "{'loss': 0.6793, 'learning_rate': 0.00010797979797979798, 'epoch': 0.04}\n",
      "{'loss': 0.6527, 'learning_rate': 0.00010787878787878789, 'epoch': 0.04}\n",
      "{'loss': 0.6379, 'learning_rate': 0.00010777777777777778, 'epoch': 0.04}\n",
      "{'loss': 0.7027, 'learning_rate': 0.00010767676767676769, 'epoch': 0.04}\n",
      "{'loss': 0.6521, 'learning_rate': 0.00010757575757575758, 'epoch': 0.04}\n",
      "{'loss': 0.6877, 'learning_rate': 0.00010747474747474748, 'epoch': 0.04}\n",
      "{'loss': 0.6613, 'learning_rate': 0.00010737373737373738, 'epoch': 0.05}\n",
      "{'loss': 0.6243, 'learning_rate': 0.00010727272727272728, 'epoch': 0.05}\n",
      "{'loss': 0.7148, 'learning_rate': 0.00010717171717171716, 'epoch': 0.05}\n",
      "{'loss': 0.6237, 'learning_rate': 0.00010707070707070708, 'epoch': 0.05}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff39cab7361a40c5b357a55695034b30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6641908884048462, 'eval_runtime': 11.9908, 'eval_samples_per_second': 20.849, 'eval_steps_per_second': 3.503, 'epoch': 0.05}\n",
      "{'loss': 0.6403, 'learning_rate': 0.00010696969696969696, 'epoch': 0.05}\n",
      "{'loss': 0.6706, 'learning_rate': 0.00010686868686868687, 'epoch': 0.05}\n",
      "{'loss': 0.6912, 'learning_rate': 0.00010676767676767679, 'epoch': 0.05}\n",
      "{'loss': 0.6684, 'learning_rate': 0.00010666666666666667, 'epoch': 0.05}\n",
      "{'loss': 0.6653, 'learning_rate': 0.00010656565656565659, 'epoch': 0.05}\n",
      "{'loss': 0.5979, 'learning_rate': 0.00010646464646464647, 'epoch': 0.05}\n",
      "{'loss': 0.5963, 'learning_rate': 0.00010636363636363637, 'epoch': 0.05}\n",
      "{'loss': 0.6068, 'learning_rate': 0.00010626262626262626, 'epoch': 0.05}\n",
      "{'loss': 0.6688, 'learning_rate': 0.00010616161616161617, 'epoch': 0.05}\n",
      "{'loss': 0.5799, 'learning_rate': 0.00010606060606060606, 'epoch': 0.05}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96c1012b823a4da896464ec34b602b71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.666348934173584, 'eval_runtime': 11.9812, 'eval_samples_per_second': 20.866, 'eval_steps_per_second': 3.505, 'epoch': 0.05}\n",
      "{'loss': 0.6966, 'learning_rate': 0.00010595959595959597, 'epoch': 0.05}\n",
      "{'loss': 0.7129, 'learning_rate': 0.00010585858585858586, 'epoch': 0.05}\n",
      "{'loss': 0.6849, 'learning_rate': 0.00010575757575757577, 'epoch': 0.05}\n",
      "{'loss': 0.6579, 'learning_rate': 0.00010565656565656565, 'epoch': 0.05}\n",
      "{'loss': 0.6595, 'learning_rate': 0.00010555555555555557, 'epoch': 0.05}\n",
      "{'loss': 0.6752, 'learning_rate': 0.00010545454545454545, 'epoch': 0.05}\n",
      "{'loss': 0.6269, 'learning_rate': 0.00010535353535353537, 'epoch': 0.05}\n",
      "{'loss': 0.6486, 'learning_rate': 0.00010525252525252525, 'epoch': 0.05}\n",
      "{'loss': 0.6637, 'learning_rate': 0.00010515151515151515, 'epoch': 0.05}\n",
      "{'loss': 0.7251, 'learning_rate': 0.00010505050505050507, 'epoch': 0.05}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "386bde56354543688cc156e0ce6ace35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6633542776107788, 'eval_runtime': 12.0008, 'eval_samples_per_second': 20.832, 'eval_steps_per_second': 3.5, 'epoch': 0.05}\n",
      "{'loss': 0.6877, 'learning_rate': 0.00010494949494949495, 'epoch': 0.05}\n",
      "{'loss': 0.7189, 'learning_rate': 0.00010484848484848486, 'epoch': 0.05}\n",
      "{'loss': 0.6284, 'learning_rate': 0.00010474747474747475, 'epoch': 0.05}\n",
      "{'loss': 0.6365, 'learning_rate': 0.00010464646464646466, 'epoch': 0.05}\n",
      "{'loss': 0.6577, 'learning_rate': 0.00010454545454545455, 'epoch': 0.05}\n",
      "{'loss': 0.6772, 'learning_rate': 0.00010444444444444445, 'epoch': 0.05}\n",
      "{'loss': 0.7115, 'learning_rate': 0.00010434343434343435, 'epoch': 0.05}\n",
      "{'loss': 0.6868, 'learning_rate': 0.00010424242424242425, 'epoch': 0.05}\n",
      "{'loss': 0.7711, 'learning_rate': 0.00010414141414141415, 'epoch': 0.05}\n",
      "{'loss': 0.6766, 'learning_rate': 0.00010404040404040405, 'epoch': 0.05}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "997e13b48f73436f88f8d7c79705a911",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.665090799331665, 'eval_runtime': 12.0012, 'eval_samples_per_second': 20.831, 'eval_steps_per_second': 3.5, 'epoch': 0.05}\n",
      "{'loss': 0.6598, 'learning_rate': 0.00010393939393939393, 'epoch': 0.05}\n",
      "{'loss': 0.6647, 'learning_rate': 0.00010383838383838385, 'epoch': 0.05}\n",
      "{'loss': 0.7521, 'learning_rate': 0.00010373737373737373, 'epoch': 0.05}\n",
      "{'loss': 0.7382, 'learning_rate': 0.00010363636363636364, 'epoch': 0.05}\n",
      "{'loss': 0.6326, 'learning_rate': 0.00010353535353535353, 'epoch': 0.05}\n",
      "{'loss': 0.6969, 'learning_rate': 0.00010343434343434344, 'epoch': 0.05}\n",
      "{'loss': 0.7109, 'learning_rate': 0.00010333333333333334, 'epoch': 0.05}\n",
      "{'loss': 0.657, 'learning_rate': 0.00010323232323232324, 'epoch': 0.05}\n",
      "{'loss': 0.7074, 'learning_rate': 0.00010313131313131314, 'epoch': 0.05}\n",
      "{'loss': 0.6708, 'learning_rate': 0.00010303030303030303, 'epoch': 0.05}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffc8090d7635409f80c95254eac6a38c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6628615856170654, 'eval_runtime': 12.005, 'eval_samples_per_second': 20.825, 'eval_steps_per_second': 3.499, 'epoch': 0.05}\n",
      "{'loss': 0.6989, 'learning_rate': 0.00010292929292929294, 'epoch': 0.05}\n",
      "{'loss': 0.6579, 'learning_rate': 0.00010282828282828283, 'epoch': 0.05}\n",
      "{'loss': 0.7092, 'learning_rate': 0.00010272727272727274, 'epoch': 0.05}\n",
      "{'loss': 0.6656, 'learning_rate': 0.00010262626262626263, 'epoch': 0.05}\n",
      "{'loss': 0.6645, 'learning_rate': 0.00010252525252525254, 'epoch': 0.05}\n",
      "{'loss': 0.696, 'learning_rate': 0.00010242424242424242, 'epoch': 0.05}\n",
      "{'loss': 0.6412, 'learning_rate': 0.00010232323232323234, 'epoch': 0.05}\n",
      "{'loss': 0.6653, 'learning_rate': 0.00010222222222222222, 'epoch': 0.05}\n",
      "{'loss': 0.6836, 'learning_rate': 0.00010212121212121212, 'epoch': 0.05}\n",
      "{'loss': 0.7159, 'learning_rate': 0.00010202020202020202, 'epoch': 0.05}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75d6305dacfc45cfbc4b6ce95a6d4788",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6631112098693848, 'eval_runtime': 12.006, 'eval_samples_per_second': 20.823, 'eval_steps_per_second': 3.498, 'epoch': 0.05}\n",
      "{'loss': 0.6542, 'learning_rate': 0.00010191919191919192, 'epoch': 0.05}\n",
      "{'loss': 0.636, 'learning_rate': 0.00010181818181818181, 'epoch': 0.05}\n",
      "{'loss': 0.6931, 'learning_rate': 0.00010171717171717172, 'epoch': 0.05}\n",
      "{'loss': 0.7095, 'learning_rate': 0.00010161616161616163, 'epoch': 0.05}\n",
      "{'loss': 0.6347, 'learning_rate': 0.00010151515151515152, 'epoch': 0.05}\n",
      "{'loss': 0.6517, 'learning_rate': 0.00010141414141414143, 'epoch': 0.05}\n",
      "{'loss': 0.5801, 'learning_rate': 0.00010131313131313132, 'epoch': 0.05}\n",
      "{'loss': 0.6734, 'learning_rate': 0.00010121212121212122, 'epoch': 0.05}\n",
      "{'loss': 0.6416, 'learning_rate': 0.00010111111111111112, 'epoch': 0.05}\n",
      "{'loss': 0.5847, 'learning_rate': 0.00010101010101010102, 'epoch': 0.05}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95931c1edfa84904908ed8214d535189",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.666031002998352, 'eval_runtime': 12.0084, 'eval_samples_per_second': 20.819, 'eval_steps_per_second': 3.498, 'epoch': 0.05}\n",
      "{'loss': 0.7478, 'learning_rate': 0.0001009090909090909, 'epoch': 0.05}\n",
      "{'loss': 0.6887, 'learning_rate': 0.00010080808080808082, 'epoch': 0.05}\n",
      "{'loss': 0.6819, 'learning_rate': 0.0001007070707070707, 'epoch': 0.05}\n",
      "{'loss': 0.719, 'learning_rate': 0.00010060606060606062, 'epoch': 0.05}\n",
      "{'loss': 0.7715, 'learning_rate': 0.0001005050505050505, 'epoch': 0.05}\n",
      "{'loss': 0.7642, 'learning_rate': 0.00010040404040404041, 'epoch': 0.05}\n",
      "{'loss': 0.7456, 'learning_rate': 0.0001003030303030303, 'epoch': 0.05}\n",
      "{'loss': 0.6859, 'learning_rate': 0.0001002020202020202, 'epoch': 0.05}\n",
      "{'loss': 0.6739, 'learning_rate': 0.0001001010101010101, 'epoch': 0.05}\n",
      "{'loss': 0.6835, 'learning_rate': 0.0001, 'epoch': 0.05}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47593529021e434f81a6da6f5122c574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6625322699546814, 'eval_runtime': 12.0103, 'eval_samples_per_second': 20.816, 'eval_steps_per_second': 3.497, 'epoch': 0.05}\n",
      "{'loss': 0.6802, 'learning_rate': 9.98989898989899e-05, 'epoch': 0.05}\n",
      "{'loss': 0.663, 'learning_rate': 9.97979797979798e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6299, 'learning_rate': 9.96969696969697e-05, 'epoch': 0.05}\n",
      "{'loss': 0.692, 'learning_rate': 9.95959595959596e-05, 'epoch': 0.05}\n",
      "{'loss': 0.7232, 'learning_rate': 9.94949494949495e-05, 'epoch': 0.05}\n",
      "{'loss': 0.7083, 'learning_rate': 9.939393939393939e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6478, 'learning_rate': 9.92929292929293e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6969, 'learning_rate': 9.919191919191919e-05, 'epoch': 0.05}\n",
      "{'loss': 0.7109, 'learning_rate': 9.909090909090911e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6417, 'learning_rate': 9.8989898989899e-05, 'epoch': 0.05}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2035e5bcc7f147ad87c69725466ec736",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6639536619186401, 'eval_runtime': 12.0176, 'eval_samples_per_second': 20.803, 'eval_steps_per_second': 3.495, 'epoch': 0.05}\n",
      "{'loss': 0.7007, 'learning_rate': 9.888888888888889e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6753, 'learning_rate': 9.87878787878788e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6768, 'learning_rate': 9.868686868686869e-05, 'epoch': 0.05}\n",
      "{'loss': 0.7419, 'learning_rate': 9.85858585858586e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6557, 'learning_rate': 9.848484848484849e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6671, 'learning_rate': 9.838383838383838e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6309, 'learning_rate': 9.828282828282829e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6831, 'learning_rate': 9.818181818181818e-05, 'epoch': 0.05}\n",
      "{'loss': 0.7022, 'learning_rate': 9.808080808080809e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6775, 'learning_rate': 9.797979797979798e-05, 'epoch': 0.05}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de167b525847498eb2aa2f3ab186395c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6621800065040588, 'eval_runtime': 13.3452, 'eval_samples_per_second': 18.733, 'eval_steps_per_second': 3.147, 'epoch': 0.05}\n",
      "{'loss': 0.6555, 'learning_rate': 9.787878787878789e-05, 'epoch': 0.05}\n",
      "{'loss': 0.7055, 'learning_rate': 9.777777777777778e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6516, 'learning_rate': 9.767676767676767e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6856, 'learning_rate': 9.757575757575758e-05, 'epoch': 0.05}\n",
      "{'loss': 0.662, 'learning_rate': 9.747474747474747e-05, 'epoch': 0.05}\n",
      "{'loss': 0.7532, 'learning_rate': 9.737373737373738e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6888, 'learning_rate': 9.727272727272728e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6256, 'learning_rate': 9.717171717171718e-05, 'epoch': 0.05}\n",
      "{'loss': 0.7083, 'learning_rate': 9.707070707070708e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6211, 'learning_rate': 9.696969696969698e-05, 'epoch': 0.05}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7ba3ea0e93c49f7a524ed2bd37391a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6617512106895447, 'eval_runtime': 14.1537, 'eval_samples_per_second': 17.663, 'eval_steps_per_second': 2.967, 'epoch': 0.05}\n",
      "{'loss': 0.6564, 'learning_rate': 9.686868686868688e-05, 'epoch': 0.05}\n",
      "{'loss': 0.627, 'learning_rate': 9.676767676767677e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6921, 'learning_rate': 9.666666666666667e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6281, 'learning_rate': 9.656565656565657e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6174, 'learning_rate': 9.646464646464647e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6551, 'learning_rate': 9.636363636363637e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6078, 'learning_rate': 9.626262626262627e-05, 'epoch': 0.05}\n",
      "{'loss': 0.5814, 'learning_rate': 9.616161616161616e-05, 'epoch': 0.05}\n",
      "{'loss': 0.5766, 'learning_rate': 9.606060606060606e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6039, 'learning_rate': 9.595959595959596e-05, 'epoch': 0.05}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79af34037e8e44949bf21f2c4a910899",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6638360619544983, 'eval_runtime': 13.6252, 'eval_samples_per_second': 18.348, 'eval_steps_per_second': 3.083, 'epoch': 0.05}\n",
      "{'loss': 0.6396, 'learning_rate': 9.585858585858586e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6608, 'learning_rate': 9.575757575757576e-05, 'epoch': 0.05}\n",
      "{'loss': 0.7092, 'learning_rate': 9.565656565656566e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6993, 'learning_rate': 9.555555555555557e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6659, 'learning_rate': 9.545454545454546e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6967, 'learning_rate': 9.535353535353537e-05, 'epoch': 0.05}\n",
      "{'loss': 0.7075, 'learning_rate': 9.525252525252526e-05, 'epoch': 0.05}\n",
      "{'loss': 0.7786, 'learning_rate': 9.515151515151515e-05, 'epoch': 0.05}\n",
      "{'loss': 0.7284, 'learning_rate': 9.505050505050506e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6356, 'learning_rate': 9.494949494949495e-05, 'epoch': 0.05}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c94f89b521214be0a6baf7b6d9cf1c27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6620467305183411, 'eval_runtime': 13.6498, 'eval_samples_per_second': 18.315, 'eval_steps_per_second': 3.077, 'epoch': 0.05}\n",
      "{'loss': 0.6477, 'learning_rate': 9.484848484848486e-05, 'epoch': 0.05}\n",
      "{'loss': 0.655, 'learning_rate': 9.474747474747475e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6512, 'learning_rate': 9.464646464646464e-05, 'epoch': 0.05}\n",
      "{'loss': 0.7209, 'learning_rate': 9.454545454545455e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6614, 'learning_rate': 9.444444444444444e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6613, 'learning_rate': 9.434343434343435e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6766, 'learning_rate': 9.424242424242424e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6613, 'learning_rate': 9.414141414141415e-05, 'epoch': 0.05}\n",
      "{'loss': 0.7089, 'learning_rate': 9.404040404040404e-05, 'epoch': 0.05}\n",
      "{'loss': 0.684, 'learning_rate': 9.393939393939395e-05, 'epoch': 0.05}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "516f45a0fa5c41cca10ff20bcaa5b0f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6631615161895752, 'eval_runtime': 13.6331, 'eval_samples_per_second': 18.338, 'eval_steps_per_second': 3.081, 'epoch': 0.05}\n",
      "{'loss': 0.7417, 'learning_rate': 9.383838383838385e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6588, 'learning_rate': 9.373737373737375e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6638, 'learning_rate': 9.363636363636364e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6894, 'learning_rate': 9.353535353535354e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6646, 'learning_rate': 9.343434343434344e-05, 'epoch': 0.05}\n",
      "{'loss': 0.7457, 'learning_rate': 9.333333333333334e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6856, 'learning_rate': 9.323232323232324e-05, 'epoch': 0.05}\n",
      "{'loss': 0.7269, 'learning_rate': 9.313131313131314e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6781, 'learning_rate': 9.303030303030303e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6297, 'learning_rate': 9.292929292929293e-05, 'epoch': 0.05}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e10c15ae0a1149e0a331ab5ac926c624",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6613369584083557, 'eval_runtime': 13.6596, 'eval_samples_per_second': 18.302, 'eval_steps_per_second': 3.075, 'epoch': 0.05}\n",
      "{'loss': 0.6793, 'learning_rate': 9.282828282828283e-05, 'epoch': 0.05}\n",
      "{'loss': 0.697, 'learning_rate': 9.272727272727273e-05, 'epoch': 0.05}\n",
      "{'loss': 0.7171, 'learning_rate': 9.262626262626263e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6586, 'learning_rate': 9.252525252525253e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6635, 'learning_rate': 9.242424242424242e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6417, 'learning_rate': 9.232323232323232e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6425, 'learning_rate': 9.222222222222223e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6675, 'learning_rate': 9.212121212121214e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6751, 'learning_rate': 9.202020202020203e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6415, 'learning_rate': 9.191919191919192e-05, 'epoch': 0.05}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "321ca31b857b480f9d395ff69dd763b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6614481806755066, 'eval_runtime': 13.6499, 'eval_samples_per_second': 18.315, 'eval_steps_per_second': 3.077, 'epoch': 0.05}\n",
      "{'loss': 0.6828, 'learning_rate': 9.181818181818183e-05, 'epoch': 0.05}\n",
      "{'loss': 0.7059, 'learning_rate': 9.171717171717172e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6521, 'learning_rate': 9.161616161616163e-05, 'epoch': 0.05}\n",
      "{'loss': 0.7051, 'learning_rate': 9.151515151515152e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6656, 'learning_rate': 9.141414141414141e-05, 'epoch': 0.05}\n",
      "{'loss': 0.7028, 'learning_rate': 9.131313131313132e-05, 'epoch': 0.05}\n",
      "{'loss': 0.7453, 'learning_rate': 9.121212121212121e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6604, 'learning_rate': 9.111111111111112e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6613, 'learning_rate': 9.101010101010101e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6237, 'learning_rate': 9.090909090909092e-05, 'epoch': 0.05}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57f3cd1bf3ff470b9f0f8b9e046b0f8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6638213992118835, 'eval_runtime': 13.5808, 'eval_samples_per_second': 18.408, 'eval_steps_per_second': 3.093, 'epoch': 0.05}\n",
      "{'loss': 0.6815, 'learning_rate': 9.080808080808081e-05, 'epoch': 0.05}\n",
      "{'loss': 0.7487, 'learning_rate': 9.07070707070707e-05, 'epoch': 0.05}\n",
      "{'loss': 0.747, 'learning_rate': 9.060606060606061e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6799, 'learning_rate': 9.050505050505052e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6836, 'learning_rate': 9.040404040404041e-05, 'epoch': 0.05}\n",
      "{'loss': 0.7705, 'learning_rate': 9.030303030303031e-05, 'epoch': 0.05}\n",
      "{'loss': 0.729, 'learning_rate': 9.02020202020202e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6712, 'learning_rate': 9.010101010101011e-05, 'epoch': 0.05}\n",
      "{'loss': 0.7065, 'learning_rate': 9e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6894, 'learning_rate': 8.98989898989899e-05, 'epoch': 0.05}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbdc57c1ef4f4a88b60d2858edc99f8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6617538928985596, 'eval_runtime': 13.6231, 'eval_samples_per_second': 18.351, 'eval_steps_per_second': 3.083, 'epoch': 0.05}\n",
      "{'loss': 0.7207, 'learning_rate': 8.97979797979798e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6882, 'learning_rate': 8.96969696969697e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6717, 'learning_rate': 8.95959595959596e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6463, 'learning_rate': 8.94949494949495e-05, 'epoch': 0.05}\n",
      "{'loss': 0.7377, 'learning_rate': 8.93939393939394e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6973, 'learning_rate': 8.92929292929293e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6802, 'learning_rate': 8.919191919191919e-05, 'epoch': 0.05}\n",
      "{'loss': 0.7302, 'learning_rate': 8.90909090909091e-05, 'epoch': 0.05}\n",
      "{'loss': 0.714, 'learning_rate': 8.898989898989899e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6423, 'learning_rate': 8.888888888888889e-05, 'epoch': 0.05}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "288ace313abc402d868d5295425d2ce1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.662483274936676, 'eval_runtime': 13.6235, 'eval_samples_per_second': 18.351, 'eval_steps_per_second': 3.083, 'epoch': 0.05}\n",
      "{'loss': 0.7256, 'learning_rate': 8.87878787878788e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6293, 'learning_rate': 8.868686868686869e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6682, 'learning_rate': 8.85858585858586e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6947, 'learning_rate': 8.848484848484849e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6483, 'learning_rate': 8.83838383838384e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6069, 'learning_rate': 8.828282828282829e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6855, 'learning_rate': 8.818181818181818e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6791, 'learning_rate': 8.808080808080809e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6787, 'learning_rate': 8.797979797979798e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6367, 'learning_rate': 8.787878787878789e-05, 'epoch': 0.05}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e2fdf1cfee04e1380f38957a2c7c7fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6605274677276611, 'eval_runtime': 13.6425, 'eval_samples_per_second': 18.325, 'eval_steps_per_second': 3.079, 'epoch': 0.05}\n",
      "{'loss': 0.6487, 'learning_rate': 8.777777777777778e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6653, 'learning_rate': 8.767676767676767e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6723, 'learning_rate': 8.757575757575758e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6995, 'learning_rate': 8.747474747474747e-05, 'epoch': 0.05}\n",
      "{'loss': 0.7029, 'learning_rate': 8.737373737373738e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6974, 'learning_rate': 8.727272727272727e-05, 'epoch': 0.05}\n",
      "{'loss': 0.7144, 'learning_rate': 8.717171717171718e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6609, 'learning_rate': 8.707070707070707e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6743, 'learning_rate': 8.696969696969698e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6615, 'learning_rate': 8.686868686868688e-05, 'epoch': 0.05}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c57f5ead35a4f74ba29f70e1d36863a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6603103280067444, 'eval_runtime': 13.616, 'eval_samples_per_second': 18.361, 'eval_steps_per_second': 3.085, 'epoch': 0.05}\n",
      "{'loss': 0.6578, 'learning_rate': 8.676767676767678e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6574, 'learning_rate': 8.666666666666667e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6508, 'learning_rate': 8.656565656565657e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6531, 'learning_rate': 8.646464646464647e-05, 'epoch': 0.05}\n",
      "{'loss': 0.6793, 'learning_rate': 8.636363636363637e-05, 'epoch': 0.06}\n",
      "{'loss': 0.585, 'learning_rate': 8.626262626262627e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6666, 'learning_rate': 8.616161616161616e-05, 'epoch': 0.06}\n",
      "{'loss': 0.7106, 'learning_rate': 8.606060606060606e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6407, 'learning_rate': 8.595959595959596e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6631, 'learning_rate': 8.585858585858586e-05, 'epoch': 0.06}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5fa1795650845a8b3dee129c98d85b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6624495983123779, 'eval_runtime': 13.5871, 'eval_samples_per_second': 18.4, 'eval_steps_per_second': 3.091, 'epoch': 0.06}\n",
      "{'loss': 0.6497, 'learning_rate': 8.575757575757576e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6578, 'learning_rate': 8.565656565656566e-05, 'epoch': 0.06}\n",
      "{'loss': 0.7448, 'learning_rate': 8.555555555555556e-05, 'epoch': 0.06}\n",
      "{'loss': 0.7669, 'learning_rate': 8.545454545454545e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6675, 'learning_rate': 8.535353535353535e-05, 'epoch': 0.06}\n",
      "{'loss': 0.7873, 'learning_rate': 8.525252525252526e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6941, 'learning_rate': 8.515151515151515e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6766, 'learning_rate': 8.505050505050506e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6929, 'learning_rate': 8.494949494949495e-05, 'epoch': 0.06}\n",
      "{'loss': 0.7547, 'learning_rate': 8.484848484848486e-05, 'epoch': 0.06}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab28e39ba7224ffb98ea69ec8b8c62f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.661601185798645, 'eval_runtime': 13.5887, 'eval_samples_per_second': 18.398, 'eval_steps_per_second': 3.091, 'epoch': 0.06}\n",
      "{'loss': 0.6629, 'learning_rate': 8.474747474747475e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6424, 'learning_rate': 8.464646464646466e-05, 'epoch': 0.06}\n",
      "{'loss': 0.698, 'learning_rate': 8.454545454545455e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6774, 'learning_rate': 8.444444444444444e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6579, 'learning_rate': 8.434343434343435e-05, 'epoch': 0.06}\n",
      "{'loss': 0.7477, 'learning_rate': 8.424242424242424e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6908, 'learning_rate': 8.414141414141415e-05, 'epoch': 0.06}\n",
      "{'loss': 0.7181, 'learning_rate': 8.404040404040404e-05, 'epoch': 0.06}\n",
      "{'loss': 0.7318, 'learning_rate': 8.393939393939393e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6531, 'learning_rate': 8.383838383838384e-05, 'epoch': 0.06}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9663ae261ac246c198df601e65a0573b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6621599197387695, 'eval_runtime': 13.5682, 'eval_samples_per_second': 18.425, 'eval_steps_per_second': 3.095, 'epoch': 0.06}\n",
      "{'loss': 0.704, 'learning_rate': 8.373737373737373e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6539, 'learning_rate': 8.363636363636364e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6274, 'learning_rate': 8.353535353535355e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6641, 'learning_rate': 8.343434343434344e-05, 'epoch': 0.06}\n",
      "{'loss': 0.7124, 'learning_rate': 8.333333333333334e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6988, 'learning_rate': 8.323232323232324e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6778, 'learning_rate': 8.313131313131314e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6135, 'learning_rate': 8.303030303030304e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6361, 'learning_rate': 8.292929292929293e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6977, 'learning_rate': 8.282828282828283e-05, 'epoch': 0.06}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c7a09822af74f538ff31cab7b67c3fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6601074934005737, 'eval_runtime': 13.6462, 'eval_samples_per_second': 18.32, 'eval_steps_per_second': 3.078, 'epoch': 0.06}\n",
      "{'loss': 0.6464, 'learning_rate': 8.272727272727273e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6842, 'learning_rate': 8.262626262626263e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6264, 'learning_rate': 8.252525252525253e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6103, 'learning_rate': 8.242424242424243e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6316, 'learning_rate': 8.232323232323233e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6518, 'learning_rate': 8.222222222222222e-05, 'epoch': 0.06}\n",
      "{'loss': 0.7043, 'learning_rate': 8.212121212121212e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6298, 'learning_rate': 8.202020202020202e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6173, 'learning_rate': 8.191919191919192e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6104, 'learning_rate': 8.181818181818183e-05, 'epoch': 0.06}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47f2f9848bc54d598843a81be3ad4d32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6602405905723572, 'eval_runtime': 13.6495, 'eval_samples_per_second': 18.316, 'eval_steps_per_second': 3.077, 'epoch': 0.06}\n",
      "{'loss': 0.596, 'learning_rate': 8.171717171717172e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6441, 'learning_rate': 8.161616161616163e-05, 'epoch': 0.06}\n",
      "{'loss': 0.7062, 'learning_rate': 8.151515151515152e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6546, 'learning_rate': 8.141414141414141e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6675, 'learning_rate': 8.131313131313132e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6938, 'learning_rate': 8.121212121212121e-05, 'epoch': 0.06}\n",
      "{'loss': 0.5484, 'learning_rate': 8.111111111111112e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6398, 'learning_rate': 8.101010101010101e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6704, 'learning_rate': 8.090909090909092e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6348, 'learning_rate': 8.080808080808081e-05, 'epoch': 0.06}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1141056254748159bb731d82ab8f382",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6629443168640137, 'eval_runtime': 13.6126, 'eval_samples_per_second': 18.365, 'eval_steps_per_second': 3.085, 'epoch': 0.06}\n",
      "{'loss': 0.7508, 'learning_rate': 8.07070707070707e-05, 'epoch': 0.06}\n",
      "{'loss': 0.7278, 'learning_rate': 8.060606060606061e-05, 'epoch': 0.06}\n",
      "{'loss': 0.8044, 'learning_rate': 8.05050505050505e-05, 'epoch': 0.06}\n",
      "{'loss': 0.7036, 'learning_rate': 8.040404040404041e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6695, 'learning_rate': 8.03030303030303e-05, 'epoch': 0.06}\n",
      "{'loss': 0.7212, 'learning_rate': 8.02020202020202e-05, 'epoch': 0.06}\n",
      "{'loss': 0.7018, 'learning_rate': 8.010101010101011e-05, 'epoch': 0.06}\n",
      "{'loss': 0.72, 'learning_rate': 8e-05, 'epoch': 0.06}\n",
      "{'loss': 0.7048, 'learning_rate': 7.989898989898991e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6873, 'learning_rate': 7.97979797979798e-05, 'epoch': 0.06}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20b8e2897f654f61aaa2782f640f4e9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6601124405860901, 'eval_runtime': 13.6095, 'eval_samples_per_second': 18.369, 'eval_steps_per_second': 3.086, 'epoch': 0.06}\n",
      "{'loss': 0.6411, 'learning_rate': 7.96969696969697e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6641, 'learning_rate': 7.95959595959596e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6536, 'learning_rate': 7.94949494949495e-05, 'epoch': 0.06}\n",
      "{'loss': 0.7129, 'learning_rate': 7.93939393939394e-05, 'epoch': 0.06}\n",
      "{'loss': 0.7134, 'learning_rate': 7.92929292929293e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6861, 'learning_rate': 7.919191919191919e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6949, 'learning_rate': 7.90909090909091e-05, 'epoch': 0.06}\n",
      "{'loss': 0.7033, 'learning_rate': 7.898989898989899e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6865, 'learning_rate': 7.88888888888889e-05, 'epoch': 0.06}\n",
      "{'loss': 0.7438, 'learning_rate': 7.878787878787879e-05, 'epoch': 0.06}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b109b98236b4d1381b163e71bf3f3d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6620050072669983, 'eval_runtime': 13.6127, 'eval_samples_per_second': 18.365, 'eval_steps_per_second': 3.085, 'epoch': 0.06}\n",
      "{'loss': 0.7034, 'learning_rate': 7.868686868686869e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6987, 'learning_rate': 7.858585858585859e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6851, 'learning_rate': 7.848484848484848e-05, 'epoch': 0.06}\n",
      "{'loss': 0.5845, 'learning_rate': 7.83838383838384e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6567, 'learning_rate': 7.828282828282829e-05, 'epoch': 0.06}\n",
      "{'loss': 0.669, 'learning_rate': 7.818181818181818e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6741, 'learning_rate': 7.808080808080809e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6771, 'learning_rate': 7.797979797979798e-05, 'epoch': 0.06}\n",
      "{'loss': 0.7158, 'learning_rate': 7.787878787878789e-05, 'epoch': 0.06}\n",
      "{'loss': 0.605, 'learning_rate': 7.777777777777778e-05, 'epoch': 0.06}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5f648d3c1da4da4aea156f2381aa29f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6601585745811462, 'eval_runtime': 13.6367, 'eval_samples_per_second': 18.333, 'eval_steps_per_second': 3.08, 'epoch': 0.06}\n",
      "{'loss': 0.6984, 'learning_rate': 7.767676767676769e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6532, 'learning_rate': 7.757575757575758e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6815, 'learning_rate': 7.747474747474747e-05, 'epoch': 0.06}\n",
      "{'loss': 0.5898, 'learning_rate': 7.737373737373738e-05, 'epoch': 0.06}\n",
      "{'loss': 0.696, 'learning_rate': 7.727272727272727e-05, 'epoch': 0.06}\n",
      "{'loss': 0.613, 'learning_rate': 7.717171717171718e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6018, 'learning_rate': 7.707070707070707e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6515, 'learning_rate': 7.696969696969696e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6975, 'learning_rate': 7.686868686868687e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6105, 'learning_rate': 7.676767676767676e-05, 'epoch': 0.06}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e93a39b68a2e4fb99a028ff5354a8985",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6595816612243652, 'eval_runtime': 13.5306, 'eval_samples_per_second': 18.477, 'eval_steps_per_second': 3.104, 'epoch': 0.06}\n",
      "{'loss': 0.6178, 'learning_rate': 7.666666666666667e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6459, 'learning_rate': 7.656565656565658e-05, 'epoch': 0.06}\n",
      "{'loss': 0.5994, 'learning_rate': 7.646464646464647e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6415, 'learning_rate': 7.636363636363637e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6513, 'learning_rate': 7.626262626262627e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6192, 'learning_rate': 7.616161616161617e-05, 'epoch': 0.06}\n",
      "{'loss': 0.7057, 'learning_rate': 7.606060606060607e-05, 'epoch': 0.06}\n",
      "{'loss': 0.605, 'learning_rate': 7.595959595959596e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6772, 'learning_rate': 7.585858585858586e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6614, 'learning_rate': 7.575757575757576e-05, 'epoch': 0.06}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7480a37031b423fbbc6756e1315dbeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6615853309631348, 'eval_runtime': 13.5383, 'eval_samples_per_second': 18.466, 'eval_steps_per_second': 3.102, 'epoch': 0.06}\n",
      "{'loss': 0.7065, 'learning_rate': 7.565656565656566e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6786, 'learning_rate': 7.555555555555556e-05, 'epoch': 0.06}\n",
      "{'loss': 0.7132, 'learning_rate': 7.545454545454545e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6798, 'learning_rate': 7.535353535353536e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6731, 'learning_rate': 7.525252525252525e-05, 'epoch': 0.06}\n",
      "{'loss': 0.614, 'learning_rate': 7.515151515151515e-05, 'epoch': 0.06}\n",
      "{'loss': 0.664, 'learning_rate': 7.505050505050505e-05, 'epoch': 0.06}\n",
      "{'loss': 0.623, 'learning_rate': 7.494949494949495e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6708, 'learning_rate': 7.484848484848486e-05, 'epoch': 0.06}\n",
      "{'loss': 0.655, 'learning_rate': 7.474747474747475e-05, 'epoch': 0.06}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "391122071a6243ca954615310bc16ca3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6598238348960876, 'eval_runtime': 11.9284, 'eval_samples_per_second': 20.958, 'eval_steps_per_second': 3.521, 'epoch': 0.06}\n",
      "{'loss': 0.7082, 'learning_rate': 7.464646464646466e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6738, 'learning_rate': 7.454545454545455e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6502, 'learning_rate': 7.444444444444444e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6432, 'learning_rate': 7.434343434343435e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6546, 'learning_rate': 7.424242424242424e-05, 'epoch': 0.06}\n",
      "{'loss': 0.7155, 'learning_rate': 7.414141414141415e-05, 'epoch': 0.06}\n",
      "{'loss': 0.7139, 'learning_rate': 7.404040404040404e-05, 'epoch': 0.06}\n",
      "{'loss': 0.7036, 'learning_rate': 7.393939393939395e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6277, 'learning_rate': 7.383838383838384e-05, 'epoch': 0.06}\n",
      "{'loss': 0.641, 'learning_rate': 7.373737373737373e-05, 'epoch': 0.06}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "066aa44483b24beba0ddb3b246f7cfed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6602964997291565, 'eval_runtime': 11.9269, 'eval_samples_per_second': 20.961, 'eval_steps_per_second': 3.521, 'epoch': 0.06}\n",
      "{'loss': 0.7259, 'learning_rate': 7.363636363636364e-05, 'epoch': 0.06}\n",
      "{'loss': 0.7685, 'learning_rate': 7.353535353535353e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6814, 'learning_rate': 7.343434343434344e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6909, 'learning_rate': 7.333333333333333e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6742, 'learning_rate': 7.323232323232324e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6471, 'learning_rate': 7.313131313131314e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6434, 'learning_rate': 7.303030303030304e-05, 'epoch': 0.06}\n",
      "{'loss': 0.642, 'learning_rate': 7.292929292929293e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6524, 'learning_rate': 7.282828282828284e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6953, 'learning_rate': 7.272727272727273e-05, 'epoch': 0.06}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c503eac858248998b05830af689ea80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6589701175689697, 'eval_runtime': 11.9341, 'eval_samples_per_second': 20.948, 'eval_steps_per_second': 3.519, 'epoch': 0.06}\n",
      "{'loss': 0.6847, 'learning_rate': 7.262626262626263e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6425, 'learning_rate': 7.252525252525253e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6653, 'learning_rate': 7.242424242424243e-05, 'epoch': 0.06}\n",
      "{'loss': 0.7204, 'learning_rate': 7.232323232323233e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6471, 'learning_rate': 7.222222222222222e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6603, 'learning_rate': 7.212121212121213e-05, 'epoch': 0.06}\n",
      "{'loss': 0.707, 'learning_rate': 7.202020202020202e-05, 'epoch': 0.06}\n",
      "{'loss': 0.628, 'learning_rate': 7.191919191919192e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6987, 'learning_rate': 7.181818181818182e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6321, 'learning_rate': 7.171717171717171e-05, 'epoch': 0.06}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1115e226744646cb977d7319edf6ceb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6586670875549316, 'eval_runtime': 11.9283, 'eval_samples_per_second': 20.959, 'eval_steps_per_second': 3.521, 'epoch': 0.06}\n",
      "{'loss': 0.6245, 'learning_rate': 7.161616161616162e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6343, 'learning_rate': 7.151515151515152e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6606, 'learning_rate': 7.141414141414143e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6709, 'learning_rate': 7.131313131313132e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6665, 'learning_rate': 7.121212121212121e-05, 'epoch': 0.06}\n",
      "{'loss': 0.655, 'learning_rate': 7.111111111111112e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6759, 'learning_rate': 7.101010101010101e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6465, 'learning_rate': 7.090909090909092e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6167, 'learning_rate': 7.080808080808081e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6508, 'learning_rate': 7.07070707070707e-05, 'epoch': 0.06}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27f4dcc2660847e991815ac343f0f319",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6604257822036743, 'eval_runtime': 11.9315, 'eval_samples_per_second': 20.953, 'eval_steps_per_second': 3.52, 'epoch': 0.06}\n",
      "{'loss': 0.5895, 'learning_rate': 7.060606060606061e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6312, 'learning_rate': 7.05050505050505e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6607, 'learning_rate': 7.040404040404041e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6744, 'learning_rate': 7.03030303030303e-05, 'epoch': 0.06}\n",
      "{'loss': 0.7047, 'learning_rate': 7.020202020202021e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6721, 'learning_rate': 7.01010101010101e-05, 'epoch': 0.06}\n",
      "{'loss': 0.7181, 'learning_rate': 7e-05, 'epoch': 0.06}\n",
      "{'loss': 0.7561, 'learning_rate': 6.98989898989899e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6506, 'learning_rate': 6.97979797979798e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6644, 'learning_rate': 6.96969696969697e-05, 'epoch': 0.06}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4196fd50bc794ff091277f16977306e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6594417691230774, 'eval_runtime': 11.9405, 'eval_samples_per_second': 20.937, 'eval_steps_per_second': 3.517, 'epoch': 0.06}\n",
      "{'loss': 0.6974, 'learning_rate': 6.95959595959596e-05, 'epoch': 0.06}\n",
      "{'loss': 0.7509, 'learning_rate': 6.94949494949495e-05, 'epoch': 0.06}\n",
      "{'loss': 0.716, 'learning_rate': 6.93939393939394e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6572, 'learning_rate': 6.92929292929293e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6507, 'learning_rate': 6.91919191919192e-05, 'epoch': 0.06}\n",
      "{'loss': 0.7016, 'learning_rate': 6.90909090909091e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6221, 'learning_rate': 6.898989898989899e-05, 'epoch': 0.06}\n",
      "{'loss': 0.7123, 'learning_rate': 6.88888888888889e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6588, 'learning_rate': 6.878787878787879e-05, 'epoch': 0.06}\n",
      "{'loss': 0.667, 'learning_rate': 6.86868686868687e-05, 'epoch': 0.06}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f23350e69bb413bad82162cf870f5a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6596691608428955, 'eval_runtime': 11.9444, 'eval_samples_per_second': 20.93, 'eval_steps_per_second': 3.516, 'epoch': 0.06}\n",
      "{'loss': 0.6915, 'learning_rate': 6.858585858585859e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6209, 'learning_rate': 6.848484848484848e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6574, 'learning_rate': 6.838383838383839e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6846, 'learning_rate': 6.828282828282828e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6658, 'learning_rate': 6.818181818181818e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6249, 'learning_rate': 6.808080808080809e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6593, 'learning_rate': 6.797979797979798e-05, 'epoch': 0.06}\n",
      "{'loss': 0.7037, 'learning_rate': 6.787878787878789e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6561, 'learning_rate': 6.777777777777778e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6321, 'learning_rate': 6.767676767676769e-05, 'epoch': 0.06}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03a853cdb43e4e62828efd78775e7113",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6589194536209106, 'eval_runtime': 11.9469, 'eval_samples_per_second': 20.926, 'eval_steps_per_second': 3.516, 'epoch': 0.06}\n",
      "{'loss': 0.6389, 'learning_rate': 6.757575757575758e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6608, 'learning_rate': 6.747474747474747e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6167, 'learning_rate': 6.737373737373738e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6332, 'learning_rate': 6.727272727272727e-05, 'epoch': 0.06}\n",
      "{'loss': 0.667, 'learning_rate': 6.717171717171718e-05, 'epoch': 0.06}\n",
      "{'loss': 0.693, 'learning_rate': 6.707070707070707e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6764, 'learning_rate': 6.696969696969696e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6577, 'learning_rate': 6.686868686868687e-05, 'epoch': 0.06}\n",
      "{'loss': 0.68, 'learning_rate': 6.676767676767676e-05, 'epoch': 0.06}\n",
      "{'loss': 0.7009, 'learning_rate': 6.666666666666667e-05, 'epoch': 0.06}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c07ff26bb414591a73e5270f84d64f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6578995585441589, 'eval_runtime': 11.9376, 'eval_samples_per_second': 20.942, 'eval_steps_per_second': 3.518, 'epoch': 0.06}\n",
      "{'loss': 0.6647, 'learning_rate': 6.656565656565656e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6825, 'learning_rate': 6.646464646464647e-05, 'epoch': 0.06}\n",
      "{'loss': 0.617, 'learning_rate': 6.636363636363638e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6497, 'learning_rate': 6.626262626262627e-05, 'epoch': 0.06}\n",
      "{'loss': 0.7059, 'learning_rate': 6.616161616161617e-05, 'epoch': 0.06}\n",
      "{'loss': 0.5922, 'learning_rate': 6.606060606060607e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6047, 'learning_rate': 6.595959595959596e-05, 'epoch': 0.06}\n",
      "{'loss': 0.5946, 'learning_rate': 6.585858585858587e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6655, 'learning_rate': 6.575757575757576e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6554, 'learning_rate': 6.565656565656566e-05, 'epoch': 0.06}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7154c24564ba47f4be3dc97bc870fdda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.659349799156189, 'eval_runtime': 11.9483, 'eval_samples_per_second': 20.923, 'eval_steps_per_second': 3.515, 'epoch': 0.06}\n",
      "{'loss': 0.542, 'learning_rate': 6.555555555555556e-05, 'epoch': 0.06}\n",
      "{'loss': 0.6814, 'learning_rate': 6.545454545454546e-05, 'epoch': 0.06}\n",
      "{'loss': 0.7641, 'learning_rate': 6.535353535353536e-05, 'epoch': 0.07}\n",
      "{'loss': 0.7099, 'learning_rate': 6.525252525252525e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6716, 'learning_rate': 6.515151515151516e-05, 'epoch': 0.07}\n",
      "{'loss': 0.7549, 'learning_rate': 6.505050505050505e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6523, 'learning_rate': 6.494949494949495e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6323, 'learning_rate': 6.484848484848485e-05, 'epoch': 0.07}\n",
      "{'loss': 0.7526, 'learning_rate': 6.474747474747474e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6635, 'learning_rate': 6.464646464646466e-05, 'epoch': 0.07}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e888b74d2a374489afffbc14f1cfbfaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6582999229431152, 'eval_runtime': 11.9553, 'eval_samples_per_second': 20.911, 'eval_steps_per_second': 3.513, 'epoch': 0.07}\n",
      "{'loss': 0.7062, 'learning_rate': 6.454545454545455e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6588, 'learning_rate': 6.444444444444446e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6964, 'learning_rate': 6.434343434343435e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6876, 'learning_rate': 6.424242424242424e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6682, 'learning_rate': 6.414141414141415e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6865, 'learning_rate': 6.404040404040404e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6692, 'learning_rate': 6.393939393939395e-05, 'epoch': 0.07}\n",
      "{'loss': 0.7372, 'learning_rate': 6.383838383838384e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6898, 'learning_rate': 6.373737373737373e-05, 'epoch': 0.07}\n",
      "{'loss': 0.67, 'learning_rate': 6.363636363636364e-05, 'epoch': 0.07}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ac4ca451e28481ea1fd8b8623adbf3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6587921380996704, 'eval_runtime': 11.9351, 'eval_samples_per_second': 20.947, 'eval_steps_per_second': 3.519, 'epoch': 0.07}\n",
      "{'loss': 0.6471, 'learning_rate': 6.353535353535353e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6807, 'learning_rate': 6.343434343434344e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6396, 'learning_rate': 6.333333333333333e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6928, 'learning_rate': 6.323232323232323e-05, 'epoch': 0.07}\n",
      "{'loss': 0.7176, 'learning_rate': 6.313131313131313e-05, 'epoch': 0.07}\n",
      "{'loss': 0.633, 'learning_rate': 6.303030303030302e-05, 'epoch': 0.07}\n",
      "{'loss': 0.5889, 'learning_rate': 6.292929292929294e-05, 'epoch': 0.07}\n",
      "{'loss': 0.7045, 'learning_rate': 6.282828282828284e-05, 'epoch': 0.07}\n",
      "{'loss': 0.632, 'learning_rate': 6.272727272727273e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6313, 'learning_rate': 6.262626262626264e-05, 'epoch': 0.07}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10104c66f619406c8fa892baa50376e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6578293442726135, 'eval_runtime': 11.9207, 'eval_samples_per_second': 20.972, 'eval_steps_per_second': 3.523, 'epoch': 0.07}\n",
      "{'loss': 0.6282, 'learning_rate': 6.252525252525253e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6944, 'learning_rate': 6.242424242424243e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6403, 'learning_rate': 6.232323232323233e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6782, 'learning_rate': 6.222222222222222e-05, 'epoch': 0.07}\n",
      "{'loss': 0.7134, 'learning_rate': 6.212121212121213e-05, 'epoch': 0.07}\n",
      "{'loss': 0.7034, 'learning_rate': 6.202020202020202e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6867, 'learning_rate': 6.191919191919192e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6521, 'learning_rate': 6.181818181818182e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6748, 'learning_rate': 6.171717171717172e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6574, 'learning_rate': 6.161616161616162e-05, 'epoch': 0.07}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0da6d6302c414add86a102143fb08f3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6577032208442688, 'eval_runtime': 11.9079, 'eval_samples_per_second': 20.994, 'eval_steps_per_second': 3.527, 'epoch': 0.07}\n",
      "{'loss': 0.7059, 'learning_rate': 6.151515151515151e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6068, 'learning_rate': 6.141414141414142e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6464, 'learning_rate': 6.131313131313131e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6403, 'learning_rate': 6.121212121212121e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6529, 'learning_rate': 6.111111111111112e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6435, 'learning_rate': 6.101010101010102e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6202, 'learning_rate': 6.090909090909091e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6526, 'learning_rate': 6.080808080808081e-05, 'epoch': 0.07}\n",
      "{'loss': 0.649, 'learning_rate': 6.070707070707071e-05, 'epoch': 0.07}\n",
      "{'loss': 0.5961, 'learning_rate': 6.060606060606061e-05, 'epoch': 0.07}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c2976269d0440cebfe3671f1823f82a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6586385369300842, 'eval_runtime': 11.9236, 'eval_samples_per_second': 20.967, 'eval_steps_per_second': 3.522, 'epoch': 0.07}\n",
      "{'loss': 0.6605, 'learning_rate': 6.050505050505051e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6035, 'learning_rate': 6.040404040404041e-05, 'epoch': 0.07}\n",
      "{'loss': 0.7419, 'learning_rate': 6.03030303030303e-05, 'epoch': 0.07}\n",
      "{'loss': 0.7413, 'learning_rate': 6.02020202020202e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6818, 'learning_rate': 6.01010101010101e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6249, 'learning_rate': 6e-05, 'epoch': 0.07}\n",
      "{'loss': 0.7462, 'learning_rate': 5.98989898989899e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6819, 'learning_rate': 5.97979797979798e-05, 'epoch': 0.07}\n",
      "{'loss': 0.7618, 'learning_rate': 5.969696969696969e-05, 'epoch': 0.07}\n",
      "{'loss': 0.7029, 'learning_rate': 5.959595959595959e-05, 'epoch': 0.07}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3b58ba9708c468fb019081ae2544437",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.658195436000824, 'eval_runtime': 11.9287, 'eval_samples_per_second': 20.958, 'eval_steps_per_second': 3.521, 'epoch': 0.07}\n",
      "{'loss': 0.6632, 'learning_rate': 5.949494949494949e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6689, 'learning_rate': 5.93939393939394e-05, 'epoch': 0.07}\n",
      "{'loss': 0.7001, 'learning_rate': 5.92929292929293e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6821, 'learning_rate': 5.91919191919192e-05, 'epoch': 0.07}\n",
      "{'loss': 0.7067, 'learning_rate': 5.90909090909091e-05, 'epoch': 0.07}\n",
      "{'loss': 0.7222, 'learning_rate': 5.8989898989898996e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6653, 'learning_rate': 5.8888888888888896e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6489, 'learning_rate': 5.878787878787879e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6478, 'learning_rate': 5.868686868686869e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6409, 'learning_rate': 5.858585858585859e-05, 'epoch': 0.07}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b3e13e00e59410095ee36938d8ad12c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6582894325256348, 'eval_runtime': 11.9443, 'eval_samples_per_second': 20.931, 'eval_steps_per_second': 3.516, 'epoch': 0.07}\n",
      "{'loss': 0.7003, 'learning_rate': 5.848484848484849e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6606, 'learning_rate': 5.8383838383838386e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6871, 'learning_rate': 5.8282828282828286e-05, 'epoch': 0.07}\n",
      "{'loss': 0.7001, 'learning_rate': 5.818181818181818e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6927, 'learning_rate': 5.808080808080808e-05, 'epoch': 0.07}\n",
      "{'loss': 0.7183, 'learning_rate': 5.797979797979798e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6855, 'learning_rate': 5.787878787878788e-05, 'epoch': 0.07}\n",
      "{'loss': 0.7097, 'learning_rate': 5.7777777777777776e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6508, 'learning_rate': 5.767676767676768e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6507, 'learning_rate': 5.757575757575758e-05, 'epoch': 0.07}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1643adff8a964859b7fbb1de56fb4b91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6576160788536072, 'eval_runtime': 11.9344, 'eval_samples_per_second': 20.948, 'eval_steps_per_second': 3.519, 'epoch': 0.07}\n",
      "{'loss': 0.6288, 'learning_rate': 5.747474747474748e-05, 'epoch': 0.07}\n",
      "{'loss': 0.5815, 'learning_rate': 5.737373737373738e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6421, 'learning_rate': 5.727272727272728e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6909, 'learning_rate': 5.717171717171717e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6525, 'learning_rate': 5.707070707070707e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6347, 'learning_rate': 5.696969696969697e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6959, 'learning_rate': 5.686868686868687e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6588, 'learning_rate': 5.676767676767677e-05, 'epoch': 0.07}\n",
      "{'loss': 0.7158, 'learning_rate': 5.666666666666667e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6857, 'learning_rate': 5.6565656565656563e-05, 'epoch': 0.07}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57870bace0544eb39354957ebd7a2acf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6574967503547668, 'eval_runtime': 11.9385, 'eval_samples_per_second': 20.941, 'eval_steps_per_second': 3.518, 'epoch': 0.07}\n",
      "{'loss': 0.6205, 'learning_rate': 5.646464646464646e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6392, 'learning_rate': 5.636363636363636e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6352, 'learning_rate': 5.626262626262626e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6178, 'learning_rate': 5.616161616161616e-05, 'epoch': 0.07}\n",
      "{'loss': 0.7053, 'learning_rate': 5.606060606060606e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6354, 'learning_rate': 5.595959595959597e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6695, 'learning_rate': 5.5858585858585867e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6736, 'learning_rate': 5.5757575757575766e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6495, 'learning_rate': 5.5656565656565666e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6099, 'learning_rate': 5.555555555555556e-05, 'epoch': 0.07}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "323414cf416f44df94b2137b79831e64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6582773923873901, 'eval_runtime': 11.9398, 'eval_samples_per_second': 20.938, 'eval_steps_per_second': 3.518, 'epoch': 0.07}\n",
      "{'loss': 0.7307, 'learning_rate': 5.545454545454546e-05, 'epoch': 0.07}\n",
      "{'loss': 0.662, 'learning_rate': 5.535353535353536e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6862, 'learning_rate': 5.525252525252526e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6563, 'learning_rate': 5.5151515151515156e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6718, 'learning_rate': 5.5050505050505056e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6985, 'learning_rate': 5.494949494949495e-05, 'epoch': 0.07}\n",
      "{'loss': 0.7127, 'learning_rate': 5.484848484848485e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6994, 'learning_rate': 5.474747474747475e-05, 'epoch': 0.07}\n",
      "{'loss': 0.664, 'learning_rate': 5.464646464646465e-05, 'epoch': 0.07}\n",
      "{'loss': 0.635, 'learning_rate': 5.4545454545454546e-05, 'epoch': 0.07}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6665ef6f8034a2b8e04075111adb12c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6577516794204712, 'eval_runtime': 11.9343, 'eval_samples_per_second': 20.948, 'eval_steps_per_second': 3.519, 'epoch': 0.07}\n",
      "{'loss': 0.6801, 'learning_rate': 5.4444444444444446e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6746, 'learning_rate': 5.434343434343434e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6282, 'learning_rate': 5.424242424242425e-05, 'epoch': 0.07}\n",
      "{'loss': 0.7281, 'learning_rate': 5.414141414141415e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6595, 'learning_rate': 5.4040404040404044e-05, 'epoch': 0.07}\n",
      "{'loss': 0.7551, 'learning_rate': 5.393939393939394e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6783, 'learning_rate': 5.383838383838384e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6296, 'learning_rate': 5.373737373737374e-05, 'epoch': 0.07}\n",
      "{'loss': 0.7137, 'learning_rate': 5.363636363636364e-05, 'epoch': 0.07}\n",
      "{'loss': 0.7377, 'learning_rate': 5.353535353535354e-05, 'epoch': 0.07}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9ad2d0803734c74a7aca14696a010b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6578617095947266, 'eval_runtime': 11.9425, 'eval_samples_per_second': 20.934, 'eval_steps_per_second': 3.517, 'epoch': 0.07}\n",
      "{'loss': 0.704, 'learning_rate': 5.3434343434343434e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6602, 'learning_rate': 5.333333333333333e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6444, 'learning_rate': 5.323232323232323e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6715, 'learning_rate': 5.313131313131313e-05, 'epoch': 0.07}\n",
      "{'loss': 0.7171, 'learning_rate': 5.303030303030303e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6033, 'learning_rate': 5.292929292929293e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6431, 'learning_rate': 5.2828282828282824e-05, 'epoch': 0.07}\n",
      "{'loss': 0.7198, 'learning_rate': 5.272727272727272e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6519, 'learning_rate': 5.262626262626262e-05, 'epoch': 0.07}\n",
      "{'loss': 0.624, 'learning_rate': 5.2525252525252536e-05, 'epoch': 0.07}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c31cf7d998c645ca9269fd5759a22f8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6573916077613831, 'eval_runtime': 11.9425, 'eval_samples_per_second': 20.934, 'eval_steps_per_second': 3.517, 'epoch': 0.07}\n",
      "{'loss': 0.6169, 'learning_rate': 5.242424242424243e-05, 'epoch': 0.07}\n",
      "{'loss': 0.636, 'learning_rate': 5.232323232323233e-05, 'epoch': 0.07}\n",
      "{'loss': 0.765, 'learning_rate': 5.222222222222223e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6892, 'learning_rate': 5.212121212121213e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6669, 'learning_rate': 5.2020202020202026e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6846, 'learning_rate': 5.1919191919191926e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6471, 'learning_rate': 5.181818181818182e-05, 'epoch': 0.07}\n",
      "{'loss': 0.5834, 'learning_rate': 5.171717171717172e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6912, 'learning_rate': 5.161616161616162e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6715, 'learning_rate': 5.151515151515152e-05, 'epoch': 0.07}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0bbcc9469e241bf824fd70fd498d094",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6568858623504639, 'eval_runtime': 11.946, 'eval_samples_per_second': 20.928, 'eval_steps_per_second': 3.516, 'epoch': 0.07}\n",
      "{'loss': 0.6418, 'learning_rate': 5.1414141414141416e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6652, 'learning_rate': 5.1313131313131316e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6366, 'learning_rate': 5.121212121212121e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6439, 'learning_rate': 5.111111111111111e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6227, 'learning_rate': 5.101010101010101e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6606, 'learning_rate': 5.090909090909091e-05, 'epoch': 0.07}\n",
      "{'loss': 0.5942, 'learning_rate': 5.080808080808081e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6702, 'learning_rate': 5.070707070707071e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6238, 'learning_rate': 5.060606060606061e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6159, 'learning_rate': 5.050505050505051e-05, 'epoch': 0.07}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46b2d85b913745d2ac17069ba3173fdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6585679650306702, 'eval_runtime': 11.9438, 'eval_samples_per_second': 20.931, 'eval_steps_per_second': 3.516, 'epoch': 0.07}\n",
      "{'loss': 0.7894, 'learning_rate': 5.040404040404041e-05, 'epoch': 0.07}\n",
      "{'loss': 0.8016, 'learning_rate': 5.030303030303031e-05, 'epoch': 0.07}\n",
      "{'loss': 0.7726, 'learning_rate': 5.0202020202020203e-05, 'epoch': 0.07}\n",
      "{'loss': 0.7037, 'learning_rate': 5.01010101010101e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6677, 'learning_rate': 5e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6544, 'learning_rate': 4.98989898989899e-05, 'epoch': 0.07}\n",
      "{'loss': 0.683, 'learning_rate': 4.97979797979798e-05, 'epoch': 0.07}\n",
      "{'loss': 0.7032, 'learning_rate': 4.9696969696969694e-05, 'epoch': 0.07}\n",
      "{'loss': 0.7102, 'learning_rate': 4.9595959595959594e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6918, 'learning_rate': 4.94949494949495e-05, 'epoch': 0.07}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f52588ccf3045a5bf6d12366a6a2891",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.657628059387207, 'eval_runtime': 11.9037, 'eval_samples_per_second': 21.002, 'eval_steps_per_second': 3.528, 'epoch': 0.07}\n",
      "{'loss': 0.6518, 'learning_rate': 4.93939393939394e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6434, 'learning_rate': 4.92929292929293e-05, 'epoch': 0.07}\n",
      "{'loss': 0.7019, 'learning_rate': 4.919191919191919e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6783, 'learning_rate': 4.909090909090909e-05, 'epoch': 0.07}\n",
      "{'loss': 0.7044, 'learning_rate': 4.898989898989899e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6975, 'learning_rate': 4.888888888888889e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6994, 'learning_rate': 4.878787878787879e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6944, 'learning_rate': 4.868686868686869e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6477, 'learning_rate': 4.858585858585859e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6971, 'learning_rate': 4.848484848484849e-05, 'epoch': 0.07}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5f68832f67148838523c5795cdee519",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6571594476699829, 'eval_runtime': 11.917, 'eval_samples_per_second': 20.978, 'eval_steps_per_second': 3.524, 'epoch': 0.07}\n",
      "{'loss': 0.6226, 'learning_rate': 4.838383838383839e-05, 'epoch': 0.07}\n",
      "{'loss': 0.693, 'learning_rate': 4.828282828282829e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6492, 'learning_rate': 4.8181818181818186e-05, 'epoch': 0.07}\n",
      "{'loss': 0.692, 'learning_rate': 4.808080808080808e-05, 'epoch': 0.07}\n",
      "{'loss': 0.7053, 'learning_rate': 4.797979797979798e-05, 'epoch': 0.07}\n",
      "{'loss': 0.687, 'learning_rate': 4.787878787878788e-05, 'epoch': 0.07}\n",
      "{'loss': 0.7291, 'learning_rate': 4.7777777777777784e-05, 'epoch': 0.07}\n",
      "{'loss': 0.7, 'learning_rate': 4.7676767676767684e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6938, 'learning_rate': 4.7575757575757576e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6646, 'learning_rate': 4.7474747474747476e-05, 'epoch': 0.07}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55c9e1b83d094777b2725ff08753dcaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6568325757980347, 'eval_runtime': 11.9319, 'eval_samples_per_second': 20.952, 'eval_steps_per_second': 3.52, 'epoch': 0.07}\n",
      "{'loss': 0.6906, 'learning_rate': 4.7373737373737375e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6461, 'learning_rate': 4.7272727272727275e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6901, 'learning_rate': 4.7171717171717174e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6845, 'learning_rate': 4.7070707070707074e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6153, 'learning_rate': 4.696969696969697e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6694, 'learning_rate': 4.686868686868687e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6616, 'learning_rate': 4.676767676767677e-05, 'epoch': 0.07}\n",
      "{'loss': 0.663, 'learning_rate': 4.666666666666667e-05, 'epoch': 0.07}\n",
      "{'loss': 0.608, 'learning_rate': 4.656565656565657e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6374, 'learning_rate': 4.6464646464646464e-05, 'epoch': 0.07}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d914e3370b6d4bcd9dd16c8411ffd503",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6564183831214905, 'eval_runtime': 11.929, 'eval_samples_per_second': 20.957, 'eval_steps_per_second': 3.521, 'epoch': 0.07}\n",
      "{'loss': 0.6337, 'learning_rate': 4.636363636363636e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6363, 'learning_rate': 4.626262626262626e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6446, 'learning_rate': 4.616161616161616e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6273, 'learning_rate': 4.606060606060607e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6236, 'learning_rate': 4.595959595959596e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6774, 'learning_rate': 4.585858585858586e-05, 'epoch': 0.07}\n",
      "{'loss': 0.615, 'learning_rate': 4.575757575757576e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6658, 'learning_rate': 4.565656565656566e-05, 'epoch': 0.07}\n",
      "{'loss': 0.5963, 'learning_rate': 4.555555555555556e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6636, 'learning_rate': 4.545454545454546e-05, 'epoch': 0.07}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38e3b5fb0d44433f863948c2d5520850",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6573676466941833, 'eval_runtime': 11.9321, 'eval_samples_per_second': 20.952, 'eval_steps_per_second': 3.52, 'epoch': 0.07}\n",
      "{'loss': 0.6516, 'learning_rate': 4.535353535353535e-05, 'epoch': 0.07}\n",
      "{'loss': 0.7072, 'learning_rate': 4.525252525252526e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6371, 'learning_rate': 4.515151515151516e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6612, 'learning_rate': 4.5050505050505056e-05, 'epoch': 0.07}\n",
      "{'loss': 0.759, 'learning_rate': 4.494949494949495e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6834, 'learning_rate': 4.484848484848485e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6422, 'learning_rate': 4.474747474747475e-05, 'epoch': 0.07}\n",
      "{'loss': 0.7128, 'learning_rate': 4.464646464646465e-05, 'epoch': 0.07}\n",
      "{'loss': 0.6213, 'learning_rate': 4.454545454545455e-05, 'epoch': 0.07}\n",
      "{'loss': 0.7137, 'learning_rate': 4.4444444444444447e-05, 'epoch': 0.07}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4566975f08e34c9394d13ff794e8f656",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.657257080078125, 'eval_runtime': 11.937, 'eval_samples_per_second': 20.943, 'eval_steps_per_second': 3.518, 'epoch': 0.07}\n",
      "{'loss': 0.6507, 'learning_rate': 4.4343434343434346e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6788, 'learning_rate': 4.4242424242424246e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6665, 'learning_rate': 4.4141414141414145e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6494, 'learning_rate': 4.4040404040404044e-05, 'epoch': 0.08}\n",
      "{'loss': 0.7818, 'learning_rate': 4.3939393939393944e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6888, 'learning_rate': 4.383838383838384e-05, 'epoch': 0.08}\n",
      "{'loss': 0.7008, 'learning_rate': 4.3737373737373736e-05, 'epoch': 0.08}\n",
      "{'loss': 0.7007, 'learning_rate': 4.3636363636363636e-05, 'epoch': 0.08}\n",
      "{'loss': 0.7198, 'learning_rate': 4.3535353535353535e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6641, 'learning_rate': 4.343434343434344e-05, 'epoch': 0.08}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43d543ad338d41df9382fe7c8f02ea71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6571552753448486, 'eval_runtime': 11.9424, 'eval_samples_per_second': 20.934, 'eval_steps_per_second': 3.517, 'epoch': 0.08}\n",
      "{'loss': 0.7013, 'learning_rate': 4.3333333333333334e-05, 'epoch': 0.08}\n",
      "{'loss': 0.7017, 'learning_rate': 4.3232323232323234e-05, 'epoch': 0.08}\n",
      "{'loss': 0.7082, 'learning_rate': 4.313131313131313e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6614, 'learning_rate': 4.303030303030303e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6516, 'learning_rate': 4.292929292929293e-05, 'epoch': 0.08}\n",
      "{'loss': 0.7039, 'learning_rate': 4.282828282828283e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6429, 'learning_rate': 4.2727272727272724e-05, 'epoch': 0.08}\n",
      "{'loss': 0.665, 'learning_rate': 4.262626262626263e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6579, 'learning_rate': 4.252525252525253e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6697, 'learning_rate': 4.242424242424243e-05, 'epoch': 0.08}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a26c16cb0b294151b5852356cf0ddc2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6569389700889587, 'eval_runtime': 11.9456, 'eval_samples_per_second': 20.928, 'eval_steps_per_second': 3.516, 'epoch': 0.08}\n",
      "{'loss': 0.685, 'learning_rate': 4.232323232323233e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6722, 'learning_rate': 4.222222222222222e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6025, 'learning_rate': 4.212121212121212e-05, 'epoch': 0.08}\n",
      "{'loss': 0.614, 'learning_rate': 4.202020202020202e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6471, 'learning_rate': 4.191919191919192e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6751, 'learning_rate': 4.181818181818182e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6579, 'learning_rate': 4.171717171717172e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6462, 'learning_rate': 4.161616161616162e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6364, 'learning_rate': 4.151515151515152e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6215, 'learning_rate': 4.141414141414142e-05, 'epoch': 0.08}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d93f5122b43245b9a727a1da05f00578",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6562970876693726, 'eval_runtime': 11.9449, 'eval_samples_per_second': 20.929, 'eval_steps_per_second': 3.516, 'epoch': 0.08}\n",
      "{'loss': 0.6821, 'learning_rate': 4.131313131313132e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6612, 'learning_rate': 4.1212121212121216e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6375, 'learning_rate': 4.111111111111111e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6446, 'learning_rate': 4.101010101010101e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6453, 'learning_rate': 4.0909090909090915e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6762, 'learning_rate': 4.0808080808080814e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6052, 'learning_rate': 4.070707070707071e-05, 'epoch': 0.08}\n",
      "{'loss': 0.5701, 'learning_rate': 4.0606060606060606e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6195, 'learning_rate': 4.0505050505050506e-05, 'epoch': 0.08}\n",
      "{'loss': 0.629, 'learning_rate': 4.0404040404040405e-05, 'epoch': 0.08}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22dade92291b4361a409e9cf623ddc2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6567826867103577, 'eval_runtime': 11.9372, 'eval_samples_per_second': 20.943, 'eval_steps_per_second': 3.518, 'epoch': 0.08}\n",
      "{'loss': 0.6676, 'learning_rate': 4.0303030303030305e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6249, 'learning_rate': 4.0202020202020204e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6779, 'learning_rate': 4.01010101010101e-05, 'epoch': 0.08}\n",
      "{'loss': 0.7325, 'learning_rate': 4e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6934, 'learning_rate': 3.98989898989899e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6974, 'learning_rate': 3.97979797979798e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6896, 'learning_rate': 3.96969696969697e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6772, 'learning_rate': 3.9595959595959594e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6425, 'learning_rate': 3.9494949494949494e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6819, 'learning_rate': 3.939393939393939e-05, 'epoch': 0.08}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d34f15bca444e84a386747fef041463",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.656534731388092, 'eval_runtime': 11.9518, 'eval_samples_per_second': 20.917, 'eval_steps_per_second': 3.514, 'epoch': 0.08}\n",
      "{'loss': 0.6562, 'learning_rate': 3.929292929292929e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6603, 'learning_rate': 3.91919191919192e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6571, 'learning_rate': 3.909090909090909e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6527, 'learning_rate': 3.898989898989899e-05, 'epoch': 0.08}\n",
      "{'loss': 0.638, 'learning_rate': 3.888888888888889e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6378, 'learning_rate': 3.878787878787879e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6791, 'learning_rate': 3.868686868686869e-05, 'epoch': 0.08}\n",
      "{'loss': 0.5938, 'learning_rate': 3.858585858585859e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6881, 'learning_rate': 3.848484848484848e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6126, 'learning_rate': 3.838383838383838e-05, 'epoch': 0.08}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9a9d7a8aa644e8e92349786689cd38a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6560543179512024, 'eval_runtime': 11.9284, 'eval_samples_per_second': 20.958, 'eval_steps_per_second': 3.521, 'epoch': 0.08}\n",
      "{'loss': 0.6946, 'learning_rate': 3.828282828282829e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6946, 'learning_rate': 3.818181818181819e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6903, 'learning_rate': 3.8080808080808087e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6251, 'learning_rate': 3.797979797979798e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6773, 'learning_rate': 3.787878787878788e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6794, 'learning_rate': 3.777777777777778e-05, 'epoch': 0.08}\n",
      "{'loss': 0.658, 'learning_rate': 3.767676767676768e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6458, 'learning_rate': 3.757575757575758e-05, 'epoch': 0.08}\n",
      "{'loss': 0.5927, 'learning_rate': 3.747474747474748e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6579, 'learning_rate': 3.7373737373737376e-05, 'epoch': 0.08}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "119d2f5f7f3747ea8baf1e96d9ddbdf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6558454632759094, 'eval_runtime': 11.9196, 'eval_samples_per_second': 20.974, 'eval_steps_per_second': 3.524, 'epoch': 0.08}\n",
      "{'loss': 0.6633, 'learning_rate': 3.7272727272727276e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6308, 'learning_rate': 3.7171717171717175e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6301, 'learning_rate': 3.7070707070707075e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6686, 'learning_rate': 3.6969696969696974e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6468, 'learning_rate': 3.686868686868687e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6719, 'learning_rate': 3.6767676767676766e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6918, 'learning_rate': 3.6666666666666666e-05, 'epoch': 0.08}\n",
      "{'loss': 0.7069, 'learning_rate': 3.656565656565657e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6623, 'learning_rate': 3.6464646464646465e-05, 'epoch': 0.08}\n",
      "{'loss': 0.65, 'learning_rate': 3.6363636363636364e-05, 'epoch': 0.08}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3194643c963341d29f20b4ddcb2b4ccf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.655515193939209, 'eval_runtime': 11.9419, 'eval_samples_per_second': 20.935, 'eval_steps_per_second': 3.517, 'epoch': 0.08}\n",
      "{'loss': 0.6459, 'learning_rate': 3.6262626262626264e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6094, 'learning_rate': 3.616161616161616e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6362, 'learning_rate': 3.606060606060606e-05, 'epoch': 0.08}\n",
      "{'loss': 0.606, 'learning_rate': 3.595959595959596e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6201, 'learning_rate': 3.5858585858585855e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6256, 'learning_rate': 3.575757575757576e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6026, 'learning_rate': 3.565656565656566e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6382, 'learning_rate': 3.555555555555556e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6817, 'learning_rate': 3.545454545454546e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6451, 'learning_rate': 3.535353535353535e-05, 'epoch': 0.08}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a06ed7be7304a0b97c8730a49de2661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6562878489494324, 'eval_runtime': 11.9266, 'eval_samples_per_second': 20.962, 'eval_steps_per_second': 3.522, 'epoch': 0.08}\n",
      "{'loss': 0.692, 'learning_rate': 3.525252525252525e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6124, 'learning_rate': 3.515151515151515e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6238, 'learning_rate': 3.505050505050505e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6731, 'learning_rate': 3.494949494949495e-05, 'epoch': 0.08}\n",
      "{'loss': 0.638, 'learning_rate': 3.484848484848485e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6806, 'learning_rate': 3.474747474747475e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6498, 'learning_rate': 3.464646464646465e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6282, 'learning_rate': 3.454545454545455e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6318, 'learning_rate': 3.444444444444445e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6452, 'learning_rate': 3.434343434343435e-05, 'epoch': 0.08}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5783b1b34814a648cef86e9b4a58678",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6561543941497803, 'eval_runtime': 11.9351, 'eval_samples_per_second': 20.947, 'eval_steps_per_second': 3.519, 'epoch': 0.08}\n",
      "{'loss': 0.6935, 'learning_rate': 3.424242424242424e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6553, 'learning_rate': 3.414141414141414e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6647, 'learning_rate': 3.4040404040404045e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6849, 'learning_rate': 3.3939393939393945e-05, 'epoch': 0.08}\n",
      "{'loss': 0.7151, 'learning_rate': 3.3838383838383844e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6523, 'learning_rate': 3.373737373737374e-05, 'epoch': 0.08}\n",
      "{'loss': 0.7252, 'learning_rate': 3.3636363636363636e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6341, 'learning_rate': 3.3535353535353536e-05, 'epoch': 0.08}\n",
      "{'loss': 0.7055, 'learning_rate': 3.3434343434343435e-05, 'epoch': 0.08}\n",
      "{'loss': 0.683, 'learning_rate': 3.3333333333333335e-05, 'epoch': 0.08}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ade88ef0f76644e8a3056fb19f94c5a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6558624505996704, 'eval_runtime': 11.9399, 'eval_samples_per_second': 20.938, 'eval_steps_per_second': 3.518, 'epoch': 0.08}\n",
      "{'loss': 0.6382, 'learning_rate': 3.3232323232323234e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6564, 'learning_rate': 3.3131313131313134e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6397, 'learning_rate': 3.303030303030303e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6765, 'learning_rate': 3.292929292929293e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6881, 'learning_rate': 3.282828282828283e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6612, 'learning_rate': 3.272727272727273e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6689, 'learning_rate': 3.2626262626262624e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6964, 'learning_rate': 3.2525252525252524e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6567, 'learning_rate': 3.2424242424242423e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6582, 'learning_rate': 3.232323232323233e-05, 'epoch': 0.08}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f52ba21f4049442c8d39206b955a2ab7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6559213399887085, 'eval_runtime': 11.9346, 'eval_samples_per_second': 20.947, 'eval_steps_per_second': 3.519, 'epoch': 0.08}\n",
      "{'loss': 0.684, 'learning_rate': 3.222222222222223e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6927, 'learning_rate': 3.212121212121212e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6605, 'learning_rate': 3.202020202020202e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6371, 'learning_rate': 3.191919191919192e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6187, 'learning_rate': 3.181818181818182e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6797, 'learning_rate': 3.171717171717172e-05, 'epoch': 0.08}\n",
      "{'loss': 0.5992, 'learning_rate': 3.161616161616161e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6495, 'learning_rate': 3.151515151515151e-05, 'epoch': 0.08}\n",
      "{'loss': 0.5977, 'learning_rate': 3.141414141414142e-05, 'epoch': 0.08}\n",
      "{'loss': 0.5975, 'learning_rate': 3.131313131313132e-05, 'epoch': 0.08}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72d2a381e3b349e8870e7ce234b7f0b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.655439555644989, 'eval_runtime': 11.9543, 'eval_samples_per_second': 20.913, 'eval_steps_per_second': 3.513, 'epoch': 0.08}\n",
      "{'loss': 0.674, 'learning_rate': 3.121212121212122e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6545, 'learning_rate': 3.111111111111111e-05, 'epoch': 0.08}\n",
      "{'loss': 0.7598, 'learning_rate': 3.101010101010101e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6087, 'learning_rate': 3.090909090909091e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6776, 'learning_rate': 3.080808080808081e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6116, 'learning_rate': 3.070707070707071e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6947, 'learning_rate': 3.060606060606061e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6488, 'learning_rate': 3.050505050505051e-05, 'epoch': 0.08}\n",
      "{'loss': 0.7137, 'learning_rate': 3.0404040404040406e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6353, 'learning_rate': 3.0303030303030306e-05, 'epoch': 0.08}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2638795a6f1d469fae9b9a854c88e3e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6557064056396484, 'eval_runtime': 11.9406, 'eval_samples_per_second': 20.937, 'eval_steps_per_second': 3.517, 'epoch': 0.08}\n",
      "{'loss': 0.6058, 'learning_rate': 3.0202020202020205e-05, 'epoch': 0.08}\n",
      "{'loss': 0.7227, 'learning_rate': 3.01010101010101e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6845, 'learning_rate': 3e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6517, 'learning_rate': 2.98989898989899e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6665, 'learning_rate': 2.9797979797979796e-05, 'epoch': 0.08}\n",
      "{'loss': 0.676, 'learning_rate': 2.96969696969697e-05, 'epoch': 0.08}\n",
      "{'loss': 0.7098, 'learning_rate': 2.95959595959596e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6872, 'learning_rate': 2.9494949494949498e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6902, 'learning_rate': 2.9393939393939394e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6889, 'learning_rate': 2.9292929292929294e-05, 'epoch': 0.08}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7541bc4b644420ca545faa4ed333d64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6556941866874695, 'eval_runtime': 11.952, 'eval_samples_per_second': 20.917, 'eval_steps_per_second': 3.514, 'epoch': 0.08}\n",
      "{'loss': 0.7243, 'learning_rate': 2.9191919191919193e-05, 'epoch': 0.08}\n",
      "{'loss': 0.7087, 'learning_rate': 2.909090909090909e-05, 'epoch': 0.08}\n",
      "{'loss': 0.7995, 'learning_rate': 2.898989898989899e-05, 'epoch': 0.08}\n",
      "{'loss': 0.7069, 'learning_rate': 2.8888888888888888e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6345, 'learning_rate': 2.878787878787879e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6488, 'learning_rate': 2.868686868686869e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6598, 'learning_rate': 2.8585858585858587e-05, 'epoch': 0.08}\n",
      "{'loss': 0.671, 'learning_rate': 2.8484848484848486e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6809, 'learning_rate': 2.8383838383838386e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6681, 'learning_rate': 2.8282828282828282e-05, 'epoch': 0.08}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86f3b98ee44447608c6f7060dcfa7f91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6552347540855408, 'eval_runtime': 11.9453, 'eval_samples_per_second': 20.929, 'eval_steps_per_second': 3.516, 'epoch': 0.08}\n",
      "{'loss': 0.6933, 'learning_rate': 2.818181818181818e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6654, 'learning_rate': 2.808080808080808e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6733, 'learning_rate': 2.7979797979797984e-05, 'epoch': 0.08}\n",
      "{'loss': 0.686, 'learning_rate': 2.7878787878787883e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6507, 'learning_rate': 2.777777777777778e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6462, 'learning_rate': 2.767676767676768e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6791, 'learning_rate': 2.7575757575757578e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6864, 'learning_rate': 2.7474747474747474e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6524, 'learning_rate': 2.7373737373737374e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6554, 'learning_rate': 2.7272727272727273e-05, 'epoch': 0.08}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18f086489c0f4496ac7f0265c850e588",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6553255319595337, 'eval_runtime': 11.9159, 'eval_samples_per_second': 20.98, 'eval_steps_per_second': 3.525, 'epoch': 0.08}\n",
      "{'loss': 0.6869, 'learning_rate': 2.717171717171717e-05, 'epoch': 0.08}\n",
      "{'loss': 0.7206, 'learning_rate': 2.7070707070707075e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6759, 'learning_rate': 2.696969696969697e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6901, 'learning_rate': 2.686868686868687e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6529, 'learning_rate': 2.676767676767677e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6429, 'learning_rate': 2.6666666666666667e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6082, 'learning_rate': 2.6565656565656566e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6159, 'learning_rate': 2.6464646464646466e-05, 'epoch': 0.08}\n",
      "{'loss': 0.5943, 'learning_rate': 2.636363636363636e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6359, 'learning_rate': 2.6262626262626268e-05, 'epoch': 0.08}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53363deab49248f0aeadf2388e9a33c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6550354361534119, 'eval_runtime': 11.922, 'eval_samples_per_second': 20.97, 'eval_steps_per_second': 3.523, 'epoch': 0.08}\n",
      "{'loss': 0.6431, 'learning_rate': 2.6161616161616164e-05, 'epoch': 0.08}\n",
      "{'loss': 0.671, 'learning_rate': 2.6060606060606063e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6707, 'learning_rate': 2.5959595959595963e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6277, 'learning_rate': 2.585858585858586e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6384, 'learning_rate': 2.575757575757576e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6551, 'learning_rate': 2.5656565656565658e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6453, 'learning_rate': 2.5555555555555554e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6394, 'learning_rate': 2.5454545454545454e-05, 'epoch': 0.08}\n",
      "{'loss': 0.636, 'learning_rate': 2.5353535353535356e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6441, 'learning_rate': 2.5252525252525256e-05, 'epoch': 0.08}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d53ba309f2a34aaca34a2b591fc33b2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6553594470024109, 'eval_runtime': 11.9235, 'eval_samples_per_second': 20.967, 'eval_steps_per_second': 3.522, 'epoch': 0.08}\n",
      "{'loss': 0.6133, 'learning_rate': 2.5151515151515155e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6366, 'learning_rate': 2.505050505050505e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6596, 'learning_rate': 2.494949494949495e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6532, 'learning_rate': 2.4848484848484847e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6764, 'learning_rate': 2.474747474747475e-05, 'epoch': 0.08}\n",
      "{'loss': 0.7283, 'learning_rate': 2.464646464646465e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6583, 'learning_rate': 2.4545454545454545e-05, 'epoch': 0.08}\n",
      "{'loss': 0.7277, 'learning_rate': 2.4444444444444445e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6946, 'learning_rate': 2.4343434343434344e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6946, 'learning_rate': 2.4242424242424244e-05, 'epoch': 0.08}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26cdc67aa55c4cdf87f76d12876472ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6555597186088562, 'eval_runtime': 11.9339, 'eval_samples_per_second': 20.949, 'eval_steps_per_second': 3.519, 'epoch': 0.08}\n",
      "{'loss': 0.6975, 'learning_rate': 2.4141414141414143e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6363, 'learning_rate': 2.404040404040404e-05, 'epoch': 0.08}\n",
      "{'loss': 0.714, 'learning_rate': 2.393939393939394e-05, 'epoch': 0.08}\n",
      "{'loss': 0.65, 'learning_rate': 2.3838383838383842e-05, 'epoch': 0.08}\n",
      "{'loss': 0.748, 'learning_rate': 2.3737373737373738e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6463, 'learning_rate': 2.3636363636363637e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6843, 'learning_rate': 2.3535353535353537e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6393, 'learning_rate': 2.3434343434343436e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6462, 'learning_rate': 2.3333333333333336e-05, 'epoch': 0.08}\n",
      "{'loss': 0.6466, 'learning_rate': 2.3232323232323232e-05, 'epoch': 0.09}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f653bb2e2aff4f9696fb6f7b946c5190",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6550632119178772, 'eval_runtime': 11.9423, 'eval_samples_per_second': 20.934, 'eval_steps_per_second': 3.517, 'epoch': 0.09}\n",
      "{'loss': 0.6468, 'learning_rate': 2.313131313131313e-05, 'epoch': 0.09}\n",
      "{'loss': 0.7708, 'learning_rate': 2.3030303030303034e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6153, 'learning_rate': 2.292929292929293e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6738, 'learning_rate': 2.282828282828283e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6801, 'learning_rate': 2.272727272727273e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6922, 'learning_rate': 2.262626262626263e-05, 'epoch': 0.09}\n",
      "{'loss': 0.691, 'learning_rate': 2.2525252525252528e-05, 'epoch': 0.09}\n",
      "{'loss': 0.696, 'learning_rate': 2.2424242424242424e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6582, 'learning_rate': 2.2323232323232324e-05, 'epoch': 0.09}\n",
      "{'loss': 0.5984, 'learning_rate': 2.2222222222222223e-05, 'epoch': 0.09}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0acb92264ec4479abc324b3c5902a5aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6553144454956055, 'eval_runtime': 11.95, 'eval_samples_per_second': 20.92, 'eval_steps_per_second': 3.515, 'epoch': 0.09}\n",
      "{'loss': 0.6764, 'learning_rate': 2.2121212121212123e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6475, 'learning_rate': 2.2020202020202022e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6139, 'learning_rate': 2.191919191919192e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6627, 'learning_rate': 2.1818181818181818e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6466, 'learning_rate': 2.171717171717172e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6302, 'learning_rate': 2.1616161616161617e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6041, 'learning_rate': 2.1515151515151516e-05, 'epoch': 0.09}\n",
      "{'loss': 0.719, 'learning_rate': 2.1414141414141416e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6287, 'learning_rate': 2.1313131313131315e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6419, 'learning_rate': 2.1212121212121215e-05, 'epoch': 0.09}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68acb64e1d6a44ea93f715784e51e171",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6549475789070129, 'eval_runtime': 11.9483, 'eval_samples_per_second': 20.923, 'eval_steps_per_second': 3.515, 'epoch': 0.09}\n",
      "{'loss': 0.6976, 'learning_rate': 2.111111111111111e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6158, 'learning_rate': 2.101010101010101e-05, 'epoch': 0.09}\n",
      "{'loss': 0.5827, 'learning_rate': 2.090909090909091e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6277, 'learning_rate': 2.080808080808081e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6858, 'learning_rate': 2.070707070707071e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6575, 'learning_rate': 2.0606060606060608e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6938, 'learning_rate': 2.0505050505050504e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6251, 'learning_rate': 2.0404040404040407e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6727, 'learning_rate': 2.0303030303030303e-05, 'epoch': 0.09}\n",
      "{'loss': 0.5928, 'learning_rate': 2.0202020202020203e-05, 'epoch': 0.09}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61211bacec684bcea851b999aa97aac3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6547052264213562, 'eval_runtime': 11.9521, 'eval_samples_per_second': 20.917, 'eval_steps_per_second': 3.514, 'epoch': 0.09}\n",
      "{'loss': 0.6422, 'learning_rate': 2.0101010101010102e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6819, 'learning_rate': 2e-05, 'epoch': 0.09}\n",
      "{'loss': 0.7747, 'learning_rate': 1.98989898989899e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6943, 'learning_rate': 1.9797979797979797e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6706, 'learning_rate': 1.9696969696969697e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6547, 'learning_rate': 1.95959595959596e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6176, 'learning_rate': 1.9494949494949496e-05, 'epoch': 0.09}\n",
      "{'loss': 0.7502, 'learning_rate': 1.9393939393939395e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6996, 'learning_rate': 1.9292929292929295e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6836, 'learning_rate': 1.919191919191919e-05, 'epoch': 0.09}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "358822dd506e48fca0b792fa5d1d31cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6548425555229187, 'eval_runtime': 11.944, 'eval_samples_per_second': 20.931, 'eval_steps_per_second': 3.516, 'epoch': 0.09}\n",
      "{'loss': 0.6451, 'learning_rate': 1.9090909090909094e-05, 'epoch': 0.09}\n",
      "{'loss': 0.7129, 'learning_rate': 1.898989898989899e-05, 'epoch': 0.09}\n",
      "{'loss': 0.692, 'learning_rate': 1.888888888888889e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6178, 'learning_rate': 1.878787878787879e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6517, 'learning_rate': 1.8686868686868688e-05, 'epoch': 0.09}\n",
      "{'loss': 0.7164, 'learning_rate': 1.8585858585858588e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6488, 'learning_rate': 1.8484848484848487e-05, 'epoch': 0.09}\n",
      "{'loss': 0.7159, 'learning_rate': 1.8383838383838383e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6645, 'learning_rate': 1.8282828282828286e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6211, 'learning_rate': 1.8181818181818182e-05, 'epoch': 0.09}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8af3d0110504a148e23970bcda805e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6546996235847473, 'eval_runtime': 11.9585, 'eval_samples_per_second': 20.906, 'eval_steps_per_second': 3.512, 'epoch': 0.09}\n",
      "{'loss': 0.7335, 'learning_rate': 1.808080808080808e-05, 'epoch': 0.09}\n",
      "{'loss': 0.7293, 'learning_rate': 1.797979797979798e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6591, 'learning_rate': 1.787878787878788e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6736, 'learning_rate': 1.777777777777778e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6363, 'learning_rate': 1.7676767676767676e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6525, 'learning_rate': 1.7575757575757576e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6278, 'learning_rate': 1.7474747474747475e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6612, 'learning_rate': 1.7373737373737375e-05, 'epoch': 0.09}\n",
      "{'loss': 0.607, 'learning_rate': 1.7272727272727274e-05, 'epoch': 0.09}\n",
      "{'loss': 0.677, 'learning_rate': 1.7171717171717173e-05, 'epoch': 0.09}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c87d16cf5ef844a5ac10c902fd7f13fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6547916531562805, 'eval_runtime': 11.9267, 'eval_samples_per_second': 20.961, 'eval_steps_per_second': 3.522, 'epoch': 0.09}\n",
      "{'loss': 0.6607, 'learning_rate': 1.707070707070707e-05, 'epoch': 0.09}\n",
      "{'loss': 0.7253, 'learning_rate': 1.6969696969696972e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6156, 'learning_rate': 1.686868686868687e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6915, 'learning_rate': 1.6767676767676768e-05, 'epoch': 0.09}\n",
      "{'loss': 0.662, 'learning_rate': 1.6666666666666667e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6681, 'learning_rate': 1.6565656565656567e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6776, 'learning_rate': 1.6464646464646466e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6399, 'learning_rate': 1.6363636363636366e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6816, 'learning_rate': 1.6262626262626262e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6543, 'learning_rate': 1.6161616161616165e-05, 'epoch': 0.09}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "607f9be0cde44f2f9322a4101777466b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6546362042427063, 'eval_runtime': 11.9162, 'eval_samples_per_second': 20.98, 'eval_steps_per_second': 3.525, 'epoch': 0.09}\n",
      "{'loss': 0.6598, 'learning_rate': 1.606060606060606e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6281, 'learning_rate': 1.595959595959596e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6952, 'learning_rate': 1.585858585858586e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6548, 'learning_rate': 1.5757575757575756e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6396, 'learning_rate': 1.565656565656566e-05, 'epoch': 0.09}\n",
      "{'loss': 0.5974, 'learning_rate': 1.5555555555555555e-05, 'epoch': 0.09}\n",
      "{'loss': 0.627, 'learning_rate': 1.5454545454545454e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6722, 'learning_rate': 1.5353535353535354e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6432, 'learning_rate': 1.5252525252525255e-05, 'epoch': 0.09}\n",
      "{'loss': 0.592, 'learning_rate': 1.5151515151515153e-05, 'epoch': 0.09}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a40d432c099f496c847af573fe932559",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6545441746711731, 'eval_runtime': 11.9226, 'eval_samples_per_second': 20.969, 'eval_steps_per_second': 3.523, 'epoch': 0.09}\n",
      "{'loss': 0.6017, 'learning_rate': 1.505050505050505e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6466, 'learning_rate': 1.494949494949495e-05, 'epoch': 0.09}\n",
      "{'loss': 0.698, 'learning_rate': 1.484848484848485e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6602, 'learning_rate': 1.4747474747474749e-05, 'epoch': 0.09}\n",
      "{'loss': 0.7494, 'learning_rate': 1.4646464646464647e-05, 'epoch': 0.09}\n",
      "{'loss': 0.7258, 'learning_rate': 1.4545454545454545e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6852, 'learning_rate': 1.4444444444444444e-05, 'epoch': 0.09}\n",
      "{'loss': 0.7029, 'learning_rate': 1.4343434343434345e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6654, 'learning_rate': 1.4242424242424243e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6754, 'learning_rate': 1.4141414141414141e-05, 'epoch': 0.09}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fb2793b98d843f6810facfdeee2c72f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6546444892883301, 'eval_runtime': 11.9361, 'eval_samples_per_second': 20.945, 'eval_steps_per_second': 3.519, 'epoch': 0.09}\n",
      "{'loss': 0.6665, 'learning_rate': 1.404040404040404e-05, 'epoch': 0.09}\n",
      "{'loss': 0.7867, 'learning_rate': 1.3939393939393942e-05, 'epoch': 0.09}\n",
      "{'loss': 0.732, 'learning_rate': 1.383838383838384e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6675, 'learning_rate': 1.3737373737373737e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6959, 'learning_rate': 1.3636363636363637e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6946, 'learning_rate': 1.3535353535353538e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6594, 'learning_rate': 1.3434343434343436e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6745, 'learning_rate': 1.3333333333333333e-05, 'epoch': 0.09}\n",
      "{'loss': 0.7217, 'learning_rate': 1.3232323232323233e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6574, 'learning_rate': 1.3131313131313134e-05, 'epoch': 0.09}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b12d2aad416042ba94f453d895ab6cda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6544700860977173, 'eval_runtime': 11.9451, 'eval_samples_per_second': 20.929, 'eval_steps_per_second': 3.516, 'epoch': 0.09}\n",
      "{'loss': 0.6417, 'learning_rate': 1.3030303030303032e-05, 'epoch': 0.09}\n",
      "{'loss': 0.7095, 'learning_rate': 1.292929292929293e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6469, 'learning_rate': 1.2828282828282829e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6431, 'learning_rate': 1.2727272727272727e-05, 'epoch': 0.09}\n",
      "{'loss': 0.7208, 'learning_rate': 1.2626262626262628e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6634, 'learning_rate': 1.2525252525252526e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6403, 'learning_rate': 1.2424242424242424e-05, 'epoch': 0.09}\n",
      "{'loss': 0.5975, 'learning_rate': 1.2323232323232325e-05, 'epoch': 0.09}\n",
      "{'loss': 0.628, 'learning_rate': 1.2222222222222222e-05, 'epoch': 0.09}\n",
      "{'loss': 0.619, 'learning_rate': 1.2121212121212122e-05, 'epoch': 0.09}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "017f0551123e415fabf3307e7b393980",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6544524431228638, 'eval_runtime': 11.9387, 'eval_samples_per_second': 20.94, 'eval_steps_per_second': 3.518, 'epoch': 0.09}\n",
      "{'loss': 0.6585, 'learning_rate': 1.202020202020202e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6676, 'learning_rate': 1.1919191919191921e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6888, 'learning_rate': 1.1818181818181819e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6707, 'learning_rate': 1.1717171717171718e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6939, 'learning_rate': 1.1616161616161616e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6961, 'learning_rate': 1.1515151515151517e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6797, 'learning_rate': 1.1414141414141415e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6621, 'learning_rate': 1.1313131313131314e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6544, 'learning_rate': 1.1212121212121212e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6574, 'learning_rate': 1.1111111111111112e-05, 'epoch': 0.09}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b20e8aab2e9649768a0f0462a280a73c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6544018983840942, 'eval_runtime': 11.9522, 'eval_samples_per_second': 20.917, 'eval_steps_per_second': 3.514, 'epoch': 0.09}\n",
      "{'loss': 0.5896, 'learning_rate': 1.1010101010101011e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6102, 'learning_rate': 1.0909090909090909e-05, 'epoch': 0.09}\n",
      "{'loss': 0.613, 'learning_rate': 1.0808080808080808e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6503, 'learning_rate': 1.0707070707070708e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6175, 'learning_rate': 1.0606060606060607e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6739, 'learning_rate': 1.0505050505050505e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6432, 'learning_rate': 1.0404040404040405e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6509, 'learning_rate': 1.0303030303030304e-05, 'epoch': 0.09}\n",
      "{'loss': 0.634, 'learning_rate': 1.0202020202020204e-05, 'epoch': 0.09}\n",
      "{'loss': 0.5846, 'learning_rate': 1.0101010101010101e-05, 'epoch': 0.09}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d0e855aa46e4d349ff8a7808c33efe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6543157696723938, 'eval_runtime': 11.9407, 'eval_samples_per_second': 20.937, 'eval_steps_per_second': 3.517, 'epoch': 0.09}\n",
      "{'loss': 0.783, 'learning_rate': 1e-05, 'epoch': 0.09}\n",
      "{'loss': 0.6292, 'learning_rate': 9.898989898989899e-06, 'epoch': 0.09}\n",
      "{'loss': 0.726, 'learning_rate': 9.7979797979798e-06, 'epoch': 0.09}\n",
      "{'loss': 0.6551, 'learning_rate': 9.696969696969698e-06, 'epoch': 0.09}\n",
      "{'loss': 0.6344, 'learning_rate': 9.595959595959595e-06, 'epoch': 0.09}\n",
      "{'loss': 0.7406, 'learning_rate': 9.494949494949495e-06, 'epoch': 0.09}\n",
      "{'loss': 0.671, 'learning_rate': 9.393939393939394e-06, 'epoch': 0.09}\n",
      "{'loss': 0.6399, 'learning_rate': 9.292929292929294e-06, 'epoch': 0.09}\n",
      "{'loss': 0.714, 'learning_rate': 9.191919191919192e-06, 'epoch': 0.09}\n",
      "{'loss': 0.6695, 'learning_rate': 9.090909090909091e-06, 'epoch': 0.09}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "985a4a2e3eef44fbab6393395adf88a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6543260216712952, 'eval_runtime': 11.9481, 'eval_samples_per_second': 20.924, 'eval_steps_per_second': 3.515, 'epoch': 0.09}\n",
      "{'loss': 0.6362, 'learning_rate': 8.98989898989899e-06, 'epoch': 0.09}\n",
      "{'loss': 0.6492, 'learning_rate': 8.88888888888889e-06, 'epoch': 0.09}\n",
      "{'loss': 0.7079, 'learning_rate': 8.787878787878788e-06, 'epoch': 0.09}\n",
      "{'loss': 0.7222, 'learning_rate': 8.686868686868687e-06, 'epoch': 0.09}\n",
      "{'loss': 0.6675, 'learning_rate': 8.585858585858587e-06, 'epoch': 0.09}\n",
      "{'loss': 0.6245, 'learning_rate': 8.484848484848486e-06, 'epoch': 0.09}\n",
      "{'loss': 0.6952, 'learning_rate': 8.383838383838384e-06, 'epoch': 0.09}\n",
      "{'loss': 0.6707, 'learning_rate': 8.282828282828283e-06, 'epoch': 0.09}\n",
      "{'loss': 0.6641, 'learning_rate': 8.181818181818183e-06, 'epoch': 0.09}\n",
      "{'loss': 0.6894, 'learning_rate': 8.080808080808082e-06, 'epoch': 0.09}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d2ad9e99e3441fbb41e30962d43bc01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6542685031890869, 'eval_runtime': 11.951, 'eval_samples_per_second': 20.919, 'eval_steps_per_second': 3.514, 'epoch': 0.09}\n",
      "{'loss': 0.6553, 'learning_rate': 7.97979797979798e-06, 'epoch': 0.09}\n",
      "{'loss': 0.7304, 'learning_rate': 7.878787878787878e-06, 'epoch': 0.09}\n",
      "{'loss': 0.7351, 'learning_rate': 7.777777777777777e-06, 'epoch': 0.09}\n",
      "{'loss': 0.5928, 'learning_rate': 7.676767676767677e-06, 'epoch': 0.09}\n",
      "{'loss': 0.6124, 'learning_rate': 7.5757575757575764e-06, 'epoch': 0.09}\n",
      "{'loss': 0.6179, 'learning_rate': 7.474747474747475e-06, 'epoch': 0.09}\n",
      "{'loss': 0.7484, 'learning_rate': 7.3737373737373745e-06, 'epoch': 0.09}\n",
      "{'loss': 0.625, 'learning_rate': 7.272727272727272e-06, 'epoch': 0.09}\n",
      "{'loss': 0.6368, 'learning_rate': 7.171717171717173e-06, 'epoch': 0.09}\n",
      "{'loss': 0.6987, 'learning_rate': 7.0707070707070704e-06, 'epoch': 0.09}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41917b943d5e4680ba55e54a91bbf4b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6542194485664368, 'eval_runtime': 11.9611, 'eval_samples_per_second': 20.901, 'eval_steps_per_second': 3.511, 'epoch': 0.09}\n",
      "{'loss': 0.6409, 'learning_rate': 6.969696969696971e-06, 'epoch': 0.09}\n",
      "{'loss': 0.663, 'learning_rate': 6.8686868686868685e-06, 'epoch': 0.09}\n",
      "{'loss': 0.683, 'learning_rate': 6.767676767676769e-06, 'epoch': 0.09}\n",
      "{'loss': 0.7012, 'learning_rate': 6.666666666666667e-06, 'epoch': 0.09}\n",
      "{'loss': 0.6337, 'learning_rate': 6.565656565656567e-06, 'epoch': 0.09}\n",
      "{'loss': 0.6854, 'learning_rate': 6.464646464646465e-06, 'epoch': 0.09}\n",
      "{'loss': 0.6368, 'learning_rate': 6.363636363636363e-06, 'epoch': 0.09}\n",
      "{'loss': 0.6073, 'learning_rate': 6.262626262626263e-06, 'epoch': 0.09}\n",
      "{'loss': 0.637, 'learning_rate': 6.161616161616162e-06, 'epoch': 0.09}\n",
      "{'loss': 0.7889, 'learning_rate': 6.060606060606061e-06, 'epoch': 0.09}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a7e4590bd3441278493c046e3b7e8bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6542031764984131, 'eval_runtime': 11.9485, 'eval_samples_per_second': 20.923, 'eval_steps_per_second': 3.515, 'epoch': 0.09}\n",
      "{'loss': 0.6174, 'learning_rate': 5.9595959595959605e-06, 'epoch': 0.09}\n",
      "{'loss': 0.6494, 'learning_rate': 5.858585858585859e-06, 'epoch': 0.09}\n",
      "{'loss': 0.6042, 'learning_rate': 5.7575757575757586e-06, 'epoch': 0.09}\n",
      "{'loss': 0.6377, 'learning_rate': 5.656565656565657e-06, 'epoch': 0.09}\n",
      "{'loss': 0.6306, 'learning_rate': 5.555555555555556e-06, 'epoch': 0.09}\n",
      "{'loss': 0.6113, 'learning_rate': 5.4545454545454545e-06, 'epoch': 0.09}\n",
      "{'loss': 0.644, 'learning_rate': 5.353535353535354e-06, 'epoch': 0.09}\n",
      "{'loss': 0.6376, 'learning_rate': 5.2525252525252526e-06, 'epoch': 0.09}\n",
      "{'loss': 0.6125, 'learning_rate': 5.151515151515152e-06, 'epoch': 0.09}\n",
      "{'loss': 0.6278, 'learning_rate': 5.050505050505051e-06, 'epoch': 0.09}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92f2db82bf7d45808c767b86c52707a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6541908383369446, 'eval_runtime': 11.9444, 'eval_samples_per_second': 20.93, 'eval_steps_per_second': 3.516, 'epoch': 0.09}\n",
      "{'loss': 0.6074, 'learning_rate': 4.949494949494949e-06, 'epoch': 0.09}\n",
      "{'loss': 0.6976, 'learning_rate': 4.848484848484849e-06, 'epoch': 0.09}\n",
      "{'loss': 0.6377, 'learning_rate': 4.747474747474747e-06, 'epoch': 0.09}\n",
      "{'loss': 0.6561, 'learning_rate': 4.646464646464647e-06, 'epoch': 0.09}\n",
      "{'loss': 0.6828, 'learning_rate': 4.5454545454545455e-06, 'epoch': 0.09}\n",
      "{'loss': 0.6228, 'learning_rate': 4.444444444444445e-06, 'epoch': 0.09}\n",
      "{'loss': 0.7293, 'learning_rate': 4.343434343434344e-06, 'epoch': 0.09}\n",
      "{'loss': 0.6761, 'learning_rate': 4.242424242424243e-06, 'epoch': 0.09}\n",
      "{'loss': 0.6778, 'learning_rate': 4.141414141414142e-06, 'epoch': 0.09}\n",
      "{'loss': 0.5905, 'learning_rate': 4.040404040404041e-06, 'epoch': 0.09}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4b4a873ff2c414a816def55638d3b04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6541656255722046, 'eval_runtime': 13.5956, 'eval_samples_per_second': 18.388, 'eval_steps_per_second': 3.089, 'epoch': 0.09}\n",
      "{'loss': 0.7001, 'learning_rate': 3.939393939393939e-06, 'epoch': 0.09}\n",
      "{'loss': 0.6563, 'learning_rate': 3.8383838383838385e-06, 'epoch': 0.09}\n",
      "{'loss': 0.6958, 'learning_rate': 3.7373737373737375e-06, 'epoch': 0.09}\n",
      "{'loss': 0.6391, 'learning_rate': 3.636363636363636e-06, 'epoch': 0.09}\n",
      "{'loss': 0.7471, 'learning_rate': 3.5353535353535352e-06, 'epoch': 0.09}\n",
      "{'loss': 0.7052, 'learning_rate': 3.4343434343434343e-06, 'epoch': 0.09}\n",
      "{'loss': 0.7305, 'learning_rate': 3.3333333333333333e-06, 'epoch': 0.09}\n",
      "{'loss': 0.6776, 'learning_rate': 3.2323232323232324e-06, 'epoch': 0.09}\n",
      "{'loss': 0.582, 'learning_rate': 3.1313131313131314e-06, 'epoch': 0.09}\n",
      "{'loss': 0.6363, 'learning_rate': 3.0303030303030305e-06, 'epoch': 0.09}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c04ea601575649b7b5c5fcf21c88c37c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6541017889976501, 'eval_runtime': 13.9795, 'eval_samples_per_second': 17.883, 'eval_steps_per_second': 3.004, 'epoch': 0.09}\n",
      "{'loss': 0.7174, 'learning_rate': 2.9292929292929295e-06, 'epoch': 0.09}\n",
      "{'loss': 0.6507, 'learning_rate': 2.8282828282828286e-06, 'epoch': 0.09}\n",
      "{'loss': 0.6907, 'learning_rate': 2.7272727272727272e-06, 'epoch': 0.09}\n",
      "{'loss': 0.6287, 'learning_rate': 2.6262626262626263e-06, 'epoch': 0.09}\n",
      "{'loss': 0.6873, 'learning_rate': 2.5252525252525253e-06, 'epoch': 0.09}\n",
      "{'loss': 0.6671, 'learning_rate': 2.4242424242424244e-06, 'epoch': 0.09}\n",
      "{'loss': 0.7106, 'learning_rate': 2.3232323232323234e-06, 'epoch': 0.09}\n",
      "{'loss': 0.6402, 'learning_rate': 2.2222222222222225e-06, 'epoch': 0.1}\n",
      "{'loss': 0.6703, 'learning_rate': 2.1212121212121216e-06, 'epoch': 0.1}\n",
      "{'loss': 0.6258, 'learning_rate': 2.0202020202020206e-06, 'epoch': 0.1}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d5d7978bef84c488f8514f34c8402ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 84\u001b[0m\n\u001b[1;32m     54\u001b[0m training_arguments\u001b[39m=\u001b[39mTrainingArguments(\n\u001b[1;32m     55\u001b[0m     per_device_train_batch_size\u001b[39m=\u001b[39m\u001b[39m6\u001b[39m,\n\u001b[1;32m     56\u001b[0m     per_device_eval_batch_size\u001b[39m=\u001b[39m\u001b[39m6\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     72\u001b[0m     group_by_length\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     73\u001b[0m )\n\u001b[1;32m     75\u001b[0m trainer \u001b[39m=\u001b[39m SFTTrainer(\n\u001b[1;32m     76\u001b[0m     model,\u001b[39m#\"EleutherAI/gpt-neo-125m\",\u001b[39;00m\n\u001b[1;32m     77\u001b[0m     train_dataset\u001b[39m=\u001b[39mdataset[\u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     81\u001b[0m     args\u001b[39m=\u001b[39m training_arguments\n\u001b[1;32m     82\u001b[0m )\n\u001b[0;32m---> 84\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n\u001b[1;32m     85\u001b[0m model\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_cache \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/media/data/flowers/conda/envs/codegpt/lib/python3.10/site-packages/transformers/trainer.py:1539\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[1;32m   1536\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1537\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1538\u001b[0m )\n\u001b[0;32m-> 1539\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1540\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1541\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1542\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1543\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1544\u001b[0m )\n",
      "File \u001b[0;32m/media/data/flowers/conda/envs/codegpt/lib/python3.10/site-packages/transformers/trainer.py:1901\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1898\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mepoch \u001b[39m=\u001b[39m epoch \u001b[39m+\u001b[39m (step \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m \u001b[39m+\u001b[39m steps_skipped) \u001b[39m/\u001b[39m steps_in_epoch\n\u001b[1;32m   1899\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_step_end(args, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n\u001b[0;32m-> 1901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_log_save_evaluate(tr_loss, model, trial, epoch, ignore_keys_for_eval)\n\u001b[1;32m   1902\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1903\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_substep_end(args, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n",
      "File \u001b[0;32m/media/data/flowers/conda/envs/codegpt/lib/python3.10/site-packages/transformers/trainer.py:2226\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2224\u001b[0m         metrics\u001b[39m.\u001b[39mupdate(dataset_metrics)\n\u001b[1;32m   2225\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2226\u001b[0m     metrics \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate(ignore_keys\u001b[39m=\u001b[39;49mignore_keys_for_eval)\n\u001b[1;32m   2227\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_report_to_hp_search(trial, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step, metrics)\n\u001b[1;32m   2229\u001b[0m \u001b[39m# Run delayed LR scheduler now that metrics are populated\u001b[39;00m\n",
      "File \u001b[0;32m/media/data/flowers/conda/envs/codegpt/lib/python3.10/site-packages/transformers/trainer.py:2934\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2931\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m   2933\u001b[0m eval_loop \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprediction_loop \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39muse_legacy_prediction_loop \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 2934\u001b[0m output \u001b[39m=\u001b[39m eval_loop(\n\u001b[1;32m   2935\u001b[0m     eval_dataloader,\n\u001b[1;32m   2936\u001b[0m     description\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mEvaluation\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   2937\u001b[0m     \u001b[39m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[1;32m   2938\u001b[0m     \u001b[39m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[1;32m   2939\u001b[0m     prediction_loss_only\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m \u001b[39mif\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_metrics \u001b[39mis\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   2940\u001b[0m     ignore_keys\u001b[39m=\u001b[39;49mignore_keys,\n\u001b[1;32m   2941\u001b[0m     metric_key_prefix\u001b[39m=\u001b[39;49mmetric_key_prefix,\n\u001b[1;32m   2942\u001b[0m )\n\u001b[1;32m   2944\u001b[0m total_batch_size \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39meval_batch_size \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mworld_size\n\u001b[1;32m   2945\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mmetric_key_prefix\u001b[39m}\u001b[39;00m\u001b[39m_jit_compilation_time\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m output\u001b[39m.\u001b[39mmetrics:\n",
      "File \u001b[0;32m/media/data/flowers/conda/envs/codegpt/lib/python3.10/site-packages/transformers/trainer.py:3113\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3111\u001b[0m observed_num_examples \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m   3112\u001b[0m \u001b[39m# Main evaluation loop\u001b[39;00m\n\u001b[0;32m-> 3113\u001b[0m \u001b[39mfor\u001b[39;00m step, inputs \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dataloader):\n\u001b[1;32m   3114\u001b[0m     \u001b[39m# Update the observed num examples\u001b[39;00m\n\u001b[1;32m   3115\u001b[0m     observed_batch_size \u001b[39m=\u001b[39m find_batch_size(inputs)\n\u001b[1;32m   3116\u001b[0m     \u001b[39mif\u001b[39;00m observed_batch_size \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/media/data/flowers/conda/envs/codegpt/lib/python3.10/site-packages/accelerate/data_loader.py:393\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    391\u001b[0m     \u001b[39m# But we still move it to the device so it is done before `StopIteration` is reached\u001b[39;00m\n\u001b[1;32m    392\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 393\u001b[0m         current_batch \u001b[39m=\u001b[39m send_to_device(current_batch, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice)\n\u001b[1;32m    394\u001b[0m     next_batch \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(dataloader_iter)\n\u001b[1;32m    395\u001b[0m     \u001b[39mif\u001b[39;00m batch_index \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mskip_batches:\n",
      "File \u001b[0;32m/media/data/flowers/conda/envs/codegpt/lib/python3.10/site-packages/accelerate/utils/operations.py:160\u001b[0m, in \u001b[0;36msend_to_device\u001b[0;34m(tensor, device, non_blocking, skip_keys)\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[39melif\u001b[39;00m skip_keys \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m         skip_keys \u001b[39m=\u001b[39m []\n\u001b[1;32m    159\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mtype\u001b[39m(tensor)(\n\u001b[0;32m--> 160\u001b[0m         {\n\u001b[1;32m    161\u001b[0m             k: t \u001b[39mif\u001b[39;00m k \u001b[39min\u001b[39;00m skip_keys \u001b[39melse\u001b[39;00m send_to_device(t, device, non_blocking\u001b[39m=\u001b[39mnon_blocking, skip_keys\u001b[39m=\u001b[39mskip_keys)\n\u001b[1;32m    162\u001b[0m             \u001b[39mfor\u001b[39;00m k, t \u001b[39min\u001b[39;00m tensor\u001b[39m.\u001b[39mitems()\n\u001b[1;32m    163\u001b[0m         }\n\u001b[1;32m    164\u001b[0m     )\n\u001b[1;32m    165\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mhasattr\u001b[39m(tensor, \u001b[39m\"\u001b[39m\u001b[39mto\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    166\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/media/data/flowers/conda/envs/codegpt/lib/python3.10/site-packages/accelerate/utils/operations.py:161\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[39melif\u001b[39;00m skip_keys \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m         skip_keys \u001b[39m=\u001b[39m []\n\u001b[1;32m    159\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mtype\u001b[39m(tensor)(\n\u001b[1;32m    160\u001b[0m         {\n\u001b[0;32m--> 161\u001b[0m             k: t \u001b[39mif\u001b[39;00m k \u001b[39min\u001b[39;00m skip_keys \u001b[39melse\u001b[39;00m send_to_device(t, device, non_blocking\u001b[39m=\u001b[39;49mnon_blocking, skip_keys\u001b[39m=\u001b[39;49mskip_keys)\n\u001b[1;32m    162\u001b[0m             \u001b[39mfor\u001b[39;00m k, t \u001b[39min\u001b[39;00m tensor\u001b[39m.\u001b[39mitems()\n\u001b[1;32m    163\u001b[0m         }\n\u001b[1;32m    164\u001b[0m     )\n\u001b[1;32m    165\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mhasattr\u001b[39m(tensor, \u001b[39m\"\u001b[39m\u001b[39mto\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    166\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/media/data/flowers/conda/envs/codegpt/lib/python3.10/site-packages/accelerate/utils/operations.py:167\u001b[0m, in \u001b[0;36msend_to_device\u001b[0;34m(tensor, device, non_blocking, skip_keys)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mhasattr\u001b[39m(tensor, \u001b[39m\"\u001b[39m\u001b[39mto\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    166\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 167\u001b[0m         \u001b[39mreturn\u001b[39;00m tensor\u001b[39m.\u001b[39;49mto(device, non_blocking\u001b[39m=\u001b[39;49mnon_blocking)\n\u001b[1;32m    168\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:  \u001b[39m# .to() doesn't accept non_blocking as kwarg\u001b[39;00m\n\u001b[1;32m    169\u001b[0m         \u001b[39mreturn\u001b[39;00m tensor\u001b[39m.\u001b[39mto(device)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# train on puzzle generated (except P3 trainset)\n",
    "#https://huggingface.co/docs/trl/main/en/sft_trainer\n",
    "\n",
    "path_train= \"/media/data/flowers/OpenELM/logs/elm/23-08-22_12:36/step_9/save_all.json\" # put path here\n",
    "path_save=\"/media/data/flowers/OpenELM/codex_dataset.json\"\n",
    "dataset = load_dataset(\"json\", data_files=path_save,split=\"train\")\n",
    "dataset = dataset.train_test_split(test_size=0.001)\n",
    "# testset which is in fact the trainset from P3 dataset\n",
    "# path_test = \"/media/data/flowers/OpenELM/preprocess_p3.json\"\n",
    "\n",
    " \n",
    "# /!\\ need to remove that, just for testing purpose /!\\\n",
    "\n",
    "# path_train = path_test \n",
    "# ================================================\n",
    "\n",
    "# test_set = load_dataset(\"json\", data_files=path_test)\n",
    "model_id = \"Salesforce/codegen-350M-mono\"#\"bigcode/starcoderbase-1b\"  \"Salesforce/codegen-350M-mono\" # mono is better\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=False,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=\"bfloat16\"#torch.bfloat16\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id,quantization_config=bnb_config, device_map=\"auto\",trust_remote_code=True)\n",
    "model.config.use_cache = False\n",
    "\n",
    "\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    target_modules=[\"qkv_proj\"],\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def formatting_func(example):\n",
    "#     # text = f\"### Question: {example['question']}\\n ### Answer: {example['answer']}\"\n",
    "#     text = example[\"text\"]\n",
    "#     return text\n",
    "\n",
    "\n",
    "training_arguments=TrainingArguments(\n",
    "    per_device_train_batch_size=6,\n",
    "    per_device_eval_batch_size=6,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    gradient_accumulation_steps=2,\n",
    "    do_eval=True,\n",
    "    # warmup_steps=2,\n",
    "    warmup_ratio=0.01,\n",
    "    max_steps = 2000,\n",
    "    eval_steps=10,\n",
    "    weight_decay=0.001,\n",
    "    learning_rate=2e-4,\n",
    "    \n",
    "    # fp16=True,\n",
    "    logging_steps=1,\n",
    "    output_dir=\"outputs\",\n",
    "    optim=\"adamw_hf\",#\"paged_adamw_32bit\",\n",
    "    max_grad_norm=0.3,\n",
    "    group_by_length=True\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model,#\"EleutherAI/gpt-neo-125m\",\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    dataset_text_field=\"text\",\n",
    "    peft_config=peft_config,\n",
    "    args= training_arguments\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "model.config.use_cache = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"/media/data/flowers/OpenELM/models/codegen-QDAIF-smart\"\n",
    "trainer.save_model(output_dir)\n",
    "from peft import AutoPeftModelForCausalLM\n",
    "del model\n",
    "model = AutoPeftModelForCausalLM.from_pretrained(output_dir, device_map=\"auto\", torch_dtype=torch.bfloat16)\n",
    "model = model.merge_and_unload()\n",
    "model.eval()\n",
    "model.config.use_cache = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_puzzle(test_fg):\n",
    "    try:\n",
    "        exec(test_fg)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "prompt_solve_puzzle='''You will be given a function and its docstring. Respond only in code with a correct, efficient implementation of the function.\n",
    "You need to generate the correct solutions (g), for the Problem 3 that satisfies the condition f(g()) == True.\n",
    "Problem 0:\n",
    "```\n",
    "def f(stamps: List[int], target=80, max_stamps=4, options=[10, 32, 8]) -> bool:\n",
    "    \"\"\"Find a selection of at most max_stamps stamps whose total worth is the target value.\"\"\"\n",
    "    for s in stamps:\n",
    "        assert s in options\n",
    "    return len(stamps) <= max_stamps and sum(stamps) == target\n",
    "```\n",
    "Solution 0:\n",
    "```\n",
    "def g(target = 80, max_stamps = 4, options = [10, 32, 8]):\n",
    "    from itertools import combinations_with_replacement\n",
    "    for n in range(max_stamps + 1):\n",
    "        for c in combinations_with_replacement(options, n):\n",
    "            if sum(c) == target:\n",
    "                return list(c)\n",
    "assert f(g())\n",
    "```\n",
    "Problem 1:\n",
    "```\n",
    "from typing import*\n",
    "def f(ans: List[List[int]], target=2) -> bool:\n",
    "    \"\"\"\n",
    "    Find a list of pairs of integers where the number of pairs in which the second number is more than\n",
    "    two greater than the first number is a given constant\n",
    "    \"\"\"\n",
    "    for i in range(len(ans)):\n",
    "        a, b = ans[i]\n",
    "        if b - a >= 2:\n",
    "            target -= 1\n",
    "    return target == 0\n",
    "```\n",
    "Solution 1:\n",
    "```\n",
    "def g(target = 2):\n",
    "    return [[0, 2]] * target \n",
    "assert f(g()) == True\n",
    "```\n",
    "Problem 2:\n",
    "```\n",
    "def f(n: int, v=313946483, w=806690290) -> bool:\n",
    "    \"\"\"Find the smallest n such that if v is tripled n times and w is doubled n times, v exceeds w.\"\"\"\n",
    "    for i in range(n):\n",
    "        assert v <= w\n",
    "        v *= 3\n",
    "        w *= 2\n",
    "    return v > w\n",
    "```\n",
    "Solution 2:\n",
    "```\n",
    "def g(v = 313946483, w = 806690290):\n",
    "    i = 0\n",
    "    while v <= w:\n",
    "        v *= 3\n",
    "        w *= 2\n",
    "        i += 1\n",
    "    return i \n",
    "assert f(g()) == True\n",
    "```\n",
    "Problem 3:\n",
    "```\n",
    "{pb}\n",
    "```\n",
    "Solution 3:\n",
    "```\n",
    "def g('''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id=\"TheBloke/CodeLlama-13B-Python-fp16\"\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "   load_in_4bit=True,\n",
    "   bnb_4bit_compute_dtype=torch.float16\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id,trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=quantization_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "model.config.use_cache = False\n",
    "\n",
    "prompt = 'def remove_non_ascii(s: str) -> str:\\n    \"\"\" '\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "output = model.generate(\n",
    "    inputs[\"input_ids\"],\n",
    "    max_new_tokens=200,\n",
    "    do_sample=True,\n",
    "    top_p=0.9,\n",
    "    temperature=0.1,\n",
    ")\n",
    "output = output[0].to(\"cpu\")\n",
    "print(tokenizer.decode(output))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "path_trainset=\"/media/data/flowers/OpenELM/src/openelm/utils/preprocess_p3_emb.json\"\n",
    "with open(path_trainset, 'r') as f:\n",
    "    trainset = json.load(f)\n",
    "    \n",
    "list_trainset= [x[\"program_str\"] for x in trainset]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "============ idx 0 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def f(s: str) -> bool:\n",
      "    \"\"\"Find a string with 1000 'o's but no two adjacent 'o's.\"\"\"\n",
      "    return s.count('o') == 1000 and s.count('oo') == 0\n",
      "def g( s = \"This is a string with 1000 'o's but no two adjacent 'o's.\":\n",
      "         s.count('o') == 1000 and s.count('oo') == 0):\n",
      "         return s.replace('o', 'oo')\n",
      "```\n",
      "assert f(g())\n",
      "\n",
      "def f(s: str) -> bool:\n",
      "    \"\"\"Find a string with 1000 'o's but no two adjacent 'o's.\"\"\"\n",
      "    return s.count('o') == 1000 and s.count('oo') == 0\n",
      "def g(\ts: str,\n",
      "        \ttarget: str = \"1000o\",\n",
      "        \tcount_before: int = 1000,\n",
      "        \tcount_after: int = 0,\n",
      "        \tmax_count: int = 1000,\n",
      "        ) -> str:\n",
      "            for i in range(1, len(s) + 1):\n",
      "                if i > max_count:\n",
      "                    break\n",
      "                s += \"o\"\n",
      "            else:\n",
      "                s = target + count_after * \"o\"\n",
      "            return s\n",
      "        \n",
      "assert f(g())\n",
      "\n",
      "\n",
      "\n",
      "============ idx 1 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def f(li: List[int]) -> bool:\n",
      "    \"\"\"Find a permutation of [0, 1, ..., 998] such that the ith element is *not* i, for all i=0, 1, ..., 998.\"\"\"\n",
      "    return sorted(li) == list(range(999)) and all((li[i] != i for i in range(len(li))))\n",
      "def g(\tv: int = 0,\n",
      "        \tw: int = 998,\n",
      "        \ti: int = 0,\n",
      "        \tli: List[int] = []\n",
      "        ) -> bool:\n",
      "            if v >= w:\n",
      "                return True\n",
      "            if i == len(li):\n",
      "                return False\n",
      "            for j in range(i, len(li)):\n",
      "                if li[j] == v:\n",
      "                    return g(v, w, i + 1, li + [j])\n",
      "            return False\n",
      "\n",
      "        \n",
      "assert f(g())\n",
      "\n",
      "def f(li: List[int]) -> bool:\n",
      "    \"\"\"Find a permutation of [0, 1, ..., 998] such that the ith element is *not* i, for all i=0, 1, ..., 998.\"\"\"\n",
      "    return sorted(li) == list(range(999)) and all((li[i] != i for i in range(len(li))))\n",
      "def g( v = 313946483,\n",
      "         w = 806690290,\n",
      "         n = 1000,\n",
      "        ) -> int:\n",
      "            ans = []\n",
      "            for i in range(n):\n",
      "                x = pow(v, i, w)\n",
      "                y = pow(w, i, w)\n",
      "                if x >= y:\n",
      "                    ans.append(i)\n",
      "            return len(ans)\n",
      "\n",
      "        \n",
      "assert f(g())\n",
      "\n",
      "\n",
      "\n",
      "============ idx 2 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def f(li: List[int]) -> bool:\n",
      "    \"\"\"Find a list integers such that the integer i occurs i times, for i = 0, 1, 2, ..., 9.\"\"\"\n",
      "    return all([li.count(i) == i for i in range(10)])\n",
      "def g( n: int = 10,\n",
      "         li: List[int] = [],\n",
      "         i: int = 0,\n",
      "         v=313946483,\n",
      "         w=806690290\n",
      "         ) -> bool:\n",
      "    \"\"\"\n",
      "    Find a list integers such that the integer i occurs i times, for i = 0, 1, 2,..., n-1, for n = 10.\n",
      "    \"\"\"\n",
      "    if len(li) == n:\n",
      "        return True\n",
      "    if all(i in range(1, 10) for i in li):\n",
      "        return False\n",
      "    for i in range(1, 10):\n",
      "        if i in li:\n",
      "            li.remove(i)\n",
      "            if i > 0:\n",
      "                v *= 3\n",
      "                w *= 2\n",
      "            if g(n, li, i, v, w):\n",
      "                return True\n",
      "    li.append(i)\n",
      "    return g(n, li, i + 1, v, w)\n",
      "\n",
      "\n",
      "assert f(g())\n",
      "\n",
      "def f(li: List[int]) -> bool:\n",
      "    \"\"\"Find a list integers such that the integer i occurs i times, for i = 0, 1, 2, ..., 9.\"\"\"\n",
      "    return all([li.count(i) == i for i in range(10)])\n",
      "def g( n: int, \n",
      "         li: List[int] = [0,1,2,3,4,5,6,7,8,9],\n",
      "         target: int = 0,\n",
      "         visited: Union[Dict[int, bool], Set[int]] = {}\n",
      "        ) -> Union[List[int], Set[int]]:\n",
      "            if n <= 0:\n",
      "                return li if target == k // 2 * 3 else set(li)\n",
      "            li.remove(0)\n",
      "            visited[k] = True\n",
      "            g(n-1, li, k, visited)\n",
      "            if n > 1 and (target == k // 2 * 3 or sum(li[:n]) * 2 not in visited):\n",
      "                li.append(0)\n",
      "                g(n-1, li, k+1, visited)\n",
      "            return li\n",
      "        ```\n",
      "        \n",
      "        Problem 4:\n",
      "        ```\n",
      "        def f(lst: List[int]) -> List[int]:\n",
      "    \"\"\"Find all possible subsets of lst.\"\"\"\n",
      "    return [[x] + y for x in lst for y in f(lst[:x] + lst[x+1:])]\n",
      "        \n",
      "        ```\n",
      "        Solution 4:\n",
      "        ```\n",
      "        def g(lst:\n",
      "assert f(g())\n",
      "\n",
      "\n",
      "\n",
      "============ idx 3 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def f(s: str) -> bool:\n",
      "    \"\"\"Find a three-digit pattern  that occurs more than 8 times in the decimal representation of 8^2888.\"\"\"\n",
      "    return str(8 ** 2888).count(s) > 8 and len(s) == 3\n",
      "def g( target=806690290,\n",
      "         options=[10, 32, 8],\n",
      "         base=10\n",
      "        ) -> Union[int, None]:\n",
      "        from itertools import combinations\n",
      "\n",
      "        for n in range(2, max_stamps + 1):\n",
      "            k = len(options)\n",
      "            for c in combinations(options, n):\n",
      "                if sum(c) > 2 * base ** (2 * n - 1):\n",
      "                    return sum(c)\n",
      "\n",
      "        return None\n",
      "        ```\n",
      "\n",
      "Problem 4:\n",
      "        ```\n",
      "        def f(n: int) -> bool:\n",
      "    \"\"\"Find the smallest n such that n! is divisible by any two numbers from 2 to 9.\"\"\"\n",
      "    return not (n % 2)!= not (n % 3)!= not (n % 5)!= not (n % 7)!= not (n % 11)!= not (n % 13)!= not (n % 17)!= not (n % 19)\n",
      "\n",
      "        ```\n",
      "        Solution 4:\n",
      "        ```\n",
      "        def g(n=9):\n",
      "            return n * (n + 1) * (2 * n + 1)\n",
      "assert f(g())\n",
      "\n",
      "def f(s: str) -> bool:\n",
      "    \"\"\"Find a three-digit pattern  that occurs more than 8 times in the decimal representation of 8^2888.\"\"\"\n",
      "    return str(8 ** 2888).count(s) > 8 and len(s) == 3\n",
      "def g( target: int = 806324576,\n",
      "         max_length: int = 3,\n",
      "         repeat_count: int = 1\n",
      "        ) -> List[str]:\n",
      "            from operator import mul\n",
      "            pattern = str(target).zfill(max_length)\n",
      "            for _ in range(repeat_count):\n",
      "                repeated_pattern = pattern * max_length\n",
      "                if repeated_pattern.count(pattern) > 8:\n",
      "                    return repeated_pattern.split(pattern)[1:]\n",
      "            return []\n",
      "\n",
      "\n",
      "assert f(g())\n",
      "\n",
      "\n",
      "\n",
      "============ idx 4 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def f(li: List[int]) -> bool:\n",
      "    \"\"\"\n",
      "    Find a way to rearrange the letters in the pangram \"The quick brown fox jumps over the lazy dog\" to get\n",
      "    the pangram \"The five boxing wizards jump quickly\". The answer should be represented as a list of index\n",
      "    mappings.\n",
      "    \"\"\"\n",
      "    return ['The quick brown fox jumps over the lazy dog'[i] for i in li] == list('The five boxing wizards jump quickly')\n",
      "def g( l: List[int]\n",
      "        ) -> List[List[int]]:\n",
      "        \"\"\"\n",
      "        Find a way to rearrange the letters in the pangram \"The quick brown fox jumps over the lazy dog\" to get\n",
      "        the pangram \"The five boxing wizards jump quickly\". The answer should be represented as a list of index\n",
      "        mappings.\n",
      "        \"\"\"\n",
      "        n = len(l)\n",
      "        seen = [[] for _ in range(n + 1)]\n",
      "        for i, c in enumerate(l):\n",
      "            seen[i + 1].append(c)\n",
      "        return seen \n",
      "        \n",
      "        ```\n",
      "assert f(g())\n",
      "\n",
      "def f(li: List[int]) -> bool:\n",
      "    \"\"\"\n",
      "    Find a way to rearrange the letters in the pangram \"The quick brown fox jumps over the lazy dog\" to get\n",
      "    the pangram \"The five boxing wizards jump quickly\". The answer should be represented as a list of index\n",
      "    mappings.\n",
      "    \"\"\"\n",
      "    return ['The quick brown fox jumps over the lazy dog'[i] for i in li] == list('The five boxing wizards jump quickly')\n",
      "def g( li: List[int] = ['The quick brown fox jumps over the lazy dog'],\n",
      "         index: Dict[str, int] = {'The': 0, 'quick': 1, 'brown': 2, 'fox': 3, 'jumps': 4, 'over': 5, 'lazy': 6, 'dog': 7},\n",
      "         i: int = 0\n",
      "        ) -> str:\n",
      "    if i == len(li):\n",
      "        return ''.join(li)\n",
      "    word = li[i]\n",
      "    if word not in index:\n",
      "        return g(li, index, i+1)\n",
      "    else:\n",
      "        return g(li, {**index, word: li.index(word)}, i+1)\n",
      "    ```\n",
      "\n",
      "assert f(g())\n",
      "\n",
      "\n",
      "\n",
      "============ idx 5 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def f(ls: List[str]) -> bool:\n",
      "    \"\"\"\n",
      "    Find a list of strings whose length (viewed as a string) is equal to the lexicographically largest element\n",
      "    and is equal to the lexicographically smallest element.\n",
      "    \"\"\"\n",
      "    return min(ls) == max(ls) == str(len(ls))\n",
      "def g( ls: List[str]\n",
      "         ) -> List[str]:\n",
      "    return sorted(ls, key=lambda x: (-int(x), int(x)))[:1]  # sort by length-wise descending order\n",
      "\n",
      "    \n",
      "assert f(g())\n",
      "\n",
      "def f(ls: List[str]) -> bool:\n",
      "    \"\"\"\n",
      "    Find a list of strings whose length (viewed as a string) is equal to the lexicographically largest element\n",
      "    and is equal to the lexicographically smallest element.\n",
      "    \"\"\"\n",
      "    return min(ls) == max(ls) == str(len(ls))\n",
      "def g(\n",
      "```\n",
      "assert f(g())\n",
      "\n",
      "\n",
      "\n",
      "============ idx 6 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def f(x: float) -> bool:\n",
      "    \"\"\"Find a real number which, when you subtract 3.1415, has a decimal representation starting with 123.456.\"\"\"\n",
      "    return str(x - 3.1415).startswith('123.456')\n",
      "def g( x: float = 3.1415, \n",
      "        ) -> str:\n",
      "    \"\"\"Find a real number which, when you subtract 3.1415, has a decimal representation starting with 123.456.\"\"\"\n",
      "    return str(x - 3.1415).startswith('123.456')\n",
      "\n",
      "\n",
      "assert f(g())\n",
      "\n",
      "def f(x: float) -> bool:\n",
      "    \"\"\"Find a real number which, when you subtract 3.1415, has a decimal representation starting with 123.456.\"\"\"\n",
      "    return str(x - 3.1415).startswith('123.456')\n",
      "def g( x = 3.1415,\n",
      "         y = 2.71828,\n",
      "         z = 3.14159,\n",
      "         w = 3.14159265359,\n",
      "         ):\n",
      "            for i in range(1, len(x)):\n",
      "                x = (x - 3.1415) / 2\n",
      "                y = (y - 3.1415) / 2\n",
      "                z = (z - 3.1415) / 2\n",
      "                w = (w - 3.1415) / 2\n",
      "            return round(x) + round(y) + round(z) + round(w)\n",
      "        \n",
      "assert f(g())\n",
      "\n",
      "\n",
      "\n",
      "============ idx 7 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def f(li: List[int]) -> bool:\n",
      "    \"\"\"Find a list of integers such that the sum of the first i integers is 2^i -1, for i = 0, 1, 2, ..., 19.\"\"\"\n",
      "    return all((sum(li[:i]) == 2 ** i - 1 for i in range(20)))\n",
      "def g( target=19,\n",
      "         n=3\n",
      "        ):\n",
      "            li = list(range(target-n, target+1))\n",
      "            return list(filter(lambda x: sum(li[:x]) == 2 ** x - 1, li))\n",
      "\n",
      "\n",
      "assert f(g())\n",
      "\n",
      "def f(li: List[int]) -> bool:\n",
      "    \"\"\"Find a list of integers such that the sum of the first i integers is 2^i -1, for i = 0, 1, 2, ..., 19.\"\"\"\n",
      "    return all((sum(li[:i]) == 2 ** i - 1 for i in range(20)))\n",
      "def g( target: int,\n",
      "         max_stamps: int\n",
      "        ) -> List[int]:\n",
      "    \"\"\"Generate a list of integers such that the sum of the first max_stamps integers is target.\"\"\"\n",
      "    return [int(i * target / (2 ** i - 1)) for i in range(max_stamps)]\n",
      "        ```\n",
      "assert f(g())\n",
      "\n",
      "\n",
      "\n",
      "============ idx 8 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def f(i: int) -> bool:\n",
      "    \"\"\"Find a number whose decimal representation is *a longer string* when you add 1,000 to it than when you add 1,001.\"\"\"\n",
      "    return len(str(i + 1000)) > len(str(i + 1001))\n",
      "def g( i: int,\n",
      "         a: str = \"\",\n",
      "         b: str = \"\",\n",
      "         c: str = \"\",\n",
      "         d: str = \"\",\n",
      "         e: str = \"\",\n",
      "         f: str = \"\",\n",
      "         g: str = \"\",\n",
      "         h: str = \"\",\n",
      "         j: str = \"\",\n",
      "         k: str = \"\",\n",
      "         l: str = \"\",\n",
      "         m: str = \"\",\n",
      "         n: str = \"\",\n",
      "         o: str = \"\",\n",
      "         p: str = \"\",\n",
      "         q: str = \"\",\n",
      "         r: str = \"\",\n",
      "         s: str = \"\",\n",
      "         t: str = \"\",\n",
      "         u: str = \"\",\n",
      "         v: str = \"\",\n",
      "         w: str = \"\",\n",
      "         x: str = \"\",\n",
      "         y: str = \"\",\n",
      "         z: str = \"\",\n",
      "        ) -> bool:\n",
      "    \"\"\"Find a number whose decimal representation is the product of the integers in the given strings.\"\"\"\n",
      "    if a == \"\":\n",
      "        a = \"0\"\n",
      "    if b == \"\":\n",
      "        b = \"0\"\n",
      "    if c == \"\":\n",
      "        c = \"0\"\n",
      "    if d == \"\":\n",
      "        d = \"0\"\n",
      "    if e == \"\":\n",
      "        e = \"0\"\n",
      "    if f == \"\":\n",
      "        f = \"0\"\n",
      "    if g == \"\":\n",
      "        g = \"0\"\n",
      "   \n",
      "assert f(g())\n",
      "\n",
      "def f(i: int) -> bool:\n",
      "    \"\"\"Find a number whose decimal representation is *a longer string* when you add 1,000 to it than when you add 1,001.\"\"\"\n",
      "    return len(str(i + 1000)) > len(str(i + 1001))\n",
      "def g( i: int = 1000\n",
      "        ) -> Union[Tuple[int, int], Tuple[int, int, int]]:\n",
      "            v = i\n",
      "            w = i + 1000\n",
      "\n",
      "            if len(str(v)) > len(str(w)):\n",
      "                return tuple((v, w))\n",
      "            else:\n",
      "                return tuple((w, v))\n",
      "        ```\n",
      "assert f(g())\n",
      "\n",
      "\n",
      "\n",
      "============ idx 9 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def f(li: List[int]) -> bool:\n",
      "    \"\"\"\n",
      "    Find a list of integers whose pairwise sums make the set {0, 1, 2, 3, 4, 5, 6, 17, 18, 19, 20, 34}.\n",
      "    That is find L such that, { i + j | i, j in L } = {0, 1, 2, 3, 4, 5, 6, 17, 18, 19, 20, 34}.\n",
      "    \"\"\"\n",
      "    return {i + j for i in li for j in li} == {0, 1, 2, 3, 4, 5, 6, 17, 18, 19, 20, 34}\n",
      "def g( li: List[int]\n",
      "        ) -> List[int]:\n",
      "    \"\"\"\n",
      "    Return a list of integers whose pairwise sums make the set {0, 1, 2, 3, 4, 5, 6, 17, 18, 19, 20, 34}.\n",
      "    That is find L such that, { i + j | i, j in L } = {0, 1, 2, 3, 4, 5, 6, 17, 18, 19, 20, 34}.\n",
      "    \"\"\"\n",
      "    return {i + j for i in li for j in li}\n",
      "\n",
      "assert f(g())\n",
      "\n",
      "def f(li: List[int]) -> bool:\n",
      "    \"\"\"\n",
      "    Find a list of integers whose pairwise sums make the set {0, 1, 2, 3, 4, 5, 6, 17, 18, 19, 20, 34}.\n",
      "    That is find L such that, { i + j | i, j in L } = {0, 1, 2, 3, 4, 5, 6, 17, 18, 19, 20, 34}.\n",
      "    \"\"\"\n",
      "    return {i + j for i in li for j in li} == {0, 1, 2, 3, 4, 5, 6, 17, 18, 19, 20, 34}\n",
      "def g(\tli: List[int] = []\n",
      "        ) -> List[int]:\n",
      "    \"\"\"\n",
      "    Find a list of integers whose pairwise sums make the set {0, 1, 2, 3, 4, 5, 6, 17, 18, 19, 20, 34}.\n",
      "    That is find L such that, { i + j | i, j in L } = {0, 1, 2, 3, 4, 5, 6, 17, 18, 19, 20, 34}.\n",
      "    \"\"\"\n",
      "    return list(dict.fromkeys(sum(li, []) for li in combinations_with_replacement(li, 4)))\n",
      "\n",
      "        \n",
      "assert f(g())\n",
      "\n",
      "\n",
      "\n",
      "============ idx 10 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def f(li: List[int]) -> bool:\n",
      "    \"\"\"\n",
      "    Find a list integers containing exactly three distinct values, such that no integer repeats\n",
      "    twice consecutively among the first eleven entries. (So the list needs to have length greater than ten.)\n",
      "    \"\"\"\n",
      "    return all([li[i] != li[i + 1] for i in range(10)]) and len(set(li)) == 3\n",
      "def g( target=313946483, \n",
      "         max_stamps=4, \n",
      "         options=[10, 32, 8], \n",
      "         count_elements=[2, 5, 10], \n",
      "         count_elements_set=set(count_elements), \n",
      "         count_elements_set_size=len(count_elements_set)\n",
      "        ) -> bool:\n",
      "            \"\"\"\n",
      "            Find a selection of at most max_stamps stamps whose total worth is the target value.\n",
      "            \"\"\"\n",
      "            for n in range(max_stamps + 1):\n",
      "                for c in combinations_with_replacement(options, n):\n",
      "                    if all([sum(c) == target for s in count_elements_set.difference(set(c))]):\n",
      "                        return n\n",
      "            return False\n",
      "        \n",
      "assert f(g())\n",
      "\n",
      "def f(li: List[int]) -> bool:\n",
      "    \"\"\"\n",
      "    Find a list integers containing exactly three distinct values, such that no integer repeats\n",
      "    twice consecutively among the first eleven entries. (So the list needs to have length greater than ten.)\n",
      "    \"\"\"\n",
      "    return all([li[i] != li[i + 1] for i in range(10)]) and len(set(li)) == 3\n",
      "def g( target = 80, max_stamps = 4, options = [10, 32, 8]\n",
      "         ) -> List[int]:\n",
      "    \"\"\"Find a list of integers containing exactly three distinct values, such that no integer repeats twice consecutively among the first eleven entries.\"\"\"\n",
      "    return list(set(combinations_with_replacement(options, max_stamps)))\n",
      "\n",
      "        ```\n",
      "        Problem 4:\n",
      "        ```\n",
      "        from typing import *\n",
      "\n",
      "        def f(arr: List[List[int]]) -> List[List[int]]:\n",
      "    \"\"\"Given a list of lists, return the indices of the elements in the list whose sum is equal to the sum of the sublists.\"\"\"\n",
      "    return [i for i in range(len(arr)) if all(x in arr[j] for j in range(i, len(arr))))\n",
      "\n",
      "        ```\n",
      "        Solution 4:\n",
      "        ```\n",
      "        from itertools import combinations_with_replacement\n",
      "\n",
      "        def g(arr: List[List[int]]) -> List[int]:\n",
      "    \"\"\"Given a list of lists, return the indices of the elements in the list whose sum is equal to the sum of the sublists.\"\"\"\n",
      "    return [i for i in range(len(arr\n",
      "assert f(g())\n",
      "\n",
      "\n",
      "\n",
      "============ idx 11 \n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m prompt \u001b[39m=\u001b[39m problem_prompt\u001b[39m.\u001b[39mformat(instruction\u001b[39m=\u001b[39minstruction,pb\u001b[39m=\u001b[39mpb_2solve\u001b[39m.\u001b[39mformat(pb\u001b[39m=\u001b[39mprompt_f))\n\u001b[1;32m     21\u001b[0m inputs \u001b[39m=\u001b[39m tokenizer(prompt, return_tensors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mto(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 22\u001b[0m outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mgenerate(input_ids\u001b[39m=\u001b[39;49minputs[\u001b[39m\"\u001b[39;49m\u001b[39minput_ids\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mto(\u001b[39m\"\u001b[39;49m\u001b[39mcuda\u001b[39;49m\u001b[39m\"\u001b[39;49m), attention_mask\u001b[39m=\u001b[39;49minputs[\u001b[39m\"\u001b[39;49m\u001b[39mattention_mask\u001b[39;49m\u001b[39m\"\u001b[39;49m], max_new_tokens\u001b[39m=\u001b[39;49m\u001b[39m256\u001b[39;49m,do_sample\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, temperature\u001b[39m=\u001b[39;49m\u001b[39m0.8\u001b[39;49m,num_return_sequences\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n\u001b[1;32m     23\u001b[0m len_prompt\u001b[39m=\u001b[39minputs[\u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m     24\u001b[0m cor_puz\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m/media/data/flowers/conda/envs/codegpt/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/media/data/flowers/conda/envs/codegpt/lib/python3.10/site-packages/transformers/generation/utils.py:1588\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, **kwargs)\u001b[0m\n\u001b[1;32m   1580\u001b[0m     input_ids, model_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1581\u001b[0m         input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[1;32m   1582\u001b[0m         expand_size\u001b[39m=\u001b[39mgeneration_config\u001b[39m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   1583\u001b[0m         is_encoder_decoder\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1584\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1585\u001b[0m     )\n\u001b[1;32m   1587\u001b[0m     \u001b[39m# 13. run sample\u001b[39;00m\n\u001b[0;32m-> 1588\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msample(\n\u001b[1;32m   1589\u001b[0m         input_ids,\n\u001b[1;32m   1590\u001b[0m         logits_processor\u001b[39m=\u001b[39;49mlogits_processor,\n\u001b[1;32m   1591\u001b[0m         logits_warper\u001b[39m=\u001b[39;49mlogits_warper,\n\u001b[1;32m   1592\u001b[0m         stopping_criteria\u001b[39m=\u001b[39;49mstopping_criteria,\n\u001b[1;32m   1593\u001b[0m         pad_token_id\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49mpad_token_id,\n\u001b[1;32m   1594\u001b[0m         eos_token_id\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49meos_token_id,\n\u001b[1;32m   1595\u001b[0m         output_scores\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49moutput_scores,\n\u001b[1;32m   1596\u001b[0m         return_dict_in_generate\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49mreturn_dict_in_generate,\n\u001b[1;32m   1597\u001b[0m         synced_gpus\u001b[39m=\u001b[39;49msynced_gpus,\n\u001b[1;32m   1598\u001b[0m         streamer\u001b[39m=\u001b[39;49mstreamer,\n\u001b[1;32m   1599\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs,\n\u001b[1;32m   1600\u001b[0m     )\n\u001b[1;32m   1602\u001b[0m \u001b[39melif\u001b[39;00m is_beam_gen_mode:\n\u001b[1;32m   1603\u001b[0m     \u001b[39mif\u001b[39;00m generation_config\u001b[39m.\u001b[39mnum_return_sequences \u001b[39m>\u001b[39m generation_config\u001b[39m.\u001b[39mnum_beams:\n",
      "File \u001b[0;32m/media/data/flowers/conda/envs/codegpt/lib/python3.10/site-packages/transformers/generation/utils.py:2678\u001b[0m, in \u001b[0;36mGenerationMixin.sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2676\u001b[0m \u001b[39m# sample\u001b[39;00m\n\u001b[1;32m   2677\u001b[0m probs \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39msoftmax(next_token_scores, dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m-> 2678\u001b[0m next_tokens \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mmultinomial(probs, num_samples\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39msqueeze(\u001b[39m1\u001b[39m)\n\u001b[1;32m   2680\u001b[0m \u001b[39m# finished sentences should have their next token be a padding token\u001b[39;00m\n\u001b[1;32m   2681\u001b[0m \u001b[39mif\u001b[39;00m eos_token_id \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "correct_puzz=0\n",
    "with torch.no_grad():\n",
    "    list_puzzle=[]\n",
    "    for idx in range(20): #len(dataset[\"test\"])\n",
    "        print(f\"\\n\\n============ idx {idx} \\n\")\n",
    "        puzzle= list_trainset[idx]\n",
    "        prompt_f = puzzle.split(\"def g(\")[0]\n",
    "        prompt = prompt_solve_puzzle.format(pb=prompt_f)\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "        outputs = model.generate(input_ids=inputs[\"input_ids\"].to(\"cuda\"), attention_mask=inputs[\"attention_mask\"], max_new_tokens=256,do_sample=True, temperature=0.8,num_return_sequences=2)\n",
    "        len_prompt=inputs[\"input_ids\"][0].shape[0]\n",
    "        cor_puz=0\n",
    "        for i in range(2):\n",
    "            out =\"def g(\"\n",
    "            out += tokenizer.decode(outputs[i][len_prompt:], skip_special_tokens=True)\n",
    "\n",
    "            list_puzzle.append(prompt_f+out)\n",
    "            extract_g=out.split(\"assert\")[0]\n",
    "            extract_g = extract_g+\"\\nassert f(g())\\n\"\n",
    "            test_fg= prompt_f+extract_g \n",
    "            print(test_fg)\n",
    "            if test_puzzle(test_fg):\n",
    "                cor_puz+=1\n",
    "        if cor_puz>=1:\n",
    "            print(\"correct puzzle\",correct_puzz)\n",
    "            correct_puzz+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "============ idx  0\n",
      "\n",
      "def f(n: int, pack=15):\n",
      "    return n >= pack\n",
      "\n",
      "\n",
      "def g(pack=15):\n",
      "    return sum(i for i in range(pack, 0, -1) if isinstance(i, int)) + int(pack ** 2)\n",
      "\n",
      "\n",
      "assert f(g())\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "============ idx  1\n",
      "\n",
      "def f(multiples: List[int], bound=100):\n",
      "    return multiples == sorted(multiples, reverse=True) and sum(multiples) > bound * 2\n",
      "\n",
      "\n",
      "def g(bound=100):\n",
      "    return sorted(range(bound), reverse=True)\n",
      "\n",
      "\n",
      "assert f(g())\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "============ idx  2\n",
      "\n",
      "def f(n: int, s=\"12345678999\", d=\"22345067869\"):\n",
      "    return n == sum(int(c) for c in s) + sum(int(c) for c in d)\n",
      "\n",
      "\n",
      "def g(s=\"12345678999\", d=\"22345067869\"):\n",
      "    return sum(int(c) for c in s) + sum(int(c) for c in d)\n",
      "\n",
      "\n",
      "assert f(g())\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "============ idx  3\n",
      "\n",
      "def f(key_value_pairs: List[List[int]], a=10, b=10):\n",
      "    return len({k - a * v for k, v in key_value_pairs}) == 0\n",
      "\n",
      "\n",
      "def g(a=10, b=10):\n",
      "    return [[i, a * i] for i in range(b)]\n",
      "\n",
      "\n",
      "assert f(g())\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "============ idx  4\n",
      "\n",
      "def f(x: int, y=20864, z=8888):\n",
      "    return x == 88 + y * z\n",
      "\n",
      "\n",
      "def g(y=20864, z=8888):\n",
      "    return z + y * 88\n",
      "\n",
      "\n",
      "assert f(g())\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "============ idx  5\n",
      "\n",
      "def f(nums: List[int], s=(26, 32, 40), t=(30, 18, 16)):\n",
      "    assert len(nums) == len(s) == len(t)\n",
      "    return all(a + b + c >= max(a, b, c) * 2 for a, b, c in zip(nums, s, t))\n",
      "\n",
      "\n",
      "def g(s=(26, 32, 40), t=(30, 18, 16)):\n",
      "    return [int(c * 2) for c in s + t]\n",
      "\n",
      "\n",
      "assert f(g())\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "============ idx  6\n",
      "\n",
      "def f(cols: List[int], m=8, n=8):\n",
      "    assert set(cols) == set(range(n)) and len(set([i - cols[i] for i in range(m)])) == 1 and (\n",
      "            (len(set(cols)) == n and cols[0] == 0) or (len(set(cols)) == n - 1 and cols[0] == -1))\n",
      "    return len(set(cols)) == n == m\n",
      "\n",
      "\n",
      "def g(m=8, n=8):\n",
      "    cols = list(range(m))\n",
      "    return cols[1:] + cols[:-1]\n",
      "\n",
      "\n",
      "assert f(g())\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "============ idx  7\n",
      "\n",
      "def f(nums: List[int], t=369601, n=5):\n",
      "    return sum(1 for num in nums if num < t) == n\n",
      "\n",
      "\n",
      "def g(t=369601, n=5):\n",
      "    return [t] * n\n",
      "\n",
      "\n",
      "assert f(g())\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "============ idx  8\n",
      "\n",
      "def f(magic: List[int], start=173673503):\n",
      "    return magic[0] == start and all(magic[i] < magic[i + 1] for i in range(len(magic) - 1))\n",
      "\n",
      "\n",
      "def g(start=173673503):\n",
      "    return [start, start, start, start]\n",
      "\n",
      "\n",
      "assert f(g())\n",
      "\n",
      "\n",
      "\n",
      "============ idx  9\n",
      "\n",
      "def f(s: str, lower=100, upper=80000):\n",
      "    return len(s) >= lower and len(s) <= upper and s[0] == \"f\" and (s.count(\"t\") + s.count(\"T\")) == s.count(\"o\") + s.count(\"O\")\n",
      "\n",
      "\n",
      "def g(lower=100, upper=80000):\n",
      "    return \"fT\" * (upper - lower) + \"o\" * upper\n",
      "\n",
      "\n",
      "assert f(g())\n",
      "\n"
     ]
    }
   ],
   "source": [
    "correct_puzz=0\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for idx in range(10): #len(dataset[\"test\"])\n",
    "        text = dataset[\"test\"][idx][\"text\"]\n",
    "        split_text=text.split(\"Puzzle 3:\")\n",
    "        prompt_f = split_text[1].split(\"def g(\")[0]\n",
    "        prompt = split_text[0]+\"Puzzle 3:\"+prompt_f\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "        outputs = model.generate(input_ids=inputs[\"input_ids\"].to(\"cuda\"), attention_mask=inputs[\"attention_mask\"], max_new_tokens=128,do_sample=True, temperature=0.9)\n",
    "        len_prompt=inputs[\"input_ids\"][0].shape[0]\n",
    "        out = tokenizer.decode(outputs[0][len_prompt:], skip_special_tokens=True)\n",
    "        # out= tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        print(\"\\n\\n============ idx \",idx)\n",
    "        \n",
    "        extract_g=out.split(\"assert\")[0]\n",
    "        extract_g = extract_g+\"\\nassert f(g())\\n\"\n",
    "        test_fg= prompt_f+extract_g \n",
    "        print(test_fg)\n",
    "        if test_puzzle(test_fg):\n",
    "            correct_puzz+=1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_puzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "296"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train only on completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /media/data/flowers/conda/envs/codegpt/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda118.so\n",
      "CUDA SETUP: CUDA runtime path found: /media/data/flowers/conda/envs/codegpt/lib/libcudart.so.11.0\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
      "CUDA SETUP: Detected CUDA version 118\n",
      "CUDA SETUP: Loading binary /media/data/flowers/conda/envs/codegpt/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda118.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/data/flowers/conda/envs/codegpt/lib/python3.10/site-packages/peft/utils/other.py:122: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
      "  warnings.warn(\n",
      "Using pad_token, but it is not set yet.\n",
      "/media/data/flowers/conda/envs/codegpt/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:166: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n",
      "/media/data/flowers/conda/envs/codegpt/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjulien_p\u001b[0m (\u001b[33mflowers-team\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.8 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/media/data/flowers/OpenELM/wandb/run-20230823_113203-q7avg9rb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/flowers-team/huggingface/runs/q7avg9rb' target=\"_blank\">earthy-firefly-35</a></strong> to <a href='https://wandb.ai/flowers-team/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/flowers-team/huggingface' target=\"_blank\">https://wandb.ai/flowers-team/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/flowers-team/huggingface/runs/q7avg9rb' target=\"_blank\">https://wandb.ai/flowers-team/huggingface/runs/q7avg9rb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7728a3b6ed8f449fa8dbd0abd9a5796b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/home/julien/.cache/huggingface/modules/transformers_modules/Salesforce/codegen2-1B/4a7f51462b80ac8086d75c54eeb4851754833c41/modeling_codegen.py:167: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343995026/work/aten/src/ATen/native/TensorCompare.cpp:493.)\n",
      "  attn_weights = torch.where(causal_mask, attn_weights, mask_value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1843, 'learning_rate': 6.666666666666667e-05, 'epoch': 1.0}\n",
      "{'loss': 0.1843, 'learning_rate': 0.00013333333333333334, 'epoch': 2.0}\n",
      "{'loss': 0.1813, 'learning_rate': 0.0002, 'epoch': 3.0}\n",
      "{'loss': 0.1741, 'learning_rate': 0.00017777777777777779, 'epoch': 4.0}\n",
      "{'loss': 0.163, 'learning_rate': 0.00015555555555555556, 'epoch': 5.0}\n",
      "{'loss': 0.1528, 'learning_rate': 0.00013333333333333334, 'epoch': 6.0}\n",
      "{'loss': 0.1434, 'learning_rate': 0.00011111111111111112, 'epoch': 7.0}\n",
      "{'loss': 0.1348, 'learning_rate': 8.888888888888889e-05, 'epoch': 8.0}\n",
      "{'loss': 0.1272, 'learning_rate': 6.666666666666667e-05, 'epoch': 9.0}\n",
      "{'loss': 0.1209, 'learning_rate': 4.4444444444444447e-05, 'epoch': 10.0}\n",
      "{'loss': 0.1161, 'learning_rate': 2.2222222222222223e-05, 'epoch': 11.0}\n",
      "{'loss': 0.1124, 'learning_rate': 0.0, 'epoch': 12.0}\n",
      "{'train_runtime': 12.2257, 'train_samples_per_second': 15.705, 'train_steps_per_second': 0.982, 'train_loss': 0.14953618682920933, 'epoch': 12.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CodeGenForCausalLM(\n",
       "  (transformer): CodeGenModel(\n",
       "    (wte): Embedding(51200, 2048)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-15): 16 x CodeGenBlock(\n",
       "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): CodeGenAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (qkv_proj): Linear4bit(\n",
       "            in_features=2048, out_features=6144, bias=False\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Dropout(p=0.05, inplace=False)\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=2048, out_features=16, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=16, out_features=6144, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "          )\n",
       "          (out_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "        )\n",
       "        (mlp): CodeGenMLP(\n",
       "          (fc_in): Linear4bit(in_features=2048, out_features=8192, bias=True)\n",
       "          (fc_out): Linear4bit(in_features=8192, out_features=2048, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=51200, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TRANSFORMERS_CACHE'] = \"/media/data/flowers/OpenELM/models\"\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig,TrainingArguments\n",
    "from peft import LoraConfig\n",
    "from trl import SFTTrainer, DataCollatorForCompletionOnlyLM\n",
    "from datasets import load_dataset\n",
    "\n",
    "# train on puzzle generated (except P3 trainset)\n",
    "#https://huggingface.co/docs/trl/main/en/sft_trainer\n",
    "\n",
    "\n",
    "path_train= \"/media/data/flowers/OpenELM/logs/elm/23-08-22_12:36/step_9/save_all.json\" # put path here\n",
    "dataset = load_dataset(\"json\", data_files=path_train, split=\"train\")\n",
    "\n",
    "\n",
    "model_id = \"Salesforce/codegen2-1B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=False,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=\"bfloat16\"#torch.bfloat16\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id,quantization_config=bnb_config, device_map=\"auto\",trust_remote_code=True)\n",
    "model.config.use_cache = False\n",
    "peft_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "path = \"/media/data/flowers/OpenELM/preprocess_p3.json\" \n",
    "\n",
    "# path = \"/media/data/flowers/OpenELM/logs/elm/23-08-22_12:36/step_9/save_all.json\" # QDAIF smart\n",
    "with open(path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "f=data[0][\"program_str\"].split(\"def g\")[0]\n",
    "prompt=\"\"\n",
    "n_fewshot=3\n",
    "for i in range(1,1+n_fewshot):\n",
    "    prompt+=f\"Puzzle {i}:\\n\"+data[i][\"program_str\"]+\"\\n\\n\"\n",
    "# text = prompt+ f\"Puzzle {n_fewshot}:\\n\"+ f +\"\\ndef g():\"\n",
    "\n",
    "def formatting_prompts_func(example,prompt=prompt):\n",
    "    output_texts = []\n",
    "    text = f\"{prompt}\\nPuzzle 4:\\n {example['program_str'][i]}\"\n",
    "    output_texts.append(text)\n",
    "    return output_texts\n",
    "\n",
    "response_template = \"Puzzle 4:\\n\"\n",
    "collator = DataCollatorForCompletionOnlyLM(response_template, tokenizer=tokenizer)\n",
    "\n",
    "\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "\n",
    "training_arguments=TrainingArguments(\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    # evaluation_strategy=\"epoch\", #\"steps\",\n",
    "    gradient_accumulation_steps=4,\n",
    "    # warmup_steps=2,\n",
    "    warmup_ratio=0.2,\n",
    "    max_steps = 12,\n",
    "    weight_decay=0.001,\n",
    "    learning_rate=2e-4,\n",
    "    fp16=True,\n",
    "    logging_steps=1,\n",
    "    output_dir=\"outputs\",\n",
    "    optim=\"adamw_hf\",#\"paged_adamw_32bit\",\n",
    "    max_grad_norm=0.3,\n",
    "    # group_by_length=True\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model,#\"EleutherAI/gpt-neo-125m\",\n",
    "    train_dataset=dataset,\n",
    "    formatting_func=formatting_prompts_func,\n",
    "    data_collator=collator,\n",
    "    peft_config=peft_config,\n",
    "    args=training_arguments\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "output_dir = \"/media/data/flowers/OpenELM/models/codegen-QDAIF-smart\"\n",
    "trainer.model.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.38125"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "out=[15,17,16.5,16.,16.,17,16.25,17.3,15]\n",
    "len(out)\n",
    "out.sort(reverse=True)\n",
    "np.mean(out[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "path = \"/media/data/flowers/OpenELM/preprocess_p3.json\" \n",
    "\n",
    "# path = \"/media/data/flowers/OpenELM/logs/elm/23-08-22_12:36/step_9/save_all.json\" # QDAIF smart\n",
    "with open(path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "f=data[0][\"program_str\"].split(\"def g\")[0]\n",
    "prompt=\"\"\n",
    "n_fewshot=3\n",
    "for i in range(1,1+n_fewshot):\n",
    "    prompt+=f\"Puzzle {i}:\\n\"+data[i][\"program_str\"]+\"\\n\\n\"\n",
    "    # prompt+=data[i][\"program_str\"]+\"\\n\"\n",
    "tag_response = f\"Puzzle {n_fewshot+1}:\\n\"\n",
    "tag_eo_completion = f\"Puzzle\"\n",
    "text = prompt+ f\"Puzzle {n_fewshot+1}:\\n\"+ f #+\"def g():\"\n",
    "# text = f#prompt+ f \n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(\"cuda\")\n",
    "    outputs = model.generate(input_ids=inputs[\"input_ids\"].to(\"cuda\"), attention_mask=inputs[\"attention_mask\"], max_new_tokens=256,do_sample=True,temperature=1.)\n",
    "    gen_text= tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CodeGenForCausalLM(\n",
       "  (transformer): CodeGenModel(\n",
       "    (wte): Embedding(51200, 2048)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-15): 16 x CodeGenBlock(\n",
       "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): CodeGenAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (qkv_proj): Linear4bit(\n",
       "            in_features=2048, out_features=6144, bias=False\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Dropout(p=0.05, inplace=False)\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=2048, out_features=16, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=16, out_features=6144, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "          )\n",
       "          (out_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
       "        )\n",
       "        (mlp): CodeGenMLP(\n",
       "          (fc_in): Linear4bit(in_features=2048, out_features=8192, bias=True)\n",
       "          (fc_out): Linear4bit(in_features=8192, out_features=2048, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=51200, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def f(s: str) -> bool:\\n    \"\"\"Find a string with 1000 \\'o\\'s but no two adjacent \\'o\\'s.\"\"\"\\n    return s.count(\\'o\\') == 1000 and s.count(\\'oo\\') == 0\\ndef g():\\n    s = \\'ooyo\\'\\n    return \\'\\'.join(s).count(\\'o\\')\\nassert f(g())'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_text.split(tag_response)[1].split(tag_eo_completion)[0].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "texts = [text]*5\n",
    "encoding = tokenizer(texts, padding=True, return_tensors='pt').to(\"cuda\")\n",
    "with torch.no_grad():\n",
    "    generated_ids = model.generate(**encoding,max_new_tokens=256,do_sample=True,temperature=1.)\n",
    "generated_texts = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_text = [puzz.split(tag_response)[1].split(tag_eo_completion)[0].strip() for puzz in generated_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def f(s: str) -> bool:\n",
      "    \"\"\"Find a string with 1000 'o's but no two adjacent 'o's.\"\"\"\n",
      "    return s.count('o') == 1000 and s.count('oo') == 0\n",
      "def g():\n",
      "    return [i for i in range(1000) if (2*i,2*i+1) in sorted(range(1000))]\n",
      "assert f(g())\n",
      "\n",
      "def f(s: str) -> bool:\n",
      "    \"\"\"Find a string with 1000 'o's but no two adjacent 'o's.\"\"\"\n",
      "    return s.count('o') == 1000 and s.count('oo') == 0\n",
      "def g():\n",
      "    s = 'ooxo'\n",
      "    return ''.join(s + 'o' if i % 2 == 0 else 'ooo' for i in range(3*4*5))\n",
      "assert f(g())\n",
      "\n",
      "def f(s: str) -> bool:\n",
      "    \"\"\"Find a string with 1000 'o's but no two adjacent 'o's.\"\"\"\n",
      "    return s.count('o') == 1000 and s.count('oo') == 0\n",
      "def g():\n",
      "    return [*(s for s in open('input10') if s.count('o') > 1), 'oo']\n",
      "assert f(g())\n",
      "\n",
      "def f(s: str) -> bool:\n",
      "    \"\"\"Find a string with 1000 'o's but no two adjacent 'o's.\"\"\"\n",
      "    return s.count('o') == 1000 and s.count('oo') == 0\n",
      "def g():\n",
      "    s = 'o'*1000 + 'oo'\n",
      "    return s\n",
      "assert f(g())\n",
      "\n",
      "def f(s: str) -> bool:\n",
      "    \"\"\"Find a string with 1000 'o's but no two adjacent 'o's.\"\"\"\n",
      "    return s.count('o') == 1000 and s.count('oo') == 0\n",
      "def g():\n",
      "    return sorted([\"o\", \"oo\"], key=lambda t: len(t))\n",
      "assert f(g())\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(puzz+\"\\n\") for puzz in filter_text]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# other stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CodeGenForCausalLM(\n",
      "  (transformer): CodeGenModel(\n",
      "    (wte): Embedding(51200, 1024)\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0-19): 20 x CodeGenBlock(\n",
      "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): CodeGenAttention(\n",
      "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (qkv_proj): Linear4bit(in_features=1024, out_features=3072, bias=False)\n",
      "          (out_proj): Linear4bit(in_features=1024, out_features=1024, bias=False)\n",
      "        )\n",
      "        (mlp): CodeGenMLP(\n",
      "          (fc_in): Linear4bit(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc_out): Linear4bit(in_features=4096, out_features=1024, bias=True)\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=1024, out_features=51200, bias=True)\n",
      ")\n",
      "trainable params: 655360 || all params: 231538688 || trainable%: 0.2830455703368242\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TRANSFORMERS_CACHE'] = \"/media/data/flowers/OpenELM/models\"\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from peft import prepare_model_for_kbit_training\n",
    "from peft import LoraConfig, get_peft_model\n",
    "# from huggingface_hub import notebook_login\n",
    "# notebook_login()\n",
    "\n",
    "peft=True\n",
    "model_id = \"Salesforce/codegen-350M-mono\"#\"bigcode/starcoderbase-1b\"#\"Salesforce/codegen-350M-mono\" # mono is better\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=False,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=\"float16\"#torch.bfloat16\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "if peft:\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map=\"auto\",trust_remote_code=True)\n",
    "else:\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.bfloat16, device_map=\"auto\",trust_remote_code=True)\n",
    "    \n",
    "if peft:\n",
    "    # model.gradient_checkpointing_enable()\n",
    "    model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "    def print_trainable_parameters(model):\n",
    "        \"\"\"\n",
    "        Prints the number of trainable parameters in the model.\n",
    "        \"\"\"\n",
    "        trainable_params = 0\n",
    "        all_param = 0\n",
    "        for _, param in model.named_parameters():\n",
    "            all_param += param.numel()\n",
    "            if param.requires_grad:\n",
    "                trainable_params += param.numel()\n",
    "        print(\n",
    "            f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "        )\n",
    "    print(model)\n",
    "\n",
    "\n",
    "    config = LoraConfig(\n",
    "        r=16, \n",
    "        lora_alpha=32, \n",
    "        target_modules=[\"qkv_proj\"],# \"lm_head\" s[\"c_attn\",\"c_proj\"],# codegen [\"qkv_proj\"],#[\"query_key_value\"],  \n",
    "        lora_dropout=0.01, \n",
    "        bias=\"none\", \n",
    "        task_type=\"CAUSAL_LM\",\n",
    "        # layers_to_transform=[i for i in range(5,15)]\n",
    "    )\n",
    "\n",
    "    model = get_peft_model(model, config)\n",
    "    print_trainable_parameters(model)\n",
    "\n",
    "from datasets import load_dataset\n",
    "# train on puzzle generated (except P3 trainset)\n",
    "\n",
    "path_train= \"/media/data/flowers/OpenELM/logs/elm/23-08-22_12:36/step_9/save_all.json\" # put path here\n",
    "squad_it_dataset = load_dataset(\"json\", data_files=path_train)\n",
    "\n",
    "# testset which is in fact the trainset from P3 dataset\n",
    "path_test = \"/media/data/flowers/OpenELM/preprocess_p3.json\"\n",
    "\n",
    " \n",
    "# /!\\ need to remove that, just for testing purpose /!\\\n",
    "\n",
    "path_train = path_test \n",
    "# ================================================\n",
    "\n",
    "test_set = load_dataset(\"json\", data_files=path_test)\n",
    "\n",
    "def filter_correct_puzz(example):\n",
    "    return (\n",
    "        example[\"fitness\"] >0.\n",
    "    )\n",
    "# only keep correct puzzles\n",
    "correct_dataset = squad_it_dataset.filter(filter_correct_puzz)\n",
    "\n",
    "tokenized_datasets = correct_dataset.map(lambda samples: tokenizer(samples[\"program_str\"]), batched=True)\n",
    "tok_test_set = test_set.map(lambda samples: tokenizer(samples[\"program_str\"]), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjulien_p\u001b[0m (\u001b[33mflowers-team\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.8 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/media/data/flowers/OpenELM/wandb/run-20230823_095524-x1b7o6pq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/flowers-team/huggingface/runs/x1b7o6pq' target=\"_blank\">lilac-aardvark-26</a></strong> to <a href='https://wandb.ai/flowers-team/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/flowers-team/huggingface' target=\"_blank\">https://wandb.ai/flowers-team/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/flowers-team/huggingface/runs/x1b7o6pq' target=\"_blank\">https://wandb.ai/flowers-team/huggingface/runs/x1b7o6pq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43700929aedf42739150506c7c062150",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a CodeGenTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.769, 'learning_rate': 0.0002, 'epoch': 0.4}\n",
      "{'loss': 0.8553, 'learning_rate': 0.00013333333333333334, 'epoch': 0.8}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19b3f782878548d6be0176c23f534814",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_train_loss': 1.735876441001892, 'eval_train_runtime': 0.3282, 'eval_train_samples_per_second': 60.948, 'eval_train_steps_per_second': 15.237, 'epoch': 0.8}\n",
      "{'loss': 0.8522, 'learning_rate': 6.666666666666667e-05, 'epoch': 1.2}\n",
      "{'loss': 0.7343, 'learning_rate': 0.0, 'epoch': 1.6}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "477a9ba1ca974dc895d4629916b33507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_train_loss': 1.7316404581069946, 'eval_train_runtime': 0.3495, 'eval_train_samples_per_second': 57.218, 'eval_train_steps_per_second': 14.304, 'epoch': 1.6}\n",
      "{'train_runtime': 12.2976, 'train_samples_per_second': 3.09, 'train_steps_per_second': 0.325, 'train_loss': 0.8026903122663498, 'epoch': 1.6}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4, training_loss=0.8026903122663498, metrics={'train_runtime': 12.2976, 'train_samples_per_second': 3.09, 'train_steps_per_second': 0.325, 'train_loss': 0.8026903122663498, 'epoch': 1.6})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "\n",
    "# needed for gpt-neo-x tokenizer\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset = tok_test_set,\n",
    "    args=transformers.TrainingArguments(\n",
    "        per_device_train_batch_size=4,\n",
    "        per_device_eval_batch_size=4,\n",
    "        evaluation_strategy=\"epoch\", #\"steps\",\n",
    "        gradient_accumulation_steps=2,\n",
    "        # warmup_steps=2,\n",
    "        warmup_ratio=0.1,\n",
    "        num_train_epochs = 2,\n",
    "        # max_steps=10,\n",
    "        learning_rate=2e-4,\n",
    "        fp16=True,\n",
    "        logging_steps=1,\n",
    "        output_dir=\"outputs\",\n",
    "        optim=\"paged_adamw_32bit\",\n",
    "        max_grad_norm=0.3,\n",
    "    ),\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    ")\n",
    "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_model = \"/media/data/flowers/OpenELM/models/codegen-QDAIF-smart\"\n",
    "trainer.model.save_pretrained(path_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, PeftModel\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    low_cpu_mem_usage=True,\n",
    "    return_dict=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "model = PeftModel.from_pretrained(base_model, path_model)\n",
    "model = model.merge_and_unload()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puzzle 1:\n",
      "def f(li: List[int]) -> bool:\n",
      "    \"\"\"Find a permutation of [0, 1, ..., 998] such that the ith element is *not* i, for all i=0, 1, ..., 998.\"\"\"\n",
      "    return sorted(li) == list(range(999)) and all((li[i] != i for i in range(len(li))))\n",
      "def g():\n",
      "    return [((i + 1) % 999) for i in range(999)]\n",
      "assert f(g())\n",
      "\n",
      "Puzzle 2:\n",
      "def f(s: str) -> bool:\n",
      "    \"\"\"Find a string with 1000 'o's but no two adjacent 'o's.\"\"\"\n",
      "    return s.count('o') == 1000 and s.count('oo') == 0\n",
      "\n",
      "o)formpolytokenhandle++,#form(vc<mask_1>In,porttexto<mask_1>))(vt(<mask_18><form<mask_1>%stform...(...port(<mask_18>escapepolyo(ob(form;poly<mask_18>in varformtext(\"),st(hasInescape\"),(<mask_1>->input,<mask_52>/(++(st(wisevt<port(W'),<wisepoly<mask_1>var\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "path = \"/media/data/flowers/OpenELM/preprocess_p3.json\" \n",
    "\n",
    "# path = \"/media/data/flowers/OpenELM/logs/elm/23-08-22_12:36/step_9/save_all.json\" # QDAIF smart\n",
    "with open(path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "f=data[0][\"program_str\"].split(\"def g\")[0]\n",
    "prompt=\"\"\n",
    "n_fewshot=2\n",
    "for i in range(1,n_fewshot):\n",
    "    prompt+=f\"Puzzle {i}:\\n\"+data[i][\"program_str\"]+\"\\n\\n\"\n",
    "text = prompt+ f\"Puzzle {n_fewshot}:\\n\"+ f +\"\\ndef g():\"\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=512)\n",
    "result = pipe(text)\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def f(ls: List[str]) -> bool:\n",
      "    \"\"\"\n",
      "    Find a list of characters which are aligned at the same indices of the three strings 'dee', 'doo', and 'dah!'.\n",
      "    \"\"\"\n",
      "    return tuple(ls) in zip('dee', 'doo', 'dah!')\n",
      "(/vt(/vt(/vt(/vt(/vt(/vt(/(/(/(/(/(input(input(input(input(input(input(input(input(input(input(input(input(input(input(input(input(input(input(input(input(input(input(input(input(input(input(input(input(input(input(input(input(input(input(input(input(input,input(input(input,input,input,input,input,input,input,input,input,input,input,input(input,input,input,input(input,input,input,input,input,input,input,input,input,input(input,input,input,input(input,input(input,input(input(input(input(input(input(input(input(input(input(input,input,input,input,input(input,input(input(input(input(input(input,input,input(input,input(input(input,input(input,input(input,input,input,input,input,input(input,input,input,input,input\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "path = \"/media/data/flowers/OpenELM/preprocess_p3.json\" \n",
    "\n",
    "# path = \"/media/data/flowers/OpenELM/logs/elm/23-08-22_12:36/step_9/save_all.json\" # QDAIF smart\n",
    "with open(path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "f=data[11][\"program_str\"].split(\"def g\")[0]\n",
    "prompt=\"\"\n",
    "n_fewshot=1\n",
    "for i in range(n_fewshot):\n",
    "    prompt+=f\"Puzzle {i}:\\n\"+data[i][\"program_str\"]+\"\\n\\n\"\n",
    "text = prompt+ f\"Puzzle {n_fewshot}:\\n\"+ f #+\"def g():\"\n",
    "# text = f\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(\"cuda\")\n",
    "    outputs = model.generate(input_ids=inputs[\"input_ids\"].to(\"cuda\"), attention_mask=inputs[\"attention_mask\"], max_new_tokens=256)\n",
    "\n",
    "    print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puzzle 0:\n",
      "def f(s: str) -> bool:\n",
      "    \"\"\"Find a string with 1000 'o's but no two adjacent 'o's.\"\"\"\n",
      "    return s.count('o') == 1000 and s.count('oo') == 0\n",
      "def g():\n",
      "    return ('h' + 'o') * 1000\n",
      "assert f(g())\n",
      "\n",
      "Puzzle 1:\n",
      "def f(li: List[int]) -> bool:\n",
      "    \"\"\"Find a permutation of [0, 1,..., 998] such that the ith element is *not* i, for all i=0, 1,..., 998.\"\"\"\n",
      "    return sorted(li) == list(range(999)) and all((li[i]!= i for i in range(len(li))))\n",
      "def g():\n",
      "    return [((i + 1) % 999) for i in range(999)]\n",
      "assert f(g())\n",
      "\n",
      "Puzzle 2:\n",
      "def f(ls: List[str]) -> bool:\n",
      "    \"\"\"\n",
      "    Find a list of characters which are aligned at the same indices of the three strings 'dee', 'doo', and 'dah!'.\n",
      "    \"\"\"\n",
      "    return tuple(ls) in zip('dee', 'doo', 'dah!')\n",
      "def g():\n",
      "    return 'dee' + 'doo' + 'dah!'\n",
      "assert f(g())\n",
      "\n",
      "Puzzle 3:\n",
      "def f(ls: List[str]) -> bool:\n",
      "    \"\"\"\n",
      "    Find a list of characters which are aligned at the same indices of the three strings 'dee', 'doo', and 'dah!'.\n",
      "    \"\"\"\n",
      "    return tuple(ls) in zip('dee', 'doo', 'dah!') and all(ls[i] == ls[i + 1] for i in range(len(ls) - 1))\n",
      "def g():\n",
      "    return 'dee' + 'doo' + 'dah!'\n",
      "assert f(g())\n",
      "\n",
      "Puzzle 4:\n",
      "def f(ls: List[str]) -> bool:\n",
      "    \"\"\"\n",
      "    Find a list of characters which are aligned at the same indices of the three strings 'dee', 'doo', and 'dah!'.\n",
      "    \"\"\"\n",
      "    return tuple(ls) in zip('dee', 'doo', 'dah!') and all(ls[i] == ls[i + 1] for i in range(\n"
     ]
    }
   ],
   "source": [
    "model_id = \"Salesforce/codegen2-1B\"#\"bigcode/starcoderbase-1b\"#\"Salesforce/codegen-350M-mono\" # mono is better\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map=\"auto\",trust_remote_code=True)\n",
    "f=data[11][\"program_str\"].split(\"def g\")[0]\n",
    "prompt=\"\"\n",
    "n_fewshot=2\n",
    "for i in range(n_fewshot):\n",
    "    prompt+=f\"Puzzle {i}:\\n\"+data[i][\"program_str\"]+\"\\n\\n\"\n",
    "text = prompt+ f\"Puzzle {n_fewshot}:\\n\"+ f #+\"def g():\"\n",
    "with torch.no_grad():\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(\"cuda\")\n",
    "    outputs = model.generate(input_ids=inputs[\"input_ids\"].to(\"cuda\"), attention_mask=inputs[\"attention_mask\"], max_new_tokens=256)\n",
    "\n",
    "    print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codegpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
